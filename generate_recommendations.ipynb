{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "565a1762-f292-40ab-920c-bd301e15141c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ FAISS available for ultra-fast similarity search\n",
      "Using device: cuda\n",
      "ğŸš€ Starting Complete Image-Book Emotion Matching System\n",
      "================================================================================\n",
      "INITIALIZING COMPLETE IMAGE-BOOK EMOTION MATCHING SYSTEM\n",
      "================================================================================\n",
      "Loading ResNet model...\n",
      "âœ“ ResNet model loaded and tested successfully\n",
      "Loading and preprocessing book emotion distributions with image URLs...\n",
      "Loading preprocessed books data for image URLs...\n",
      "âœ“ Loaded 931229 books from preprocessed data\n",
      "âœ“ Found 931229 books with image URLs\n",
      "Loading ResNet emotion predictions...\n",
      "Loading BERT emotion predictions...\n",
      "âœ“ Loaded ResNet emotions for 686990 books\n",
      "âœ“ Loaded BERT emotions for 686946 books\n",
      "Merging ResNet data with image URLs...\n",
      "Merging BERT data with image URLs...\n",
      "âœ“ Final dataset: 686907 books with both ResNet and BERT predictions\n",
      "âœ“ ResNet books with image URLs: 686907\n",
      "âœ“ BERT books with image URLs: 686907\n",
      "Precomputing emotion matrices for fast similarity...\n",
      "Precomputing multimodal combinations...\n",
      "Moving emotion matrices to GPU for fast similarity...\n",
      "Building FAISS indices for similarity search...\n",
      "âœ“ FAISS indices built successfully\n",
      "âœ“ System ready! Loaded 686907 books for matching\n",
      "================================================================================\n",
      "\n",
      "ğŸ“¸ Analyzing image: input_images/anger_painting.jpg\n",
      "Image prediction took 0.009s\n",
      "Image dominant emotion: sadness\n",
      "Image confidence: 0.340\n",
      "Similarity search took 0.107s\n",
      "Total processing time: 0.119s for 686907 books\n",
      "\n",
      "ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”ğŸ”\n",
      "\n",
      "====================================================================================================\n",
      "DETAILED BOOK RECOMMENDATIONS WITH COVERS\n",
      "====================================================================================================\n",
      "\n",
      "ğŸ“¸ IMAGE ANALYSIS:\n",
      "   Dominant Emotion: sadness\n",
      "   Confidence: 0.340\n",
      "   Processing Time: 0.119s\n",
      "\n",
      "ğŸ“Š Creating emotion distribution bar charts...\n",
      "ğŸ’¾ Saving charts to: emotion_analysis_2/\n",
      "âœ“ Saved input image emotions: emotion_analysis_2/input_image_emotions_sadness.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch-local/fharlaar.12213868/ipykernel_1134582/3713606440.py:1134: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved ResNet comparison: emotion_analysis_2/resnet_emotion_comparison_sadness.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch-local/fharlaar.12213868/ipykernel_1134582/3713606440.py:1214: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved BERT comparison: emotion_analysis_2/bert_emotion_comparison_sadness.png\n",
      "âœ“ Saved Multimodal comparison: emotion_analysis_2/multimodal_emotion_comparison_sadness.png\n",
      "âœ“ Saved emotion heatmap: emotion_analysis_2/emotion_heatmap_sadness.png\n",
      "\n",
      "ğŸ“ˆ Creating detailed emotion analysis report...\n",
      "\n",
      "ğŸ“Š Creating emotion distribution bar charts...\n",
      "ğŸ’¾ Saving charts to: emotion_analysis_2/charts/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch-local/fharlaar.12213868/ipykernel_1134582/3713606440.py:1289: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Saved input image emotions: emotion_analysis_2/charts/input_image_emotions_sadness.png\n",
      "âœ“ Saved ResNet comparison: emotion_analysis_2/charts/resnet_emotion_comparison_sadness.png\n",
      "âœ“ Saved BERT comparison: emotion_analysis_2/charts/bert_emotion_comparison_sadness.png\n",
      "âœ“ Saved Multimodal comparison: emotion_analysis_2/charts/multimodal_emotion_comparison_sadness.png\n",
      "âœ“ Saved emotion heatmap: emotion_analysis_2/charts/emotion_heatmap_sadness.png\n",
      "âœ“ Saved detailed emotion analysis: emotion_analysis_2/emotion_analysis_sadness.json\n",
      "âœ“ Saved emotion charts in: emotion_analysis_2/charts/\n",
      "\n",
      "ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­\n",
      "EMOTION DISTRIBUTION ANALYSIS\n",
      "ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­ğŸ­\n",
      "\n",
      "ğŸ“¸ INPUT IMAGE EMOTION DISTRIBUTION:\n",
      "   Dominant: sadness (confidence: 0.340)\n",
      "   Full Distribution:\n",
      "   amusement       â”‚â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚ 0.051\n",
      "   awe             â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚ 0.135\n",
      "   contentment     â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚ 0.185\n",
      "   excitement      â”‚â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚ 0.040\n",
      "   anger           â”‚â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚ 0.034\n",
      "   disgust         â”‚â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚ 0.074\n",
      "   fear            â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚ 0.092\n",
      "   sadness         â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚ 0.340\n",
      "   something else  â”‚â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚ 0.049\n",
      "\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ§  RESNET RECOMMENDATIONS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“š 1. Dreamless\n",
      "   ğŸ“Š Similarity Score: 0.9975\n",
      "   ğŸ¯ Predicted Emotion: sadness\n",
      "   ğŸ“ˆ Book Emotion Distribution:\n",
      "   ğŸ” Cosine Similarity: 0.9975\n",
      "   ğŸ“ KL Divergence: 0.0052\n",
      "   amusement     â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.051 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.063 â‰ˆ\n",
      "   awe           â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.135 â”‚Book:â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.113 â‰ˆ\n",
      "   contentment   â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.185 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.191 â‰ˆ\n",
      "   excitement    â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.040 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.038 â‰ˆ\n",
      "   anger         â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.034 â”‚Book:â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.032 â‰ˆ\n",
      "   disgust       â”‚Img:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.074 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.063 â‰ˆ\n",
      "   fear          â”‚Img:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.092 â”‚Book:â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.103 â‰ˆ\n",
      "   sadness       â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.340 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.343 â‰ˆ\n",
      "   something else â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.049 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.054 â‰ˆ\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“š 2. Runaway!\n",
      "   ğŸ“Š Similarity Score: 0.9975\n",
      "   ğŸ¯ Predicted Emotion: sadness\n",
      "   ğŸ“ˆ Book Emotion Distribution:\n",
      "   ğŸ” Cosine Similarity: 0.9975\n",
      "   ğŸ“ KL Divergence: 0.0057\n",
      "   amusement     â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.051 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.060 â‰ˆ\n",
      "   awe           â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.135 â”‚Book:â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.126 â‰ˆ\n",
      "   contentment   â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.185 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.203 â‰ˆ\n",
      "   excitement    â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.040 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.038 â‰ˆ\n",
      "   anger         â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.034 â”‚Book:â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.032 â‰ˆ\n",
      "   disgust       â”‚Img:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.074 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.060 â‰ˆ\n",
      "   fear          â”‚Img:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.092 â”‚Book:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.081 â‰ˆ\n",
      "   sadness       â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.340 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.337 â‰ˆ\n",
      "   something else â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.049 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.063 â‰ˆ\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“š 3. Bengali Girls Don't\n",
      "   ğŸ“Š Similarity Score: 0.9972\n",
      "   ğŸ¯ Predicted Emotion: sadness\n",
      "   ğŸ“ˆ Book Emotion Distribution:\n",
      "   ğŸ” Cosine Similarity: 0.9972\n",
      "   ğŸ“ KL Divergence: 0.0072\n",
      "   amusement     â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.051 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.056 â‰ˆ\n",
      "   awe           â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.135 â”‚Book:â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.125 â‰ˆ\n",
      "   contentment   â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.185 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.189 â‰ˆ\n",
      "   excitement    â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.040 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.041 â‰ˆ\n",
      "   anger         â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.034 â”‚Book:â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.029 â‰ˆ\n",
      "   disgust       â”‚Img:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.074 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.058 â‰ˆ\n",
      "   fear          â”‚Img:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.092 â”‚Book:â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.106 â‰ˆ\n",
      "   sadness       â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.340 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.329 â‰ˆ\n",
      "   something else â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.049 â”‚Book:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.068 â‰ˆ\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“ BERT RECOMMENDATIONS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“š 1. The Oâ€™Rahilly: A Secret History of the Rebellion o...\n",
      "   ğŸ“Š Similarity Score: 0.9943\n",
      "   ğŸ¯ Predicted Emotion: awe\n",
      "   ğŸ“ˆ Book Emotion Distribution:\n",
      "   ğŸ” Cosine Similarity: 0.9943\n",
      "   ğŸ“ KL Divergence: 0.0204\n",
      "   amusement     â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.051 â”‚Book:â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.031 â‰ˆ\n",
      "   awe           â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.135 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.138 â‰ˆ\n",
      "   contentment   â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.185 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.165 â‰ˆ\n",
      "   excitement    â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.040 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.055 â‰ˆ\n",
      "   anger         â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.034 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.060 â‰ˆ\n",
      "   disgust       â”‚Img:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.074 â”‚Book:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.082 â‰ˆ\n",
      "   fear          â”‚Img:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.092 â”‚Book:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.091 â‰ˆ\n",
      "   sadness       â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.340 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.347 â‰ˆ\n",
      "   something else â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.049 â”‚Book:â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.031 â‰ˆ\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“š 2. Yosl Rakover Talks to God\n",
      "   ğŸ“Š Similarity Score: 0.9933\n",
      "   ğŸ¯ Predicted Emotion: something else\n",
      "   ğŸ“ˆ Book Emotion Distribution:\n",
      "   ğŸ” Cosine Similarity: 0.9933\n",
      "   ğŸ“ KL Divergence: 0.0115\n",
      "   amusement     â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.051 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.045 â‰ˆ\n",
      "   awe           â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.135 â”‚Book:â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.104 â‰ˆ\n",
      "   contentment   â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.185 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.184 â‰ˆ\n",
      "   excitement    â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.040 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.043 â‰ˆ\n",
      "   anger         â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.034 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.041 â‰ˆ\n",
      "   disgust       â”‚Img:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.074 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.056 â‰ˆ\n",
      "   fear          â”‚Img:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.092 â”‚Book:â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.103 â‰ˆ\n",
      "   sadness       â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.340 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.382 â‰ˆ\n",
      "   something else â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.049 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.040 â‰ˆ\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“š 3. We Gon' Be Alright: Notes on Race and Resegregatio...\n",
      "   ğŸ“Š Similarity Score: 0.9931\n",
      "   ğŸ¯ Predicted Emotion: amusement\n",
      "   ğŸ“ˆ Book Emotion Distribution:\n",
      "   ğŸ” Cosine Similarity: 0.9931\n",
      "   ğŸ“ KL Divergence: 0.0170\n",
      "   amusement     â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.051 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.035 â‰ˆ\n",
      "   awe           â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.135 â”‚Book:â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.119 â‰ˆ\n",
      "   contentment   â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.185 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.175 â‰ˆ\n",
      "   excitement    â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.040 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.035 â‰ˆ\n",
      "   anger         â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.034 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.052 â‰ˆ\n",
      "   disgust       â”‚Img:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.074 â”‚Book:â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.105 â‰ˆ\n",
      "   fear          â”‚Img:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.092 â”‚Book:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.072 â‰ˆ\n",
      "   sadness       â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.340 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.362 â‰ˆ\n",
      "   something else â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.049 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.045 â‰ˆ\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ”— MULTIMODAL RECOMMENDATIONS\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“š 1. The Long March: The true story behind the legendar...\n",
      "   ğŸ“Š Similarity Score: 0.9981\n",
      "   ğŸ¯ Predicted Emotion: amusement\n",
      "   ğŸ“ˆ Book Emotion Distribution:\n",
      "   ğŸ” Cosine Similarity: 0.9981\n",
      "   ğŸ“ KL Divergence: 0.0064\n",
      "   amusement     â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.051 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.060 â‰ˆ\n",
      "   awe           â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.135 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.134 â‰ˆ\n",
      "   contentment   â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.185 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.191 â‰ˆ\n",
      "   excitement    â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.040 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.036 â‰ˆ\n",
      "   anger         â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.034 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.041 â‰ˆ\n",
      "   disgust       â”‚Img:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.074 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.058 â‰ˆ\n",
      "   fear          â”‚Img:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.092 â”‚Book:â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.104 â‰ˆ\n",
      "   sadness       â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.340 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.339 â‰ˆ\n",
      "   something else â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.049 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.036 â‰ˆ\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“š 2. Summer of Hope\n",
      "   ğŸ“Š Similarity Score: 0.9968\n",
      "   ğŸ¯ Predicted Emotion: awe\n",
      "   ğŸ“ˆ Book Emotion Distribution:\n",
      "   ğŸ” Cosine Similarity: 0.9968\n",
      "   ğŸ“ KL Divergence: 0.0064\n",
      "   amusement     â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.051 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.055 â‰ˆ\n",
      "   awe           â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.135 â”‚Book:â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.111 â‰ˆ\n",
      "   contentment   â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.185 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.197 â‰ˆ\n",
      "   excitement    â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.040 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.047 â‰ˆ\n",
      "   anger         â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.034 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.035 â‰ˆ\n",
      "   disgust       â”‚Img:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.074 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.057 â‰ˆ\n",
      "   fear          â”‚Img:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.092 â”‚Book:â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.103 â‰ˆ\n",
      "   sadness       â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.340 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.347 â‰ˆ\n",
      "   something else â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.049 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.049 â‰ˆ\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“š 3. Smoldering City: Chicagoans and the Great Fire, 18...\n",
      "   ğŸ“Š Similarity Score: 0.9954\n",
      "   ğŸ¯ Predicted Emotion: awe\n",
      "   ğŸ“ˆ Book Emotion Distribution:\n",
      "   ğŸ” Cosine Similarity: 0.9954\n",
      "   ğŸ“ KL Divergence: 0.0114\n",
      "   amusement     â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.051 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.060 â‰ˆ\n",
      "   awe           â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.135 â”‚Book:â–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.107 â‰ˆ\n",
      "   contentment   â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.185 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.191 â‰ˆ\n",
      "   excitement    â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.040 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.047 â‰ˆ\n",
      "   anger         â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.034 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.046 â‰ˆ\n",
      "   disgust       â”‚Img:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.074 â”‚Book:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.061 â‰ˆ\n",
      "   fear          â”‚Img:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.092 â”‚Book:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.082 â‰ˆ\n",
      "   sadness       â”‚Img:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.340 â”‚Book:â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.336 â‰ˆ\n",
      "   something else â”‚Img:â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.049 â”‚Book:â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â”‚0.071 â‰ˆ\n",
      "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "============================== ğŸ§  RESNET-ONLY RECOMMENDATIONS ==============================\n",
      "\n",
      "ğŸ† TOP 3 MOST SIMILAR\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "   1. ğŸ“š Dreamless\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 9330885\n",
      "      â­ Rating: 3.92\n",
      "      ğŸ¯ Similarity Score: 0.9975\n",
      "      ğŸ§  ResNet Emotion: sadness\n",
      "      ğŸ“ BERT Emotion: something else\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1290170247l/9330885.jpg\n",
      "      ğŸ“– Description: A World War II romance about an American girl and a Japanese boy who have seen each other's lives in their sleep since birth. This is a 72-page, FULL COLOR graphic novel collecting the complete acclai...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   2. ğŸ“š Runaway!\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 14402305\n",
      "      â­ Rating: 4.12\n",
      "      ğŸ¯ Similarity Score: 0.9975\n",
      "      ğŸ§  ResNet Emotion: sadness\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1340031123l/14402305.jpg\n",
      "      ğŸ“– Description: Out of print\n",
      "A runaway slave boy, the Underground Railroad, a land without shadows. Robbed of his emancipation by his master's widow, a literate 14-year-old slave boy flees into the prairie. His journ...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   3. ğŸ“š Bengali Girls Don't\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 12078346\n",
      "      â­ Rating: 3.18\n",
      "      ğŸ¯ Similarity Score: 0.9972\n",
      "      ğŸ§  ResNet Emotion: sadness\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1313500615l/12078346.jpg\n",
      "      ğŸ“– Description: Based on a True Story:\n",
      "Born in a remote village during her country's liberation war, a Bangladeshi girl moves to England with her parents and struggles for freedom and identity while growing up in a m...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“Š MIDDLE 3 SIMILAR\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "   1. ğŸ“š Tiy and the Prince of Egypt\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 18306865\n",
      "      â­ Rating: 4.37\n",
      "      ğŸ¯ Similarity Score: 0.9968\n",
      "      ğŸ§  ResNet Emotion: sadness\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1376201779l/18306865.jpg\n",
      "      ğŸ“– Description: Based on the lives of Pharaoh Amenhotep III and Queen Tiy - a historical romance for all ages!Tiy is different than the other Egyptian girls--she has pale hair and more freckles than she wants to coun...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   2. ğŸ“š Never (Lightbringer, #3)\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 17167007\n",
      "      â­ Rating: 3.94\n",
      "      ğŸ¯ Similarity Score: 0.9967\n",
      "      ğŸ§  ResNet Emotion: sadness\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1356380788l/17167007.jpg\n",
      "      ğŸ“– Description: The Lightbringer trilogy's dramatic conclusion!\n",
      "The Never is on the brink of destruction by the Lady Walker. Wendy, shorn of her Light by the Reapers, must be the one to save it from the beasts betwee...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   3. ğŸ“š If You Really Love Me\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 21840882\n",
      "      â­ Rating: 3.67\n",
      "      ğŸ¯ Similarity Score: 0.9965\n",
      "      ğŸ§  ResNet Emotion: sadness\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1396491579l/21840882.jpg\n",
      "      ğŸ“– Description: A Harmony Ink Press Young Adult Title\n",
      "With time ticking until graduation, Ellis Carter doesn't have a plan for after high school. Since his best friend Cary dropped out, he has no one to talk to. All ...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“‰ BOTTOM 3 LEAST SIMILAR\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "   1. ğŸ“š Joseph's Story\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 13341980\n",
      "      â­ Rating: 3.57\n",
      "      ğŸ¯ Similarity Score: 0.9965\n",
      "      ğŸ§  ResNet Emotion: sadness\n",
      "      ğŸ“ BERT Emotion: excitement\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1340739667l/13341980.jpg\n",
      "      ğŸ“– Description: Joseph was the happiest man alive. He was going to marry the most beautiful girl in Nazareth. He had some of the best friends anyone could want. His carpentry business was taking off. His furniture an...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   2. ğŸ“š Spy Hard (SDDU, #12)\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 13263393\n",
      "      â­ Rating: 3.81\n",
      "      ğŸ¯ Similarity Score: 0.9965\n",
      "      ğŸ§  ResNet Emotion: sadness\n",
      "      ğŸ“ BERT Emotion: fear\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1338592786l/13263393.jpg\n",
      "      ğŸ“– Description: Being deep undercover in a drug lord's compound, Jase Campbell can't afford to be anything but ruthless and mission-oriented. But it doesn't take trained instincts to see that pregnant Melanie Key nee...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   3. ğŸ“š Pirates You Don't Know, and Other Adventures in the Examined Life: Collected Essays\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 18528395\n",
      "      â­ Rating: 4.84\n",
      "      ğŸ¯ Similarity Score: 0.9963\n",
      "      ğŸ§  ResNet Emotion: sadness\n",
      "      ğŸ“ BERT Emotion: amusement\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1386200677l/18528395.jpg\n",
      "      ğŸ“– Description: For nearly ten years John Griswold has been publishing his essays in Inside Higher Ed, McSweeney's Internet Tendency, Brevity, Ninth Letter, and Adjunct Advocate, many under the pen name Oronte Churm....\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "============================== ğŸ“ BERT-ONLY RECOMMENDATIONS ==============================\n",
      "\n",
      "ğŸ† TOP 3 MOST SIMILAR\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "   1. ğŸ“š The Oâ€™Rahilly: A Secret History of the Rebellion of 1916\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 29505492\n",
      "      â­ Rating: 4.0\n",
      "      ğŸ¯ Similarity Score: 0.9943\n",
      "      ğŸ§  ResNet Emotion: awe\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1457963343l/29505492.jpg\n",
      "      ğŸ“– Description: The only leader of the 1916 Rising to be killed in action, Michael O'Rahilly died in a Dublin laneway after leading a charge against a British barricade in Moore Street. A letter to his wife, written ...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   2. ğŸ“š Yosl Rakover Talks to God\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 1411357\n",
      "      â­ Rating: 4.14\n",
      "      ğŸ¯ Similarity Score: 0.9933\n",
      "      ğŸ§  ResNet Emotion: something else\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1320543569l/1411357.jpg\n",
      "      ğŸ“– Description: There are two stories here. One is the now legendary tale of a defiant Jew's refusal to abandon God, even in the face of the greatest suffering the world has known, a testament of faith that has taken...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   3. ğŸ“š We Gon' Be Alright: Notes on Race and Resegregation\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 28595947\n",
      "      â­ Rating: 4.29\n",
      "      ğŸ¯ Similarity Score: 0.9931\n",
      "      ğŸ§  ResNet Emotion: amusement\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1468230274l/28595947.jpg\n",
      "      ğŸ“– Description: In these provocative, powerful essays acclaimed writer/journalist Jeff Chang (Can't Stop Won't Stop, Who We Be) takes an incisive and wide-ranging look at the recent tragedies and widespread protests ...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“Š MIDDLE 3 SIMILAR\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "   1. ğŸ“š Empires at War: A Short History of Modern Asia Since World War II\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 7332277\n",
      "      â­ Rating: 4.0\n",
      "      ğŸ¯ Similarity Score: 0.9926\n",
      "      ğŸ§  ResNet Emotion: amusement\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1315685394l/7332277.jpg\n",
      "      ğŸ“– Description: Empires at Wargives a dramatic narrative account of how \"Modern Asia\" came into being. Ranging over the whole of Asia, from Japan to Pakistan, the modern history of this important region is placed in ...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   2. ğŸ“š Schindler's Ark\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 1394875\n",
      "      â­ Rating: 4.34\n",
      "      ğŸ¯ Similarity Score: 0.9922\n",
      "      ğŸ§  ResNet Emotion: amusement\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1415587682l/1394875.jpg\n",
      "      ğŸ“– Description: The basis for the Oscar-winning Spielberg movie, this novel recreates the story of Oskar Schindler, an Aryan who risked his life to protect Jews in Nazi-occupied Poland....\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   3. ğŸ“š Treasure Mountain\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 8411911\n",
      "      â­ Rating: 4.01\n",
      "      ğŸ¯ Similarity Score: 0.9921\n",
      "      ğŸ§  ResNet Emotion: fear\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1349265725l/8411911.jpg\n",
      "      ğŸ“– Description: How do you bring a million dollars in gold down a mountain? First you have to find it, and that's mighty hard when you're tracking a trail that is twenty years old. But the Sackett brothers were deter...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“‰ BOTTOM 3 LEAST SIMILAR\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "   1. ğŸ“š Treasure Mountain\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 282092\n",
      "      â­ Rating: 4.01\n",
      "      ğŸ¯ Similarity Score: 0.9921\n",
      "      ğŸ§  ResNet Emotion: contentment\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1320446730l/282092.jpg\n",
      "      ğŸ“– Description: How do you bring a million dollars in gold down a mountain? First you have to find it, and that's mighty hard when you're tracking a trail that is twenty years old. But the Sackett brothers were deter...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   2. ğŸ“š Treasure Mountain\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 120990\n",
      "      â­ Rating: 4.01\n",
      "      ğŸ¯ Similarity Score: 0.9921\n",
      "      ğŸ§  ResNet Emotion: sadness\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1326753881l/120990.jpg\n",
      "      ğŸ“– Description: How do you bring a million dollars in gold down a mountain? First you have to find it, and that's mighty hard when you're tracking a trail that is twenty years old. But the Sackett brothers were deter...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   3. ğŸ“š Martin Luther King, Jr.: The Last Interview: And Other Conversations\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 30160990\n",
      "      â­ Rating: 4.16\n",
      "      ğŸ¯ Similarity Score: 0.9920\n",
      "      ğŸ§  ResNet Emotion: amusement\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1471292131l/30160990.jpg\n",
      "      ğŸ“– Description: As the Black Lives Matter movement gains momentum, and books like Ta-Nehisi Coates's Between the World and Meand Claudia Rankine's Citizenswing national attention toward the racism and violence that c...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "============================== ğŸ”— MULTIMODAL RECOMMENDATIONS ==============================\n",
      "\n",
      "ğŸ† TOP 3 MOST SIMILAR\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "   1. ğŸ“š The Long March: The true story behind the legendary journey that made Mao's China\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 1442782\n",
      "      â­ Rating: 3.8\n",
      "      ğŸ¯ Similarity Score: 0.9981\n",
      "      ğŸ§  ResNet Emotion: amusement\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1450349679l/1442782.jpg\n",
      "      ğŸ“– Description: This is a living history of the legendary journey that made Mao's China. In October 1934, the First Front Army of the Chinese Communist Party fled annihilation by Chiang Kai-shek's Nationalists. Some ...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   2. ğŸ“š Summer of Hope\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 15870096\n",
      "      â­ Rating: 3.79\n",
      "      ğŸ¯ Similarity Score: 0.9968\n",
      "      ğŸ§  ResNet Emotion: awe\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1356574564l/15870096.jpg\n",
      "      ğŸ“– Description: A secret can change everything.\n",
      "After witnessing her twin brother's death, sixteen-year-old Callie shuts down. Forced to go to her family's summer beach house, she resolves to erase the pain any way s...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   3. ğŸ“š Smoldering City: Chicagoans and the Great Fire, 1871-1874\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 1816515\n",
      "      â­ Rating: 3.33\n",
      "      ğŸ¯ Similarity Score: 0.9954\n",
      "      ğŸ§  ResNet Emotion: awe\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1328872691l/1816515.jpg\n",
      "      ğŸ“– Description: The fateful kick of Mrs. O'Leary's cow, the wild flight before the flames, the astonishingly quick rebuilding--these are the well-known stories of the Great Chicago Fire of 1871. But as much as Chicag...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“Š MIDDLE 3 SIMILAR\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "   1. ğŸ“š This Change Is Everything\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 33800133\n",
      "      â­ Rating: 3.43\n",
      "      ğŸ¯ Similarity Score: 0.9947\n",
      "      ğŸ§  ResNet Emotion: awe\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1483637635l/33800133.jpg\n",
      "      ğŸ“– Description: In \"This Change Is Everything\", Shane Sebastian walks through the history of God using young people to transform individuals, communities, cultures and nations. Shane shows how seemingly insurmountabl...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   2. ğŸ“š When A Woman You Love Was Abused: A Husband's Guide to Helping Her Overcome Childhood Sexual Molestation\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 15802150\n",
      "      â­ Rating: 4.38\n",
      "      ğŸ¯ Similarity Score: 0.9944\n",
      "      ğŸ§  ResNet Emotion: awe\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1344384752l/15802150.jpg\n",
      "      ğŸ“– Description: About the Book:\n",
      "The U.S. Department of Health and Human Services reports that 80 percent of childhood abuse victims later suffer from at least one abuse-induced psychological disorder. It's proven tha...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   3. ğŸ“š The Doctor's Mission\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 11714143\n",
      "      â­ Rating: 4.0\n",
      "      ğŸ¯ Similarity Score: 0.9943\n",
      "      ğŸ§  ResNet Emotion: awe\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1313281835l/11714143.jpg\n",
      "      ğŸ“– Description: To save lives, she would risk her own\n",
      "A woman doctor! Missionary William Mayweather can't hide his disappointment. The Nynabo mission in Liberia, Africa, desperately needs help, but he's vowed not to ...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "ğŸ“‰ BOTTOM 3 LEAST SIMILAR\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "   1. ğŸ“š The Folk of the Fringe\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 92961\n",
      "      â­ Rating: 3.31\n",
      "      ğŸ¯ Similarity Score: 0.9940\n",
      "      ğŸ§  ResNet Emotion: amusement\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1311989306l/92961.jpg\n",
      "      ğŸ“– Description: Only a few nuclear weapons fell in America-the weapons that destroyed our nation were biological and, ultimately, cultural. But in the chaos, the famine, the plague, there exited a few pockets of orde...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   2. ğŸ“š Losing It All to Sprawl: How Progress Ate My Cracker Landscape\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 317567\n",
      "      â­ Rating: 4.15\n",
      "      ğŸ¯ Similarity Score: 0.9940\n",
      "      ğŸ§  ResNet Emotion: awe\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1344752725l/317567.jpg\n",
      "      ğŸ“– Description: As development threatens his very sense of place, an award-winning nature writer finds hope in the rediscovery and appreciation of his historic Cracker farmhouse.\n",
      "Losing It All to Sprawlis the poignan...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "\n",
      "   3. ğŸ“š The Silence of Our Friends\n",
      "      ğŸ‘¤ Author(s): Unknown Author\n",
      "      ğŸ†” Book ID: 11311549\n",
      "      â­ Rating: 3.86\n",
      "      ğŸ¯ Similarity Score: 0.9935\n",
      "      ğŸ§  ResNet Emotion: sadness\n",
      "      ğŸ“ BERT Emotion: sadness\n",
      "      ğŸ–¼ï¸  Cover URL: https://images.gr-assets.com/books/1316731249l/11311549.jpg\n",
      "      ğŸ“– Description: In 1960s Texas, a white family from a notoriously racist neighborhood and a black family from its poorest ward cross Houston's color line, overcoming humiliation, degradation, and violence to win the ...\n",
      "      â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "Loading cover for Dreamless...\n",
      "âœ“ Loaded cover for Dreamless...\n",
      "Loading cover for The Oâ€™Rahilly: A Secret Histor...\n",
      "âœ“ Loaded cover for The Oâ€™Rahilly: A Sec...\n",
      "Loading cover for The Long March: The true story...\n",
      "âœ“ Loaded cover for The Long March: The ...\n",
      "Loading cover for Tiy and the Prince of Egypt...\n",
      "âœ“ Loaded cover for Tiy and the Prince o...\n",
      "Loading cover for Empires at War: A Short Histor...\n",
      "âœ“ Loaded cover for Empires at War: A Sh...\n",
      "Loading cover for This Change Is Everything...\n",
      "âœ“ Loaded cover for This Change Is Every...\n",
      "Loading cover for Joseph's Story...\n",
      "âœ“ Loaded cover for Joseph's Story...\n",
      "Loading cover for Treasure Mountain...\n",
      "âœ“ Loaded cover for Treasure Mountain...\n",
      "Loading cover for The Folk of the Fringe...\n",
      "âœ“ Loaded cover for The Folk of the Frin...\n",
      "\n",
      "âœ… ANALYSIS COMPLETE!\n",
      "ğŸ“Š Emotion charts saved to: emotion_charts/\n",
      "ğŸ“ˆ Detailed analysis saved to: emotion_analysis/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch-local/fharlaar.12213868/ipykernel_1134582/3713606440.py:974: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# Complete Image to Book Emotion Matching System\n",
    "# Merges image_url_large from preprocessed_books_2025_04_20.parquet\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchvision import models, transforms\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "from ast import literal_eval\n",
    "import unicodedata\n",
    "\n",
    "# Import artemis modules (same as your notebook)\n",
    "from artemis.emotions import ARTEMIS_EMOTIONS, IDX_TO_EMOTION\n",
    "from artemis.neural_models.resnet_encoder import ResnetEncoder\n",
    "from artemis.neural_models.mlp import MLP\n",
    "from artemis.neural_models.image_emotion_clf import ImageEmotionClassifier\n",
    "from artemis.in_out.neural_net_oriented import torch_load_model\n",
    "\n",
    "# Try to import FAISS for speed optimization\n",
    "try:\n",
    "    import faiss\n",
    "    FAISS_AVAILABLE = True\n",
    "    print(\"âœ“ FAISS available for ultra-fast similarity search\")\n",
    "except ImportError:\n",
    "    FAISS_AVAILABLE = False\n",
    "    print(\"âš  FAISS not installed. Install with: pip install faiss-gpu (or faiss-cpu)\")\n",
    "    print(\"  This will provide 10-100x speedup for large datasets\")\n",
    "\n",
    "# Configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Updated Paths\n",
    "RESNET_MODEL_PATH = r'data/artemis/predictions/best_model_good_data.pt'\n",
    "BOOK_RESNET_PARQUET = r'goodreads_emotion_results/goodreads_emotion_predictions_english.parquet'\n",
    "BOOK_BERT_PARQUET = r'goodreads_bert_emotion_results/goodreads_bert_emotion_predictions_20250604_160958.parquet'\n",
    "PREPROCESSED_BOOK_PARQUET = r'preprocessed_books_2025_04_20.parquet'\n",
    "\n",
    "class CompleteImageBookMatcher:\n",
    "    \"\"\"\n",
    "    Complete system for matching image emotions with book emotion distributions\n",
    "    Merges image_url_large from original preprocessed books data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, use_gpu_similarity=True, precompute_indices=True):\n",
    "        self.emotion_labels = ARTEMIS_EMOTIONS\n",
    "        self.num_emotions = len(self.emotion_labels)\n",
    "        self.device = device\n",
    "        self.use_gpu_similarity = use_gpu_similarity and torch.cuda.is_available()\n",
    "        self.use_faiss = FAISS_AVAILABLE\n",
    "        \n",
    "        # Emotion column mapping based on your parquet structure\n",
    "        self.emotion_columns = [\n",
    "            'prob_amusement', 'prob_anger', 'prob_awe', 'prob_contentment',\n",
    "            'prob_disgust', 'prob_excitement', 'prob_fear', 'prob_sadness',\n",
    "            'prob_something_else'\n",
    "        ]\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "        print(\"INITIALIZING COMPLETE IMAGE-BOOK EMOTION MATCHING SYSTEM\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Load ResNet model (same architecture as your notebook)\n",
    "        print(\"Loading ResNet model...\")\n",
    "        self.resnet_model = self._load_resnet_model()\n",
    "        \n",
    "        # Load and preprocess book data with image URLs\n",
    "        print(\"Loading and preprocessing book emotion distributions with image URLs...\")\n",
    "        self.book_resnet_df, self.book_bert_df = self._load_book_data_with_images()\n",
    "        \n",
    "        # Precompute emotion matrices for fast similarity\n",
    "        print(\"Precomputing emotion matrices for fast similarity...\")\n",
    "        self._precompute_emotion_matrices()\n",
    "        \n",
    "        # Setup FAISS indices for ultra-fast similarity search\n",
    "        if precompute_indices and self.use_faiss:\n",
    "            print(\"Building FAISS indices for similarity search...\")\n",
    "            self._build_faiss_indices()\n",
    "        \n",
    "        # Image preprocessing (same as your notebook)\n",
    "        self.image_transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),  # Same as your notebook\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        print(f\"âœ“ System ready! Loaded {len(self.book_resnet_df)} books for matching\")\n",
    "        print(\"=\"*80)\n",
    "    \n",
    "    def _load_resnet_model(self):\n",
    "        \"\"\"Load ResNet model using exact same approach as your notebook\"\"\"\n",
    "        try:\n",
    "            # Load model exactly as in your notebook\n",
    "            model = torch_load_model(RESNET_MODEL_PATH)\n",
    "            model.to(self.device)\n",
    "            model.eval()\n",
    "            \n",
    "            # Test the model with a dummy input to make sure it works\n",
    "            with torch.no_grad():\n",
    "                dummy_input = torch.randn(1, 3, 256, 256).to(self.device)\n",
    "                _ = model(dummy_input)\n",
    "            \n",
    "            print(\"âœ“ ResNet model loaded and tested successfully\")\n",
    "            return model\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading ResNet model: {e}\")\n",
    "            print(\"Creating dummy ResNet for testing...\")\n",
    "            return self._create_dummy_resnet()\n",
    "    \n",
    "    def _create_dummy_resnet(self):\n",
    "        \"\"\"Create dummy ResNet for testing if model loading fails\"\"\"\n",
    "        print(\"âš  Using dummy ResNet model for testing\")\n",
    "        model = models.resnet34(weights='IMAGENET1K_V1')\n",
    "        model.fc = nn.Linear(model.fc.in_features, self.num_emotions)\n",
    "        model.to(self.device)\n",
    "        model.eval()\n",
    "        return model\n",
    "    \n",
    "    def _load_book_data_with_images(self):\n",
    "        \"\"\"Load book data and merge with image URLs from preprocessed books\"\"\"\n",
    "        try:\n",
    "            print(\"Loading preprocessed books data for image URLs...\")\n",
    "            # Load only book_id and image_url_large from preprocessed books\n",
    "            preprocessed_df = pd.read_parquet(PREPROCESSED_BOOK_PARQUET, \n",
    "                                            columns=['book_id', 'image_url_large', 'description'])\n",
    "            print(f\"âœ“ Loaded {len(preprocessed_df)} books from preprocessed data\")\n",
    "            print(f\"âœ“ Found {len(preprocessed_df[preprocessed_df['image_url_large'].notna()])} books with image URLs\")\n",
    "            \n",
    "            # Load emotion prediction data\n",
    "            print(\"Loading ResNet emotion predictions...\")\n",
    "            book_resnet_df = pd.read_parquet(BOOK_RESNET_PARQUET)\n",
    "            \n",
    "            print(\"Loading BERT emotion predictions...\")\n",
    "            book_bert_df = pd.read_parquet(BOOK_BERT_PARQUET)\n",
    "            \n",
    "            print(f\"âœ“ Loaded ResNet emotions for {len(book_resnet_df)} books\")\n",
    "            print(f\"âœ“ Loaded BERT emotions for {len(book_bert_df)} books\")\n",
    "            \n",
    "            # Merge with image URLs\n",
    "            print(\"Merging ResNet data with image URLs...\")\n",
    "            book_resnet_df = book_resnet_df.merge(\n",
    "                preprocessed_df[['book_id', 'image_url_large', 'description']], \n",
    "                on='book_id', \n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            print(\"Merging BERT data with image URLs...\")\n",
    "            book_bert_df = book_bert_df.merge(\n",
    "                preprocessed_df[['book_id', 'image_url_large', 'description']], \n",
    "                on='book_id', \n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            # Keep only books that exist in both datasets for multimodal comparison\n",
    "            common_book_ids = set(book_resnet_df['book_id']).intersection(\n",
    "                set(book_bert_df['book_id'])\n",
    "            )\n",
    "            \n",
    "            book_resnet_df = book_resnet_df[book_resnet_df['book_id'].isin(common_book_ids)]\n",
    "            book_bert_df = book_bert_df[book_bert_df['book_id'].isin(common_book_ids)]\n",
    "            \n",
    "            # Sort by book_id for faster merging later\n",
    "            book_resnet_df = book_resnet_df.sort_values('book_id').reset_index(drop=True)\n",
    "            book_bert_df = book_bert_df.sort_values('book_id').reset_index(drop=True)\n",
    "            \n",
    "            # Count books with image URLs\n",
    "            resnet_with_images = len(book_resnet_df[book_resnet_df['image_url_large'].notna()])\n",
    "            bert_with_images = len(book_bert_df[book_bert_df['image_url_large'].notna()])\n",
    "            \n",
    "            print(f\"âœ“ Final dataset: {len(book_resnet_df)} books with both ResNet and BERT predictions\")\n",
    "            print(f\"âœ“ ResNet books with image URLs: {resnet_with_images}\")\n",
    "            print(f\"âœ“ BERT books with image URLs: {bert_with_images}\")\n",
    "            \n",
    "            return book_resnet_df, book_bert_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading book data: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return self._create_dummy_book_data()\n",
    "    \n",
    "    def _create_dummy_book_data(self):\n",
    "        \"\"\"Create dummy book data for testing\"\"\"\n",
    "        print(\"âš  Creating dummy book data for testing\")\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        n_books = 1000  # Smaller for testing\n",
    "        book_ids = [f\"book_{i}\" for i in range(n_books)]\n",
    "        titles = [f\"Test Book Title {i}\" for i in range(n_books)]\n",
    "        authors = [[{'author_id': str(i), 'role': f'Test Author {i}'}] for i in range(n_books)]\n",
    "        \n",
    "        # Create dummy emotion probabilities\n",
    "        emotion_probs = np.random.dirichlet(np.ones(self.num_emotions), n_books)\n",
    "        \n",
    "        # Create ResNet dataframe\n",
    "        resnet_data = {\n",
    "            'book_id': book_ids,\n",
    "            'title': titles,\n",
    "            'authors': authors,\n",
    "            'average_rating': np.random.uniform(3.0, 5.0, n_books),\n",
    "            'predicted_emotion': [self.emotion_labels[np.argmax(probs)] for probs in emotion_probs],\n",
    "            'confidence': [np.max(probs) for probs in emotion_probs],\n",
    "            'image_url_large': [f'https://example.com/cover_{i}.jpg' for i in range(n_books)]\n",
    "        }\n",
    "        \n",
    "        # Add emotion probability columns\n",
    "        for i, col in enumerate(self.emotion_columns):\n",
    "            resnet_data[col] = emotion_probs[:, i]\n",
    "        \n",
    "        resnet_df = pd.DataFrame(resnet_data)\n",
    "        \n",
    "        # Create BERT dataframe (different emotion distributions)\n",
    "        bert_emotion_probs = np.random.dirichlet(np.ones(self.num_emotions), n_books)\n",
    "        bert_data = resnet_data.copy()\n",
    "        bert_data['predicted_emotion'] = [self.emotion_labels[np.argmax(probs)] for probs in bert_emotion_probs]\n",
    "        bert_data['confidence'] = [np.max(probs) for probs in bert_emotion_probs]\n",
    "        \n",
    "        for i, col in enumerate(self.emotion_columns):\n",
    "            bert_data[col] = bert_emotion_probs[:, i]\n",
    "        \n",
    "        bert_df = pd.DataFrame(bert_data)\n",
    "        \n",
    "        return resnet_df, bert_df\n",
    "    \n",
    "    def _precompute_emotion_matrices(self):\n",
    "        \"\"\"Precompute emotion matrices for vectorized operations\"\"\"\n",
    "        # Extract emotion matrices as numpy arrays for fast computation\n",
    "        self.resnet_emotions_matrix = self.book_resnet_df[self.emotion_columns].values.astype(np.float32)\n",
    "        self.bert_emotions_matrix = self.book_bert_df[self.emotion_columns].values.astype(np.float32)\n",
    "        \n",
    "        # Extract confidence arrays\n",
    "        self.resnet_confidences = self.book_resnet_df['confidence'].values.astype(np.float32)\n",
    "        self.bert_confidences = self.book_bert_df['confidence'].values.astype(np.float32)\n",
    "        \n",
    "        # Precompute combined emotions for all books\n",
    "        print(\"Precomputing multimodal combinations...\")\n",
    "        self._precompute_multimodal_emotions()\n",
    "        \n",
    "        # Convert to GPU tensors if using GPU acceleration\n",
    "        if self.use_gpu_similarity:\n",
    "            print(\"Moving emotion matrices to GPU for fast similarity...\")\n",
    "            self.resnet_emotions_gpu = torch.from_numpy(self.resnet_emotions_matrix).to(self.device)\n",
    "            self.bert_emotions_gpu = torch.from_numpy(self.bert_emotions_matrix).to(self.device)\n",
    "            self.multimodal_emotions_gpu = torch.from_numpy(self.multimodal_emotions_matrix).to(self.device)\n",
    "    \n",
    "    def _precompute_multimodal_emotions(self):\n",
    "        \"\"\"Precompute confidence-weighted combinations for all books\"\"\"\n",
    "        # Vectorized confidence weighting\n",
    "        total_confidences = self.resnet_confidences + self.bert_confidences\n",
    "        resnet_weights = self.resnet_confidences / total_confidences\n",
    "        bert_weights = self.bert_confidences / total_confidences\n",
    "        \n",
    "        # Vectorized combination\n",
    "        self.multimodal_emotions_matrix = (\n",
    "            resnet_weights[:, np.newaxis] * self.resnet_emotions_matrix +\n",
    "            bert_weights[:, np.newaxis] * self.bert_emotions_matrix\n",
    "        )\n",
    "        \n",
    "        # Normalize to ensure proper probability distributions\n",
    "        row_sums = self.multimodal_emotions_matrix.sum(axis=1, keepdims=True)\n",
    "        self.multimodal_emotions_matrix = self.multimodal_emotions_matrix / row_sums\n",
    "        \n",
    "        # Store weights for later use\n",
    "        self.resnet_weights = resnet_weights\n",
    "        self.bert_weights = bert_weights\n",
    "    \n",
    "    def _build_faiss_indices(self):\n",
    "        \"\"\"Build FAISS indices for ultra-fast similarity search\"\"\"\n",
    "        if not FAISS_AVAILABLE:\n",
    "            self.use_faiss = False\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            # Build indices for each emotion type\n",
    "            dimension = self.num_emotions\n",
    "            \n",
    "            # ResNet index\n",
    "            self.resnet_index = faiss.IndexFlatIP(dimension)  # Inner product (cosine after normalization)\n",
    "            resnet_normalized = self.resnet_emotions_matrix / np.linalg.norm(\n",
    "                self.resnet_emotions_matrix, axis=1, keepdims=True\n",
    "            )\n",
    "            self.resnet_index.add(resnet_normalized.astype('float32'))\n",
    "            \n",
    "            # BERT index\n",
    "            self.bert_index = faiss.IndexFlatIP(dimension)\n",
    "            bert_normalized = self.bert_emotions_matrix / np.linalg.norm(\n",
    "                self.bert_emotions_matrix, axis=1, keepdims=True\n",
    "            )\n",
    "            self.bert_index.add(bert_normalized.astype('float32'))\n",
    "            \n",
    "            # Multimodal index\n",
    "            self.multimodal_index = faiss.IndexFlatIP(dimension)\n",
    "            multimodal_normalized = self.multimodal_emotions_matrix / np.linalg.norm(\n",
    "                self.multimodal_emotions_matrix, axis=1, keepdims=True\n",
    "            )\n",
    "            self.multimodal_index.add(multimodal_normalized.astype('float32'))\n",
    "            \n",
    "            # Move to GPU if available\n",
    "            if faiss.get_num_gpus() > 0:\n",
    "                self.resnet_index = faiss.index_cpu_to_gpu(faiss.StandardGpuResources(), 0, self.resnet_index)\n",
    "                self.bert_index = faiss.index_cpu_to_gpu(faiss.StandardGpuResources(), 0, self.bert_index)\n",
    "                self.multimodal_index = faiss.index_cpu_to_gpu(faiss.StandardGpuResources(), 0, self.multimodal_index)\n",
    "                print(\"âœ“ FAISS indices moved to GPU\")\n",
    "            \n",
    "            self.use_faiss = True\n",
    "            print(\"âœ“ FAISS indices built successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error building FAISS indices: {e}\")\n",
    "            self.use_faiss = False\n",
    "    \n",
    "    def predict_image_emotions(self, image_path):\n",
    "        \"\"\"Predict emotions for an input image using ResNet (same as your notebook)\"\"\"\n",
    "        try:\n",
    "            # Load and preprocess image (same as notebook preprocessing)\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image_tensor = self.image_transform(image).unsqueeze(0).to(self.device)\n",
    "            \n",
    "            # Fast inference with no gradient computation\n",
    "            with torch.no_grad():\n",
    "                # Model outputs log probabilities (LogSoftmax), so we need to exp them\n",
    "                log_probs = self.resnet_model(image_tensor)\n",
    "                probs = torch.exp(log_probs).cpu().numpy()[0]  # Convert to probabilities\n",
    "                confidence = float(torch.max(torch.exp(log_probs)).cpu())\n",
    "            \n",
    "            return {\n",
    "                'emotion_distribution': probs,\n",
    "                'confidence': confidence,\n",
    "                'dominant_emotion': self.emotion_labels[np.argmax(probs)],\n",
    "                'emotion_scores': dict(zip(self.emotion_labels, probs))\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting image emotions: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "            uniform_probs = np.ones(self.num_emotions) / self.num_emotions\n",
    "            return {\n",
    "                'emotion_distribution': uniform_probs,\n",
    "                'confidence': 1.0 / self.num_emotions,\n",
    "                'dominant_emotion': self.emotion_labels[0],\n",
    "                'emotion_scores': dict(zip(self.emotion_labels, uniform_probs))\n",
    "            }\n",
    "    \n",
    "    def fast_similarity_search(self, image_emotions, top_k=1000):\n",
    "        \"\"\"Ultra-fast similarity search using FAISS or GPU acceleration\"\"\"\n",
    "        if self.use_faiss:\n",
    "            return self._faiss_similarity_search(image_emotions, top_k)\n",
    "        elif self.use_gpu_similarity:\n",
    "            return self._gpu_similarity_search(image_emotions, top_k)\n",
    "        else:\n",
    "            return self._cpu_similarity_search(image_emotions, top_k)\n",
    "    \n",
    "    def _faiss_similarity_search(self, image_emotions, top_k):\n",
    "        \"\"\"FAISS-based similarity search (fastest)\"\"\"\n",
    "        # Normalize query\n",
    "        query = image_emotions / np.linalg.norm(image_emotions)\n",
    "        query = query.reshape(1, -1).astype('float32')\n",
    "        \n",
    "        # Search all three indices\n",
    "        resnet_scores, resnet_indices = self.resnet_index.search(query, top_k)\n",
    "        bert_scores, bert_indices = self.bert_index.search(query, top_k)\n",
    "        multimodal_scores, multimodal_indices = self.multimodal_index.search(query, top_k)\n",
    "        \n",
    "        return {\n",
    "            'resnet': {'scores': resnet_scores[0], 'indices': resnet_indices[0]},\n",
    "            'bert': {'scores': bert_scores[0], 'indices': bert_indices[0]},\n",
    "            'multimodal': {'scores': multimodal_scores[0], 'indices': multimodal_indices[0]}\n",
    "        }\n",
    "    \n",
    "    def _gpu_similarity_search(self, image_emotions, top_k):\n",
    "        \"\"\"GPU-accelerated similarity search\"\"\"\n",
    "        # Convert to GPU tensor\n",
    "        image_tensor = torch.from_numpy(image_emotions).to(self.device).float()\n",
    "        image_tensor = image_tensor / torch.norm(image_tensor)  # Normalize\n",
    "        \n",
    "        # Compute similarities using matrix multiplication\n",
    "        resnet_similarities = torch.mm(image_tensor.unsqueeze(0), self.resnet_emotions_gpu.t()).squeeze()\n",
    "        bert_similarities = torch.mm(image_tensor.unsqueeze(0), self.bert_emotions_gpu.t()).squeeze()\n",
    "        multimodal_similarities = torch.mm(image_tensor.unsqueeze(0), self.multimodal_emotions_gpu.t()).squeeze()\n",
    "        \n",
    "        # Get top-k\n",
    "        resnet_top_k = torch.topk(resnet_similarities, min(top_k, len(resnet_similarities)))\n",
    "        bert_top_k = torch.topk(bert_similarities, min(top_k, len(bert_similarities)))\n",
    "        multimodal_top_k = torch.topk(multimodal_similarities, min(top_k, len(multimodal_similarities)))\n",
    "        \n",
    "        return {\n",
    "            'resnet': {\n",
    "                'scores': resnet_top_k.values.cpu().numpy(),\n",
    "                'indices': resnet_top_k.indices.cpu().numpy()\n",
    "            },\n",
    "            'bert': {\n",
    "                'scores': bert_top_k.values.cpu().numpy(), \n",
    "                'indices': bert_top_k.indices.cpu().numpy()\n",
    "            },\n",
    "            'multimodal': {\n",
    "                'scores': multimodal_top_k.values.cpu().numpy(),\n",
    "                'indices': multimodal_top_k.indices.cpu().numpy()\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _cpu_similarity_search(self, image_emotions, top_k):\n",
    "        \"\"\"CPU-based similarity search (fallback)\"\"\"\n",
    "        # Compute cosine similarities\n",
    "        resnet_similarities = cosine_similarity([image_emotions], self.resnet_emotions_matrix)[0]\n",
    "        bert_similarities = cosine_similarity([image_emotions], self.bert_emotions_matrix)[0]\n",
    "        multimodal_similarities = cosine_similarity([image_emotions], self.multimodal_emotions_matrix)[0]\n",
    "        \n",
    "        # Get top-k indices\n",
    "        resnet_top_indices = np.argpartition(resnet_similarities, -top_k)[-top_k:]\n",
    "        bert_top_indices = np.argpartition(bert_similarities, -top_k)[-top_k:]\n",
    "        multimodal_top_indices = np.argpartition(multimodal_similarities, -top_k)[-top_k:]\n",
    "        \n",
    "        # Sort by similarity\n",
    "        resnet_top_indices = resnet_top_indices[np.argsort(resnet_similarities[resnet_top_indices])[::-1]]\n",
    "        bert_top_indices = bert_top_indices[np.argsort(bert_similarities[bert_top_indices])[::-1]]\n",
    "        multimodal_top_indices = multimodal_top_indices[np.argsort(multimodal_similarities[multimodal_top_indices])[::-1]]\n",
    "        \n",
    "        return {\n",
    "            'resnet': {\n",
    "                'scores': resnet_similarities[resnet_top_indices],\n",
    "                'indices': resnet_top_indices\n",
    "            },\n",
    "            'bert': {\n",
    "                'scores': bert_similarities[bert_top_indices],\n",
    "                'indices': bert_top_indices\n",
    "            },\n",
    "            'multimodal': {\n",
    "                'scores': multimodal_similarities[multimodal_top_indices],\n",
    "                'indices': multimodal_top_indices\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def find_similar_books_complete(self, image_path, top_k=1000, final_n=3):\n",
    "        \"\"\"Complete book similarity search with all optimizations\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Predict image emotions\n",
    "        image_prediction = self.predict_image_emotions(image_path)\n",
    "        image_emotions = image_prediction['emotion_distribution']\n",
    "        \n",
    "        print(f\"Image prediction took {time.time() - start_time:.3f}s\")\n",
    "        print(f\"Image dominant emotion: {image_prediction['dominant_emotion']}\")\n",
    "        print(f\"Image confidence: {image_prediction['confidence']:.3f}\")\n",
    "        \n",
    "        # Fast similarity search\n",
    "        search_start = time.time()\n",
    "        search_results = self.fast_similarity_search(image_emotions, top_k)\n",
    "        print(f\"Similarity search took {time.time() - search_start:.3f}s\")\n",
    "        \n",
    "        # Extract top recommendations for each approach\n",
    "        def extract_recommendations(scores, indices, approach_name):\n",
    "            recommendations = []\n",
    "            for i, (score, idx) in enumerate(zip(scores[:final_n*3], indices[:final_n*3])):\n",
    "                book_row = self.book_resnet_df.iloc[idx]  # Use ResNet df for metadata\n",
    "                bert_row = self.book_bert_df.iloc[idx]    # Get BERT data for emotions\n",
    "                \n",
    "                recommendations.append({\n",
    "                    'rank': i + 1,\n",
    "                    'book_id': book_row['book_id'],\n",
    "                    'title': book_row['title'],\n",
    "                    'authors': book_row['authors'],\n",
    "                    'average_rating': book_row.get('average_rating', 'N/A'),\n",
    "                    'similarity_score': float(score),\n",
    "                    'approach': approach_name,\n",
    "                    'resnet_predicted_emotion': book_row['predicted_emotion'],\n",
    "                    'bert_predicted_emotion': bert_row['predicted_emotion'],\n",
    "                    'image_url_large': book_row.get('image_url_large', 'No cover URL'),\n",
    "                    'description': book_row.get('description', None)\n",
    "                })\n",
    "            \n",
    "            # Return top, middle, bottom\n",
    "            total = len(recommendations)\n",
    "            top_n = recommendations[:final_n]\n",
    "            middle_start = max(0, (total // 2) - (final_n // 2))\n",
    "            middle_n = recommendations[middle_start:middle_start + final_n]\n",
    "            bottom_n = recommendations[-final_n:]\n",
    "            \n",
    "            return top_n, middle_n, bottom_n\n",
    "        \n",
    "        # Extract recommendations for each approach\n",
    "        resnet_top, resnet_middle, resnet_bottom = extract_recommendations(\n",
    "            search_results['resnet']['scores'], search_results['resnet']['indices'], 'ResNet'\n",
    "        )\n",
    "        \n",
    "        bert_top, bert_middle, bert_bottom = extract_recommendations(\n",
    "            search_results['bert']['scores'], search_results['bert']['indices'], 'BERT'\n",
    "        )\n",
    "        \n",
    "        multimodal_top, multimodal_middle, multimodal_bottom = extract_recommendations(\n",
    "            search_results['multimodal']['scores'], search_results['multimodal']['indices'], 'Multimodal'\n",
    "        )\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"Total processing time: {total_time:.3f}s for {len(self.book_resnet_df)} books\")\n",
    "        \n",
    "        return {\n",
    "            'image_prediction': image_prediction,\n",
    "            'processing_time': total_time,\n",
    "            'resnet_recommendations': {\n",
    "                'top': resnet_top,\n",
    "                'middle': resnet_middle,\n",
    "                'bottom': resnet_bottom\n",
    "            },\n",
    "            'bert_recommendations': {\n",
    "                'top': bert_top,\n",
    "                'middle': bert_middle,\n",
    "                'bottom': bert_bottom\n",
    "            },\n",
    "            'multimodal_recommendations': {\n",
    "                'top': multimodal_top,\n",
    "                'middle': multimodal_middle,\n",
    "                'bottom': multimodal_bottom\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def display_emotion_distributions(self, results, show_plots=True):\n",
    "        \"\"\"Display and compare emotion distributions between image and recommendations\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"ğŸ­\" * 80)\n",
    "        print(\"EMOTION DISTRIBUTION ANALYSIS\")\n",
    "        print(\"ğŸ­\" * 80)\n",
    "        \n",
    "        # Get image emotion distribution\n",
    "        image_emotions = results['image_prediction']['emotion_distribution']\n",
    "        image_scores = results['image_prediction']['emotion_scores']\n",
    "        \n",
    "        print(f\"\\nğŸ“¸ INPUT IMAGE EMOTION DISTRIBUTION:\")\n",
    "        print(f\"   Dominant: {results['image_prediction']['dominant_emotion']} (confidence: {results['image_prediction']['confidence']:.3f})\")\n",
    "        print(\"   Full Distribution:\")\n",
    "        \n",
    "        # Display image emotions in a nice format\n",
    "        for emotion, score in image_scores.items():\n",
    "            bar_length = int(score * 50)  # Scale to 50 characters\n",
    "            bar = \"â–ˆ\" * bar_length + \"â–‘\" * (50 - bar_length)\n",
    "            print(f\"   {emotion:15s} â”‚{bar}â”‚ {score:.3f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"â”€\" * 80)\n",
    "        \n",
    "        # Compare with top recommendations from each approach\n",
    "        approaches = [\n",
    "            ('ğŸ§  RESNET RECOMMENDATIONS', results['resnet_recommendations']),\n",
    "            ('ğŸ“ BERT RECOMMENDATIONS', results['bert_recommendations']), \n",
    "            ('ğŸ”— MULTIMODAL RECOMMENDATIONS', results['multimodal_recommendations'])\n",
    "        ]\n",
    "        \n",
    "        for approach_name, recommendations in approaches:\n",
    "            print(f\"\\n{approach_name}\")\n",
    "            print(\"â”€\" * 80)\n",
    "            \n",
    "            # Show top 3 books from this approach\n",
    "            for i, book in enumerate(recommendations['top'], 1):\n",
    "                print(f\"\\nğŸ“š {i}. {book['title'][:50]}{'...' if len(book['title']) > 50 else ''}\")\n",
    "                print(f\"   ğŸ“Š Similarity Score: {book['similarity_score']:.4f}\")\n",
    "                print(f\"   ğŸ¯ Predicted Emotion: {book.get('resnet_predicted_emotion', 'N/A')}\")\n",
    "                \n",
    "                # Get book's emotion distribution\n",
    "                book_idx = self._get_book_index(book['book_id'])\n",
    "                if book_idx is not None:\n",
    "                    if 'resnet' in approach_name.lower():\n",
    "                        book_emotions = self.resnet_emotions_matrix[book_idx]\n",
    "                    elif 'bert' in approach_name.lower():\n",
    "                        book_emotions = self.bert_emotions_matrix[book_idx]\n",
    "                    else:  # multimodal\n",
    "                        book_emotions = self.multimodal_emotions_matrix[book_idx]\n",
    "                    \n",
    "                    print(f\"   ğŸ“ˆ Book Emotion Distribution:\")\n",
    "                    \n",
    "                    # Calculate similarity metrics\n",
    "                    cosine_sim = np.dot(image_emotions, book_emotions) / (\n",
    "                        np.linalg.norm(image_emotions) * np.linalg.norm(book_emotions))\n",
    "                    kl_div = self._calculate_kl_divergence(image_emotions, book_emotions)\n",
    "                    \n",
    "                    print(f\"   ğŸ” Cosine Similarity: {cosine_sim:.4f}\")\n",
    "                    print(f\"   ğŸ“ KL Divergence: {kl_div:.4f}\")\n",
    "                    \n",
    "                    # Show emotion-by-emotion comparison\n",
    "                    for j, emotion in enumerate(self.emotion_labels):\n",
    "                        img_score = image_emotions[j]\n",
    "                        book_score = book_emotions[j]\n",
    "                        diff = book_score - img_score\n",
    "                        \n",
    "                        # Visual bars\n",
    "                        img_bar_length = int(img_score * 30)\n",
    "                        book_bar_length = int(book_score * 30)\n",
    "                        img_bar = \"â–ˆ\" * img_bar_length + \"â–‘\" * (30 - img_bar_length)\n",
    "                        book_bar = \"â–ˆ\" * book_bar_length + \"â–‘\" * (30 - book_bar_length)\n",
    "                        \n",
    "                        # Color code the difference\n",
    "                        if abs(diff) < 0.05:\n",
    "                            diff_icon = \"â‰ˆ\"\n",
    "                        elif diff > 0:\n",
    "                            diff_icon = \"â†—\"\n",
    "                        else:\n",
    "                            diff_icon = \"â†˜\"\n",
    "                        \n",
    "                        print(f\"   {emotion:13s} â”‚Img:{img_bar}â”‚{img_score:.3f} â”‚Book:{book_bar}â”‚{book_score:.3f} {diff_icon}\")\n",
    "                    \n",
    "                    print(\"   \" + \"â”€\" * 70)\n",
    "        \n",
    "        # Create visualization plots if requested\n",
    "        if show_plots:\n",
    "            self._create_emotion_distribution_plots(results)\n",
    "    \n",
    "    def _get_book_index(self, book_id):\n",
    "        \"\"\"Get the index of a book in the dataframe by book_id\"\"\"\n",
    "        try:\n",
    "            # Find index in resnet dataframe (they should be aligned)\n",
    "            mask = self.book_resnet_df['book_id'] == book_id\n",
    "            indices = np.where(mask)[0]\n",
    "            if len(indices) > 0:\n",
    "                return indices[0]\n",
    "            return None\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def _calculate_kl_divergence(self, p, q, epsilon=1e-8):\n",
    "        \"\"\"Calculate KL divergence between two probability distributions\"\"\"\n",
    "        # Add small epsilon to avoid log(0)\n",
    "        p = np.clip(p, epsilon, 1.0)\n",
    "        q = np.clip(q, epsilon, 1.0)\n",
    "        \n",
    "        # Normalize to ensure they sum to 1\n",
    "        p = p / np.sum(p)\n",
    "        q = q / np.sum(q)\n",
    "        \n",
    "        return np.sum(p * np.log(p / q))\n",
    "    \n",
    "    def _create_emotion_distribution_plots(self, results):\n",
    "        \"\"\"Create visual plots comparing emotion distributions\"\"\"\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            import seaborn as sns\n",
    "            \n",
    "            # Set up the plotting style\n",
    "            plt.style.use('default')\n",
    "            sns.set_palette(\"husl\")\n",
    "            \n",
    "            # Create subplots: 2 rows x 2 cols\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "            fig.suptitle('Emotion Distribution Comparison', fontsize=16, fontweight='bold')\n",
    "            \n",
    "            # Get image emotions\n",
    "            image_emotions = results['image_prediction']['emotion_distribution']\n",
    "            \n",
    "            # Plot 1: Image emotion distribution\n",
    "            ax1 = axes[0, 0]\n",
    "            bars1 = ax1.bar(self.emotion_labels, image_emotions, alpha=0.7, color='skyblue')\n",
    "            ax1.set_title(f\"Input Image\\n(Dominant: {results['image_prediction']['dominant_emotion']})\", \n",
    "                         fontweight='bold')\n",
    "            ax1.set_ylabel('Probability')\n",
    "            ax1.tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar, val in zip(bars1, image_emotions):\n",
    "                ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                        f'{val:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "            \n",
    "            # Plot 2-4: Top recommendation from each approach\n",
    "            approaches = [\n",
    "                ('ResNet Top Match', results['resnet_recommendations']['top'][0], self.resnet_emotions_matrix),\n",
    "                ('BERT Top Match', results['bert_recommendations']['top'][0], self.bert_emotions_matrix),\n",
    "                ('Multimodal Top Match', results['multimodal_recommendations']['top'][0], self.multimodal_emotions_matrix)\n",
    "            ]\n",
    "            \n",
    "            ax_positions = [(0, 1), (1, 0), (1, 1)]\n",
    "            colors = ['lightcoral', 'lightgreen', 'lightsalmon']\n",
    "            \n",
    "            for i, ((title, book, emotion_matrix), ax_pos, color) in enumerate(zip(approaches, ax_positions, colors)):\n",
    "                ax = axes[ax_pos[0], ax_pos[1]]\n",
    "                \n",
    "                # Get book emotions\n",
    "                book_idx = self._get_book_index(book['book_id'])\n",
    "                if book_idx is not None:\n",
    "                    book_emotions = emotion_matrix[book_idx]\n",
    "                    \n",
    "                    # Create comparison bars\n",
    "                    x = np.arange(len(self.emotion_labels))\n",
    "                    width = 0.35\n",
    "                    \n",
    "                    bars1 = ax.bar(x - width/2, image_emotions, width, label='Input Image', \n",
    "                                  alpha=0.7, color='skyblue')\n",
    "                    bars2 = ax.bar(x + width/2, book_emotions, width, label='Book', \n",
    "                                  alpha=0.7, color=color)\n",
    "                    \n",
    "                    # Formatting\n",
    "                    book_title = book['title'][:25] + '...' if len(book['title']) > 25 else book['title']\n",
    "                    ax.set_title(f\"{title}\\n{book_title}\\nSim: {book['similarity_score']:.3f}\", \n",
    "                               fontweight='bold', fontsize=10)\n",
    "                    ax.set_ylabel('Probability')\n",
    "                    ax.set_xticks(x)\n",
    "                    ax.set_xticklabels(self.emotion_labels, rotation=45, ha='right')\n",
    "                    ax.legend()\n",
    "                    \n",
    "                    # Add difference annotations\n",
    "                    for j, (img_val, book_val) in enumerate(zip(image_emotions, book_emotions)):\n",
    "                        diff = book_val - img_val\n",
    "                        if abs(diff) > 0.1:  # Only show significant differences\n",
    "                            ax.annotate(f'{diff:+.2f}', \n",
    "                                      xy=(j, max(img_val, book_val) + 0.02),\n",
    "                                      ha='center', va='bottom', fontsize=8,\n",
    "                                      color='red' if diff > 0 else 'blue')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Create a heatmap comparison\n",
    "            self._create_emotion_heatmap(results)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Could not create emotion distribution plots: {e}\")\n",
    "            print(\"Install required packages: pip install matplotlib seaborn\")\n",
    "    \n",
    "    def _create_emotion_heatmap(self, results):\n",
    "        \"\"\"Create a heatmap showing emotion similarities across all recommendations\"\"\"\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            import seaborn as sns\n",
    "            \n",
    "            # Collect all emotion distributions\n",
    "            image_emotions = results['image_prediction']['emotion_distribution']\n",
    "            \n",
    "            # Get top recommendations from each approach\n",
    "            all_books = []\n",
    "            all_emotions = []\n",
    "            labels = ['Input Image']\n",
    "            all_emotions.append(image_emotions)\n",
    "            \n",
    "            approaches = [\n",
    "                ('ResNet', results['resnet_recommendations']['top'][:3], self.resnet_emotions_matrix),\n",
    "                ('BERT', results['bert_recommendations']['top'][:3], self.bert_emotions_matrix),\n",
    "                ('Multimodal', results['multimodal_recommendations']['top'][:3], self.multimodal_emotions_matrix)\n",
    "            ]\n",
    "            \n",
    "            for approach_name, books, emotion_matrix in approaches:\n",
    "                for i, book in enumerate(books, 1):\n",
    "                    book_idx = self._get_book_index(book['book_id'])\n",
    "                    if book_idx is not None:\n",
    "                        book_emotions = emotion_matrix[book_idx]\n",
    "                        all_emotions.append(book_emotions)\n",
    "                        \n",
    "                        book_title = book['title'][:20] + '...' if len(book['title']) > 20 else book['title']\n",
    "                        labels.append(f\"{approach_name}-{i}\\n{book_title}\")\n",
    "            \n",
    "            # Create emotion matrix\n",
    "            emotion_matrix = np.array(all_emotions)\n",
    "            \n",
    "            # Create heatmap\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            sns.heatmap(emotion_matrix, \n",
    "                       xticklabels=self.emotion_labels,\n",
    "                       yticklabels=labels,\n",
    "                       annot=True, \n",
    "                       fmt='.3f',\n",
    "                       cmap='YlOrRd',\n",
    "                       cbar_kws={'label': 'Emotion Probability'})\n",
    "            \n",
    "            plt.title('Emotion Distribution Heatmap\\nImage vs Top Book Recommendations', \n",
    "                     fontsize=14, fontweight='bold', pad=20)\n",
    "            plt.xlabel('Emotions', fontweight='bold')\n",
    "            plt.ylabel('Items', fontweight='bold')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.yticks(rotation=0)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Could not create emotion heatmap: {e}\")\n",
    "\n",
    "    def display_detailed_recommendations(self, results, show_covers=True, show_emotion_analysis=True, save_charts=True, save_dir=\"emotion_analysis\"):\n",
    "        \"\"\"Display detailed book recommendations with covers, descriptions, and emotion analysis\"\"\"\n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(\"DETAILED BOOK RECOMMENDATIONS WITH COVERS\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        # Image prediction summary\n",
    "        image_pred = results['image_prediction']\n",
    "        print(f\"\\nğŸ“¸ IMAGE ANALYSIS:\")\n",
    "        print(f\"   Dominant Emotion: {image_pred['dominant_emotion']}\")\n",
    "        print(f\"   Confidence: {image_pred['confidence']:.3f}\")\n",
    "        print(f\"   Processing Time: {results['processing_time']:.3f}s\")\n",
    "        \n",
    "        # Create and save emotion charts\n",
    "        if save_charts:\n",
    "            save_dir = \"emotion_analysis_2\"\n",
    "            chart_dir = self.create_emotion_bar_charts(results, show_plots=show_emotion_analysis, save_dir=save_dir)\n",
    "            detailed_analysis = self.create_detailed_emotion_report(results)\n",
    "        \n",
    "        # Show emotion distributions if requested\n",
    "        if show_emotion_analysis:\n",
    "            self.display_emotion_distributions(results, show_plots=False)  # Charts already shown above\n",
    "        \n",
    "        # All three approaches (rest of the existing code...)\n",
    "        approaches = [\n",
    "            ('ğŸ§  RESNET-ONLY RECOMMENDATIONS', results['resnet_recommendations'], 'lightcoral'),\n",
    "            ('ğŸ“ BERT-ONLY RECOMMENDATIONS', results['bert_recommendations'], 'lightgreen'), \n",
    "            ('ğŸ”— MULTIMODAL RECOMMENDATIONS', results['multimodal_recommendations'], 'lightblue')\n",
    "        ]\n",
    "        \n",
    "        for approach_name, recommendations, color in approaches:\n",
    "            print(f\"\\n{'='*30} {approach_name} {'='*30}\")\n",
    "            \n",
    "            categories = [\n",
    "                ('ğŸ† TOP 3 MOST SIMILAR', recommendations['top']),\n",
    "                ('ğŸ“Š MIDDLE 3 SIMILAR', recommendations['middle']),\n",
    "                ('ğŸ“‰ BOTTOM 3 LEAST SIMILAR', recommendations['bottom'])\n",
    "            ]\n",
    "            \n",
    "            for category_name, books in categories:\n",
    "                print(f\"\\n{category_name}\")\n",
    "                print(\"-\" * 80)\n",
    "                \n",
    "                for i, book in enumerate(books, 1):\n",
    "                    self._display_single_book(book, i, approach_name.split()[0])\n",
    "        \n",
    "        # Create a visual summary\n",
    "        if show_covers:\n",
    "            self._create_book_cover_visualization(results)\n",
    "    \n",
    "    def _display_single_book(self, book, rank, approach):\n",
    "        \"\"\"Display detailed information for a single book\"\"\"\n",
    "        \n",
    "        # Handle authors field (list of dicts from your parquet structure)\n",
    "        authors = book['authors']\n",
    "        if isinstance(authors, list) and len(authors) > 0:\n",
    "            try:\n",
    "                author_names = []\n",
    "                for author in authors[:3]:  # Show max 3 authors\n",
    "                    if isinstance(author, dict):\n",
    "                        author_name = author.get('role', 'Unknown Author')\n",
    "                        if not author_name or author_name == '':\n",
    "                            author_name = f\"Author ID: {author.get('author_id', 'Unknown')}\"\n",
    "                    else:\n",
    "                        author_name = str(author)\n",
    "                    author_names.append(author_name)\n",
    "                author_str = ', '.join(author_names)\n",
    "            except:\n",
    "                author_str = 'Unknown Author'\n",
    "        else:\n",
    "            author_str = 'Unknown Author'\n",
    "        \n",
    "        # Extract book information\n",
    "        title = book['title']\n",
    "        book_id = book['book_id']\n",
    "        similarity = book['similarity_score']\n",
    "        rating = book.get('average_rating', 'N/A')\n",
    "        \n",
    "        # Get emotion predictions\n",
    "        resnet_emotion = book.get('resnet_predicted_emotion', 'N/A')\n",
    "        bert_emotion = book.get('bert_predicted_emotion', 'N/A')\n",
    "        \n",
    "        # Use the actual image_url_large from your merged data\n",
    "        cover_url = book.get('image_url_large', 'No cover URL available')\n",
    "        \n",
    "        print(f\"\\n   {rank}. ğŸ“š {title}\")\n",
    "        print(f\"      ğŸ‘¤ Author(s): {author_str}\")\n",
    "        print(f\"      ğŸ†” Book ID: {book_id}\")\n",
    "        print(f\"      â­ Rating: {rating}\")\n",
    "        print(f\"      ğŸ¯ Similarity Score: {similarity:.4f}\")\n",
    "        print(f\"      ğŸ§  ResNet Emotion: {resnet_emotion}\")\n",
    "        print(f\"      ğŸ“ BERT Emotion: {bert_emotion}\")\n",
    "        print(f\"      ğŸ–¼ï¸  Cover URL: {cover_url}\")\n",
    "        \n",
    "        # Try to get book description\n",
    "        description = book.get('description', None)\n",
    "        if not description:\n",
    "            description = self._get_book_description(book_id, title, author_str)\n",
    "        \n",
    "        if description:\n",
    "            print(f\"      ğŸ“– Description: {description[:200]}...\")\n",
    "        else:\n",
    "            print(f\"      ğŸ“– Description: No description available\")\n",
    "        \n",
    "        print(\"      \" + \"â”€\" * 70)\n",
    "    \n",
    "    def _get_book_description(self, book_id, title, author):\n",
    "        \"\"\"Try to fetch book description from various APIs\"\"\"\n",
    "        try:\n",
    "            import requests\n",
    "            \n",
    "            # Search by title and author using Google Books API\n",
    "            search_query = f\"{title} {author}\".replace(' ', '+')\n",
    "            google_books_url = f\"https://www.googleapis.com/books/v1/volumes?q={search_query}&maxResults=1\"\n",
    "            \n",
    "            response = requests.get(google_books_url, timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                if 'items' in data and len(data['items']) > 0:\n",
    "                    volume_info = data['items'][0].get('volumeInfo', {})\n",
    "                    description = volume_info.get('description', '')\n",
    "                    if description:\n",
    "                        return description\n",
    "            \n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    def _create_book_cover_visualization(self, results):\n",
    "        \"\"\"Create a visualization grid showing actual book covers from image_url_large\"\"\"\n",
    "        try:\n",
    "            import requests\n",
    "            from io import BytesIO\n",
    "            \n",
    "            fig, axes = plt.subplots(3, 3, figsize=(15, 18))\n",
    "            fig.suptitle('Top Book Recommendations with Actual Covers', fontsize=16, fontweight='bold')\n",
    "            \n",
    "            # Get top book from each category of each approach\n",
    "            books_to_show = [\n",
    "                (results['resnet_recommendations']['top'][0], 'ResNet Top', 0, 0),\n",
    "                (results['bert_recommendations']['top'][0], 'BERT Top', 0, 1),\n",
    "                (results['multimodal_recommendations']['top'][0], 'Multimodal Top', 0, 2),\n",
    "                (results['resnet_recommendations']['middle'][0], 'ResNet Middle', 1, 0),\n",
    "                (results['bert_recommendations']['middle'][0], 'BERT Middle', 1, 1),\n",
    "                (results['multimodal_recommendations']['middle'][0], 'Multimodal Middle', 1, 2),\n",
    "                (results['resnet_recommendations']['bottom'][0], 'ResNet Bottom', 2, 0),\n",
    "                (results['bert_recommendations']['bottom'][0], 'BERT Bottom', 2, 1),\n",
    "                (results['multimodal_recommendations']['bottom'][0], 'Multimodal Bottom', 2, 2),\n",
    "            ]\n",
    "            \n",
    "            for book, label, row, col in books_to_show:\n",
    "                ax = axes[row, col]\n",
    "                \n",
    "                # Try to load actual book cover from image_url_large\n",
    "                try:\n",
    "                    cover_url = book.get('image_url_large', '')\n",
    "                    \n",
    "                    if cover_url and pd.notna(cover_url) and cover_url != 'No cover URL' and cover_url.startswith('http'):\n",
    "                        print(f\"Loading cover for {book['title'][:30]}...\")\n",
    "                        response = requests.get(cover_url, timeout=15, \n",
    "                                              headers={'User-Agent': 'Mozilla/5.0'})\n",
    "                        \n",
    "                        if response.status_code == 200:\n",
    "                            cover_image = Image.open(BytesIO(response.content))\n",
    "                            ax.imshow(cover_image)\n",
    "                            print(f\"âœ“ Loaded cover for {book['title'][:20]}...\")\n",
    "                        else:\n",
    "                            raise Exception(f\"HTTP {response.status_code}\")\n",
    "                    else:\n",
    "                        raise Exception(\"No valid URL\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Could not load cover for {book['title'][:20]}...: {e}\")\n",
    "                    # Create placeholder for failed loads\n",
    "                    placeholder = np.random.rand(300, 200, 3) * 0.3 + 0.7\n",
    "                    ax.imshow(placeholder)\n",
    "                    ax.text(0.5, 0.5, 'Cover\\nUnavailable', \n",
    "                           transform=ax.transAxes, ha='center', va='center',\n",
    "                           fontsize=12, fontweight='bold', \n",
    "                           bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "                \n",
    "                # Set title and details\n",
    "                title = book['title'][:25] + '...' if len(book['title']) > 25 else book['title']\n",
    "                similarity = book['similarity_score']\n",
    "                rating = book.get('average_rating', 'N/A')\n",
    "                \n",
    "                ax.set_title(f\"{label}\\n{title}\\nSim: {similarity:.3f} | â˜…{rating}\", \n",
    "                            fontsize=10, fontweight='bold', pad=10)\n",
    "                ax.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Could not create cover visualization: {e}\")\n",
    "            print(\"Install required packages: pip install pillow requests\")\n",
    "    \n",
    "    def get_book_urls_and_info(self, results, save_to_file=True):\n",
    "        \"\"\"Extract all book information and save to files\"\"\"\n",
    "        book_info = {\n",
    "            'image_analysis': results['image_prediction'],\n",
    "            'recommendations': {}\n",
    "        }\n",
    "        \n",
    "        approaches = ['resnet', 'bert', 'multimodal']\n",
    "        categories = ['top', 'middle', 'bottom']\n",
    "        \n",
    "        for approach in approaches:\n",
    "            book_info['recommendations'][approach] = {}\n",
    "            \n",
    "            for category in categories:\n",
    "                books = results[f'{approach}_recommendations'][category]\n",
    "                book_info['recommendations'][approach][category] = []\n",
    "                \n",
    "                for book in books:\n",
    "                    # Handle authors\n",
    "                    authors = book['authors']\n",
    "                    if isinstance(authors, list) and len(authors) > 0:\n",
    "                        try:\n",
    "                            author_names = [a.get('role', 'Unknown') if isinstance(a, dict) else str(a) for a in authors]\n",
    "                            author_str = ', '.join(author_names[:3])\n",
    "                        except:\n",
    "                            author_str = 'Unknown Author'\n",
    "                    else:\n",
    "                        author_str = 'Unknown Author'\n",
    "                    \n",
    "                    # Generate search URLs\n",
    "                    book_urls = {\n",
    "                        'actual_cover_url': book.get('image_url_large', 'No cover URL'),\n",
    "                        'goodreads_search': f\"https://www.goodreads.com/search?q={book['title'].replace(' ', '+')}\",\n",
    "                        'google_books_search': f\"https://www.google.com/search?tbm=bks&q={book['title'].replace(' ', '+')}+{author_str.replace(' ', '+')}\",\n",
    "                        'amazon_search': f\"https://www.amazon.com/s?k={book['title'].replace(' ', '+')}&i=stripbooks\",\n",
    "                    }\n",
    "                    \n",
    "                    book_entry = {\n",
    "                        'rank': book.get('rank', 0),\n",
    "                        'book_id': book['book_id'],\n",
    "                        'title': book['title'],\n",
    "                        'authors': author_str,\n",
    "                        'average_rating': book.get('average_rating', 'N/A'),\n",
    "                        'similarity_score': book['similarity_score'],\n",
    "                        'resnet_emotion': book.get('resnet_predicted_emotion', 'N/A'),\n",
    "                        'bert_emotion': book.get('bert_predicted_emotion', 'N/A'),\n",
    "                        'cover_url': book.get('image_url_large', 'No cover URL'),\n",
    "                        'description': book.get('description', 'No description available'),\n",
    "                        'urls': book_urls\n",
    "                    }\n",
    "                    \n",
    "                    book_info['recommendations'][approach][category].append(book_entry)\n",
    "        \n",
    "        # Save to file if requested\n",
    "        if save_to_file:\n",
    "            # Also create a simple CSV for easy viewing\n",
    "            csv_filename = f\"book_recommendations_{results['image_prediction']['dominant_emotion']}.csv\"\n",
    "            self._save_to_csv(book_info, csv_filename)\n",
    "            print(f\"ğŸ’¾ CSV summary saved to: {csv_filename}\")\n",
    "        \n",
    "        return book_info\n",
    "    \n",
    "    def _save_to_csv(self, book_info, filename):\n",
    "        \"\"\"Save book recommendations to CSV format with actual cover URLs\"\"\"\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = ['approach', 'category', 'rank', 'title', 'authors', 'rating', \n",
    "                         'similarity_score', 'resnet_emotion', 'bert_emotion', 'book_id',\n",
    "                         'cover_url', 'description', 'goodreads_search_url']\n",
    "            \n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            \n",
    "            for approach in ['resnet', 'bert', 'multimodal']:\n",
    "                for category in ['top', 'middle', 'bottom']:\n",
    "                    for book in book_info['recommendations'][approach][category]:\n",
    "                        writer.writerow({\n",
    "                            'approach': approach,\n",
    "                            'category': category,\n",
    "                            'rank': book['rank'],\n",
    "                            'title': book['title'],\n",
    "                            'authors': book['authors'],\n",
    "                            'rating': book['average_rating'],\n",
    "                            'similarity_score': book['similarity_score'],\n",
    "                            'resnet_emotion': book['resnet_emotion'],\n",
    "                            'bert_emotion': book['bert_emotion'],\n",
    "                            'book_id': book['book_id'],\n",
    "                            'cover_url': book['cover_url'],\n",
    "                            'description': book['description'][:200] + '...' if len(book.get('description', '')) > 200 else book.get('description', ''),\n",
    "                            'goodreads_search_url': book['urls']['goodreads_search']\n",
    "                        })\n",
    "\n",
    "    def create_emotion_bar_charts(self, results, save_dir=\"emotion_charts\", show_plots=True):\n",
    "        \"\"\"Create and save emotion distribution bar charts for image and recommendations\"\"\"\n",
    "        import os\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "        \n",
    "        # Create save directory\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Get image emotion distribution\n",
    "        image_emotions = results['image_prediction']['emotion_distribution']\n",
    "        dominant_emotion = results['image_prediction']['dominant_emotion']\n",
    "        \n",
    "        print(f\"\\nğŸ“Š Creating emotion distribution bar charts...\")\n",
    "        print(f\"ğŸ’¾ Saving charts to: {save_dir}/\")\n",
    "        \n",
    "        # 1. Create bar chart for input image\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(self.emotion_labels)))\n",
    "        \n",
    "        bars = ax.bar(range(len(self.emotion_labels)), image_emotions, \n",
    "                      color=colors, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        # Highlight dominant emotion\n",
    "        max_idx = np.argmax(image_emotions)\n",
    "        bars[max_idx].set_edgecolor('red')\n",
    "        bars[max_idx].set_linewidth(3)\n",
    "        \n",
    "        # Customize plot\n",
    "        ax.set_xlabel('Emotions', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Probability', fontsize=12, fontweight='bold')\n",
    "        ax.set_title(f'Input Image Emotion Distribution\\n(Dominant: {dominant_emotion})', \n",
    "                    fontsize=14, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Set x-axis labels\n",
    "        ax.set_xticks(range(len(self.emotion_labels)))\n",
    "        ax.set_xticklabels(self.emotion_labels, rotation=45, ha='right')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, image_emotions):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                   f'{value:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # Add grid and formatting\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.set_ylim(0, max(image_emotions) * 1.2)\n",
    "        \n",
    "        # Add dominant emotion annotation\n",
    "        ax.text(0.02, 0.98, f'Dominant: {dominant_emotion}\\nConfidence: {image_emotions[max_idx]:.3f}', \n",
    "                transform=ax.transAxes, fontsize=12, fontweight='bold',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"yellow\", alpha=0.8),\n",
    "                verticalalignment='top')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save image emotion chart\n",
    "        image_chart_path = os.path.join(save_dir, f'input_image_emotions_{dominant_emotion}.png')\n",
    "        plt.savefig(image_chart_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ“ Saved input image emotions: {image_chart_path}\")\n",
    "        \n",
    "        if show_plots:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "        \n",
    "        # 2. Create comparison charts for top recommendations\n",
    "        approaches = [\n",
    "            ('resnet', 'ResNet', results['resnet_recommendations'], self.resnet_emotions_matrix),\n",
    "            ('bert', 'BERT', results['bert_recommendations'], self.bert_emotions_matrix),\n",
    "            ('multimodal', 'Multimodal', results['multimodal_recommendations'], self.multimodal_emotions_matrix)\n",
    "        ]\n",
    "        \n",
    "        for approach_key, approach_name, recommendations, emotion_matrix in approaches:\n",
    "            # Create comparison chart for top 3 books\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "            fig.suptitle(f'{approach_name} Approach: Top 3 Book Recommendations vs Input Image', \n",
    "                        fontsize=16, fontweight='bold')\n",
    "            \n",
    "            # Plot input image in top-left\n",
    "            ax = axes[0, 0]\n",
    "            bars = ax.bar(range(len(self.emotion_labels)), image_emotions, \n",
    "                         color='skyblue', alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "            bars[max_idx].set_edgecolor('red')\n",
    "            bars[max_idx].set_linewidth(3)\n",
    "            \n",
    "            ax.set_title(f'Input Image\\n(Dominant: {dominant_emotion})', fontweight='bold')\n",
    "            ax.set_xticks(range(len(self.emotion_labels)))\n",
    "            ax.set_xticklabels(self.emotion_labels, rotation=45, ha='right')\n",
    "            ax.set_ylabel('Probability')\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # Add values on bars\n",
    "            for bar, value in zip(bars, image_emotions):\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.005,\n",
    "                       f'{value:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "            \n",
    "            # Plot top 3 book recommendations\n",
    "            positions = [(0, 1), (1, 0), (1, 1)]\n",
    "            colors_books = ['lightcoral', 'lightgreen', 'lightsalmon']\n",
    "            \n",
    "            for i, (book, pos, color) in enumerate(zip(recommendations['top'][:3], positions, colors_books)):\n",
    "                ax = axes[pos[0], pos[1]]\n",
    "                \n",
    "                # Get book emotions\n",
    "                book_idx = self._get_book_index(book['book_id'])\n",
    "                if book_idx is not None:\n",
    "                    book_emotions = emotion_matrix[book_idx]\n",
    "                    book_max_idx = np.argmax(book_emotions)\n",
    "                    \n",
    "                    # Create bars\n",
    "                    bars = ax.bar(range(len(self.emotion_labels)), book_emotions, \n",
    "                                 color=color, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "                    bars[book_max_idx].set_edgecolor('red')\n",
    "                    bars[book_max_idx].set_linewidth(3)\n",
    "                    \n",
    "                    # Formatting\n",
    "                    book_title = book['title'][:30] + '...' if len(book['title']) > 30 else book['title']\n",
    "                    book_emotion = self.emotion_labels[book_max_idx]\n",
    "                    similarity = book['similarity_score']\n",
    "                    \n",
    "                    ax.set_title(f'Book {i+1}: {book_title}\\n(Dominant: {book_emotion}, Sim: {similarity:.3f})', \n",
    "                               fontweight='bold', fontsize=11)\n",
    "                    ax.set_xticks(range(len(self.emotion_labels)))\n",
    "                    ax.set_xticklabels(self.emotion_labels, rotation=45, ha='right')\n",
    "                    ax.set_ylabel('Probability')\n",
    "                    ax.grid(True, alpha=0.3, axis='y')\n",
    "                    \n",
    "                    # Add values on bars\n",
    "                    for bar, value in zip(bars, book_emotions):\n",
    "                        if value > 0.1:  # Only show values > 0.1 to avoid clutter\n",
    "                            ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.005,\n",
    "                                   f'{value:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save comparison chart\n",
    "            comparison_path = os.path.join(save_dir, f'{approach_key}_emotion_comparison_{dominant_emotion}.png')\n",
    "            plt.savefig(comparison_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"âœ“ Saved {approach_name} comparison: {comparison_path}\")\n",
    "            \n",
    "            if show_plots:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.close()\n",
    "        \n",
    "        # 3. Create comprehensive heatmap\n",
    "        self._create_comprehensive_emotion_heatmap(results, save_dir, show_plots)\n",
    "        \n",
    "        return save_dir\n",
    "    \n",
    "    def _create_comprehensive_emotion_heatmap(self, results, save_dir, show_plots=True):\n",
    "        \"\"\"Create a comprehensive heatmap showing all emotion distributions\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        import os\n",
    "        \n",
    "        # Collect all emotion distributions\n",
    "        image_emotions = results['image_prediction']['emotion_distribution']\n",
    "        dominant_emotion = results['image_prediction']['dominant_emotion']\n",
    "        \n",
    "        all_emotions = [image_emotions]\n",
    "        labels = ['Input Image']\n",
    "        \n",
    "        # Get top 2 from each approach\n",
    "        approaches = [\n",
    "            ('ResNet', results['resnet_recommendations']['top'][:2], self.resnet_emotions_matrix),\n",
    "            ('BERT', results['bert_recommendations']['top'][:2], self.bert_emotions_matrix),\n",
    "            ('Multimodal', results['multimodal_recommendations']['top'][:2], self.multimodal_emotions_matrix)\n",
    "        ]\n",
    "        \n",
    "        for approach_name, books, emotion_matrix in approaches:\n",
    "            for i, book in enumerate(books, 1):\n",
    "                book_idx = self._get_book_index(book['book_id'])\n",
    "                if book_idx is not None:\n",
    "                    book_emotions = emotion_matrix[book_idx]\n",
    "                    all_emotions.append(book_emotions)\n",
    "                    \n",
    "                    book_title = book['title'][:25] + '...' if len(book['title']) > 25 else book['title']\n",
    "                    similarity = book['similarity_score']\n",
    "                    labels.append(f\"{approach_name}-{i}\\n{book_title}\\n(Sim: {similarity:.3f})\")\n",
    "        \n",
    "        # Create emotion matrix for heatmap\n",
    "        emotion_matrix = np.array(all_emotions)\n",
    "        \n",
    "        # Create heatmap\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        \n",
    "        # Custom colormap\n",
    "        heatmap = sns.heatmap(emotion_matrix, \n",
    "                             xticklabels=self.emotion_labels,\n",
    "                             yticklabels=labels,\n",
    "                             annot=True, \n",
    "                             fmt='.3f',\n",
    "                             cmap='YlOrRd',\n",
    "                             cbar_kws={'label': 'Emotion Probability'},\n",
    "                             linewidths=0.5)\n",
    "        \n",
    "        plt.title(f'Emotion Distribution Heatmap\\nInput Image vs Top Book Recommendations\\n(Dominant Emotion: {dominant_emotion})', \n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "        plt.xlabel('Emotions', fontweight='bold', fontsize=12)\n",
    "        plt.ylabel('Items', fontweight='bold', fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        \n",
    "        # Highlight the input image row\n",
    "        heatmap.add_patch(plt.Rectangle((0, 0), len(self.emotion_labels), 1, \n",
    "                                      fill=False, edgecolor='blue', lw=3))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save heatmap\n",
    "        heatmap_path = os.path.join(save_dir, f'emotion_heatmap_{dominant_emotion}.png')\n",
    "        plt.savefig(heatmap_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ“ Saved emotion heatmap: {heatmap_path}\")\n",
    "        \n",
    "        if show_plots:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "    \n",
    "    def create_detailed_emotion_report(self, results, save_dir=\"emotion_analysis_2\"):\n",
    "        \"\"\"Create detailed emotion analysis report with charts and statistics\"\"\"\n",
    "        import os\n",
    "        import json\n",
    "        \n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ Creating detailed emotion analysis report...\")\n",
    "        \n",
    "        # Create all bar charts\n",
    "        chart_dir = os.path.join(save_dir, \"charts\")\n",
    "        self.create_emotion_bar_charts(results, save_dir=chart_dir, show_plots=False)\n",
    "        \n",
    "        # Create detailed statistics\n",
    "        image_emotions = results['image_prediction']['emotion_distribution']\n",
    "        dominant_emotion = results['image_prediction']['dominant_emotion']\n",
    "        \n",
    "        # Calculate emotion statistics for each approach\n",
    "        emotion_analysis = {\n",
    "            'input_image': {\n",
    "                'dominant_emotion': dominant_emotion,\n",
    "                'confidence': float(results['image_prediction']['confidence']),\n",
    "                'emotion_distribution': {emotion: float(prob) for emotion, prob \n",
    "                                       in zip(self.emotion_labels, image_emotions)},\n",
    "                'top_3_emotions': []\n",
    "            },\n",
    "            'recommendations_analysis': {}\n",
    "        }\n",
    "        \n",
    "        # Get top 3 emotions for input image\n",
    "        top_3_indices = np.argsort(image_emotions)[-3:][::-1]\n",
    "        for idx in top_3_indices:\n",
    "            emotion_analysis['input_image']['top_3_emotions'].append({\n",
    "                'emotion': self.emotion_labels[idx],\n",
    "                'probability': float(image_emotions[idx])\n",
    "            })\n",
    "        \n",
    "        # Analyze each approach\n",
    "        approaches = [\n",
    "            ('resnet', results['resnet_recommendations'], self.resnet_emotions_matrix),\n",
    "            ('bert', results['bert_recommendations'], self.bert_emotions_matrix),\n",
    "            ('multimodal', results['multimodal_recommendations'], self.multimodal_emotions_matrix)\n",
    "        ]\n",
    "        \n",
    "        for approach_name, recommendations, emotion_matrix in approaches:\n",
    "            emotion_analysis['recommendations_analysis'][approach_name] = {\n",
    "                'top_books': []\n",
    "            }\n",
    "            \n",
    "            for i, book in enumerate(recommendations['top'][:3], 1):\n",
    "                book_idx = self._get_book_index(book['book_id'])\n",
    "                if book_idx is not None:\n",
    "                    book_emotions = emotion_matrix[book_idx]\n",
    "                    \n",
    "                    # Calculate similarities\n",
    "                    cosine_sim = np.dot(image_emotions, book_emotions) / (\n",
    "                        np.linalg.norm(image_emotions) * np.linalg.norm(book_emotions))\n",
    "                    kl_div = self._calculate_kl_divergence(image_emotions, book_emotions)\n",
    "                    \n",
    "                    # Get top 3 emotions for this book\n",
    "                    book_top_3_indices = np.argsort(book_emotions)[-3:][::-1]\n",
    "                    book_top_3 = []\n",
    "                    for idx in book_top_3_indices:\n",
    "                        book_top_3.append({\n",
    "                            'emotion': self.emotion_labels[idx],\n",
    "                            'probability': float(book_emotions[idx])\n",
    "                        })\n",
    "                    \n",
    "                    book_analysis = {\n",
    "                        'rank': i,\n",
    "                        'title': book['title'],\n",
    "                        'book_id': book['book_id'],\n",
    "                        'similarity_score': float(book['similarity_score']),\n",
    "                        'cosine_similarity': float(cosine_sim),\n",
    "                        'kl_divergence': float(kl_div),\n",
    "                        'dominant_emotion': self.emotion_labels[np.argmax(book_emotions)],\n",
    "                        'emotion_distribution': {emotion: float(prob) for emotion, prob \n",
    "                                               in zip(self.emotion_labels, book_emotions)},\n",
    "                        'top_3_emotions': book_top_3,\n",
    "                        'emotion_differences': {}\n",
    "                    }\n",
    "                    \n",
    "                    # Calculate emotion differences\n",
    "                    for j, emotion in enumerate(self.emotion_labels):\n",
    "                        diff = float(book_emotions[j] - image_emotions[j])\n",
    "                        book_analysis['emotion_differences'][emotion] = diff\n",
    "                    \n",
    "                    emotion_analysis['recommendations_analysis'][approach_name]['top_books'].append(book_analysis)\n",
    "        \n",
    "        # Save detailed analysis\n",
    "        analysis_file = os.path.join(save_dir, f'emotion_analysis_{dominant_emotion}.json')\n",
    "        with open(analysis_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(emotion_analysis, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"âœ“ Saved detailed emotion analysis: {analysis_file}\")\n",
    "        print(f\"âœ“ Saved emotion charts in: {chart_dir}/\")\n",
    "        \n",
    "        return emotion_analysis\n",
    "\n",
    "# ================== MAIN EXECUTION ==================\n",
    "\n",
    "# ================== UPDATED MAIN EXECUTION ==================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function with emotion chart creation\"\"\"\n",
    "    print(\"ğŸš€ Starting Complete Image-Book Emotion Matching System\")\n",
    "    \n",
    "    # Initialize the complete matcher\n",
    "    matcher = CompleteImageBookMatcher(\n",
    "        use_gpu_similarity=True,    \n",
    "        precompute_indices=True     \n",
    "    )\n",
    "    \n",
    "    # Example usage - UPDATE THIS PATH\n",
    "    image_path = \"input_images/anger_painting.jpg\"\n",
    "    \n",
    "    # Run the complete analysis\n",
    "    if os.path.exists(image_path):\n",
    "        print(f\"\\nğŸ“¸ Analyzing image: {image_path}\")\n",
    "        \n",
    "        # Fast matching with comprehensive results\n",
    "        results = matcher.find_similar_books_complete(\n",
    "            image_path=image_path,\n",
    "            top_k=100000,     \n",
    "            final_n=3       \n",
    "        )\n",
    "        \n",
    "        # Display comprehensive results WITH emotion charts\n",
    "        print(\"\\n\" + \"ğŸ”\" * 50)\n",
    "        matcher.display_detailed_recommendations(\n",
    "            results, \n",
    "            # show_covers=True, \n",
    "            show_emotion_analysis=True,\n",
    "            # save_charts=True  # NEW: Save emotion bar charts\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nâœ… ANALYSIS COMPLETE!\")\n",
    "        print(f\"ğŸ“Š Emotion charts saved to: emotion_charts/\")\n",
    "        print(f\"ğŸ“ˆ Detailed analysis saved to: emotion_analysis/\")\n",
    "        return results\n",
    "    else:\n",
    "        print(f\"âŒ Error: Image file not found: {image_path}\")\n",
    "        return None\n",
    "\n",
    "results = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c9f1913-7bbe-4105-b0d0-5645e359f22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_prediction': {'emotion_distribution': array([0.051175  , 0.1347416 , 0.1851053 , 0.04031268, 0.03425219,\n",
       "         0.07360052, 0.09151398, 0.33991244, 0.04938627], dtype=float32),\n",
       "  'confidence': 0.33991244435310364,\n",
       "  'dominant_emotion': 'sadness',\n",
       "  'emotion_scores': {'amusement': 0.051175002,\n",
       "   'awe': 0.1347416,\n",
       "   'contentment': 0.1851053,\n",
       "   'excitement': 0.040312678,\n",
       "   'anger': 0.03425219,\n",
       "   'disgust': 0.07360052,\n",
       "   'fear': 0.091513984,\n",
       "   'sadness': 0.33991244,\n",
       "   'something else': 0.04938627}},\n",
       " 'processing_time': 0.11922168731689453,\n",
       " 'resnet_recommendations': {'top': [{'rank': 1,\n",
       "    'book_id': '9330885',\n",
       "    'title': 'Dreamless',\n",
       "    'authors': array([{'author_id': '2358626', 'role': ''},\n",
       "           {'author_id': '512445', 'role': 'Illustrator'}], dtype=object),\n",
       "    'average_rating': 3.92,\n",
       "    'similarity_score': 0.9975203275680542,\n",
       "    'approach': 'ResNet',\n",
       "    'resnet_predicted_emotion': 'sadness',\n",
       "    'bert_predicted_emotion': 'something else',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1290170247l/9330885.jpg',\n",
       "    'description': \"A World War II romance about an American girl and a Japanese boy who have seen each other's lives in their sleep since birth. This is a 72-page, FULL COLOR graphic novel collecting the complete acclaimed DREAMLESS story in one handy printed volume! Written by MARRY ME and LAST BLOOD author Bobby Crosby, and beautifully painted by THE PHOENIX REQUIEM creator Sarah Ellerton.\"},\n",
       "   {'rank': 2,\n",
       "    'book_id': '14402305',\n",
       "    'title': 'Runaway!',\n",
       "    'authors': array([{'author_id': '6025490', 'role': ''}], dtype=object),\n",
       "    'average_rating': 4.12,\n",
       "    'similarity_score': 0.9974592924118042,\n",
       "    'approach': 'ResNet',\n",
       "    'resnet_predicted_emotion': 'sadness',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1340031123l/14402305.jpg',\n",
       "    'description': \"Out of print\\nA runaway slave boy, the Underground Railroad, a land without shadows. Robbed of his emancipation by his master's widow, a literate 14-year-old slave boy flees into the prairie. His journey crosses a territory ripped apart in conflict over slavery: stolen elections, printing presses thrown in the river, church houses nailed shut. But folk stories and campfire songs help him find conductors on the Underground Railroad. Slavecatchers dog his trail, but before the runaway can cross the river to freedom, he must first place his faith in an illiterate freewoman.\"},\n",
       "   {'rank': 3,\n",
       "    'book_id': '12078346',\n",
       "    'title': \"Bengali Girls Don't\",\n",
       "    'authors': array([{'author_id': '1947044', 'role': ''}], dtype=object),\n",
       "    'average_rating': 3.18,\n",
       "    'similarity_score': 0.9971522092819214,\n",
       "    'approach': 'ResNet',\n",
       "    'resnet_predicted_emotion': 'sadness',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1313500615l/12078346.jpg',\n",
       "    'description': \"Based on a True Story:\\nBorn in a remote village during her country's liberation war, a Bangladeshi girl moves to England with her parents and struggles for freedom and identity while growing up in a mixed neighborhood. Caught between the world of her white friends and that of her parents, she scraps her Muslim gear for blue jeans and runs away with her boyfriend.\\nBut when her father tracks her down and finds her, he tricks her into going to Bangladesh so that he can marry her off.\\nIn Bangladesh, she is faced with a choice: get married or never go home.\\nIt's an unforgettable true story about heartache and irony. About broken dreams. And how the life we choose is not always the life that chooses us.\\nABOUT THE AUTHOR\\nL.A. Sherman grew up in Bradford, England where she learned how to sneak out of the house without making the door creak. At the age of fifteen, she was tricked into going to Bangladesh by her parents and forced to marry a man as old as her father. After four years there with a wicked mother-in-law, she won the visa lottery for America and moved to the Big Apple. Now hard at work on her second book, she lives in Tampa, Florida with her family near a pond full of gators and spends her time doing all the things that Bengali girls don't.\"}],\n",
       "  'middle': [{'rank': 4,\n",
       "    'book_id': '18306865',\n",
       "    'title': 'Tiy and the Prince of Egypt',\n",
       "    'authors': array([{'author_id': '6535967', 'role': ''}], dtype=object),\n",
       "    'average_rating': 4.37,\n",
       "    'similarity_score': 0.9967974424362183,\n",
       "    'approach': 'ResNet',\n",
       "    'resnet_predicted_emotion': 'sadness',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1376201779l/18306865.jpg',\n",
       "    'description': 'Based on the lives of Pharaoh Amenhotep III and Queen Tiy - a historical romance for all ages!Tiy is different than the other Egyptian girls--she has pale hair and more freckles than she wants to count. With her mother consumed by the need to keep up appearances, and her father too busy to care, Tiy just wants to disappear into the background. But her hope for a quiet life is shattered when she rescues Prince Amenhotep from a sandstorm and is rewarded with an invitation to attend the royal school in Egypt\\'s capital\"\"-a place where girls like her will never belong.\\nAmenhotep welcomes her into his close circle of friends and their friendship strengthens into a bond neither is willing to lose. But when Amenhotep becomes Pharaoh and is pressured by the priests to marry, the strength of their friendship is threatened. Will Tiy find enough courage to accept Amenhotep\\'s hand when he wants her to become the next Queen of Egypt, especially when her feelings run no deeper than friendship? And how can she protect him from the Nubian rebels who are determined to take control of Egypt?\\n>>>\"This story is a rare gem.\" - Playing for Sweeps\\n>>>\"Debbie Dee blew me away, yet again....I was at the edge of my seat over and over.\" - Kayla\\'s Place\\n>>>\"Really draws you in.\" - Trips Down Imagination Road'},\n",
       "   {'rank': 5,\n",
       "    'book_id': '17167007',\n",
       "    'title': 'Never (Lightbringer, #3)',\n",
       "    'authors': array([{'author_id': '4862188', 'role': ''}], dtype=object),\n",
       "    'average_rating': 3.94,\n",
       "    'similarity_score': 0.9966678619384766,\n",
       "    'approach': 'ResNet',\n",
       "    'resnet_predicted_emotion': 'sadness',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1356380788l/17167007.jpg',\n",
       "    'description': \"The Lightbringer trilogy's dramatic conclusion!\\nThe Never is on the brink of destruction by the Lady Walker. Wendy, shorn of her Light by the Reapers, must be the one to save it from the beasts between the worlds. Now no more powerful than an average spirit, Wendy reluctantly strikes a balance between Elise, the new Reaper matriarch, and Jane, a Reaper gone rogue. Torn between her duty to her friends, the Riders, and her duty as the Lightbringer, Wendy must rush to learn the secrets left behind.\\nShe must make the ultimate sacrifice to bring the worlds into balance once more... even if it costs her very soul.\"},\n",
       "   {'rank': 6,\n",
       "    'book_id': '21840882',\n",
       "    'title': 'If You Really Love Me',\n",
       "    'authors': array([{'author_id': '5989784', 'role': ''}], dtype=object),\n",
       "    'average_rating': 3.67,\n",
       "    'similarity_score': 0.996509850025177,\n",
       "    'approach': 'ResNet',\n",
       "    'resnet_predicted_emotion': 'sadness',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1396491579l/21840882.jpg',\n",
       "    'description': \"A Harmony Ink Press Young Adult Title\\nWith time ticking until graduation, Ellis Carter doesn't have a plan for after high school. Since his best friend Cary dropped out, he has no one to talk to. All he knows is he doesn't want to continue being a burden to his mother. Adding to his daily torture is the school's new resident bad boy, Saul Brooks. So to say he's amazed when the mysterious Saul invites him to the gym for a workout is an understatement. Soon, they go from workout buddies to boyfriends, and Ellis couldn't be happier. But happiness is fleeting. His mother begins a new relationship he thinks will lead to pain, and Cary makes a decision that could take him out of Ellis's life for good. Just when he needs to lean on his boyfriend the most, Ellis discovers Saul has a secret that could break them apart.\"}],\n",
       "  'bottom': [{'rank': 7,\n",
       "    'book_id': '13341980',\n",
       "    'title': \"Joseph's Story\",\n",
       "    'authors': array([{'author_id': '5419731', 'role': ''}], dtype=object),\n",
       "    'average_rating': 3.57,\n",
       "    'similarity_score': 0.9965054988861084,\n",
       "    'approach': 'ResNet',\n",
       "    'resnet_predicted_emotion': 'sadness',\n",
       "    'bert_predicted_emotion': 'excitement',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1340739667l/13341980.jpg',\n",
       "    'description': \"Joseph was the happiest man alive. He was going to marry the most beautiful girl in Nazareth. He had some of the best friends anyone could want. His carpentry business was taking off. His furniture and other products that he had built were the talk of the town. Everything seemed to be going Joseph's way. He had his whole life planned out... Then it all changed. Join me as we plunge into an adventure, based on biblical events, of what Joseph's life may have been like before Jesus was born. A life of oppressive Roman rule, where greed and power and corruption seemed to be rampant; A time of love, betrayal and forgiveness; A time where the heavens touched the earth in helping usher in the most anticipated birth in human history. This is Jospeh's Story\"},\n",
       "   {'rank': 8,\n",
       "    'book_id': '13263393',\n",
       "    'title': 'Spy Hard (SDDU, #12)',\n",
       "    'authors': array([{'author_id': '150270', 'role': ''}], dtype=object),\n",
       "    'average_rating': 3.81,\n",
       "    'similarity_score': 0.9964667558670044,\n",
       "    'approach': 'ResNet',\n",
       "    'resnet_predicted_emotion': 'sadness',\n",
       "    'bert_predicted_emotion': 'fear',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1338592786l/13263393.jpg',\n",
       "    'description': \"Being deep undercover in a drug lord's compound, Jase Campbell can't afford to be anything but ruthless and mission-oriented. But it doesn't take trained instincts to see that pregnant Melanie Key needs his help to escape an increasingly lethal situation...whether she wants it or not. Jase can certainly understand why the once-naive widow insists on relying on herself and will trust him only so far. And her courage and unexpected resourcefulness in the face of killer obstacles is sparking something even more risky--and irresistible--between them. Now, with danger fast closing in, Jase will put everything at stake for a future with Melanie--if they can survive to have one.\"},\n",
       "   {'rank': 9,\n",
       "    'book_id': '18528395',\n",
       "    'title': \"Pirates You Don't Know, and Other Adventures in the Examined Life: Collected Essays\",\n",
       "    'authors': array([{'author_id': '59504', 'role': ''}], dtype=object),\n",
       "    'average_rating': 4.84,\n",
       "    'similarity_score': 0.9963057041168213,\n",
       "    'approach': 'ResNet',\n",
       "    'resnet_predicted_emotion': 'sadness',\n",
       "    'bert_predicted_emotion': 'amusement',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1386200677l/18528395.jpg',\n",
       "    'description': 'For nearly ten years John Griswold has been publishing his essays in Inside Higher Ed, McSweeney\\'s Internet Tendency, Brevity, Ninth Letter, and Adjunct Advocate, many under the pen name Oronte Churm. Churm\\'s topics have ranged widely, exploring themes such as the writing life and the utility of creative-writing classes, race issues in a university town, and the beautiful, protective crocodiles that lie patiently waiting in the minds of fathers.\\nThough Griswold recently entered the tenure stream, much of his experience, at a Big Ten university, has been as an adjunct lecturer--that tenuous and uncertain position so many now occupy in higher education. In Pirates You Don\\'t Know, Griswold writes poignantly and hilariously about the contingent nature of this life, tying it to his birth in the last American enclave in Saigon during the Vietnam War, his upbringing in a coal town in southern Illinois, and his experience as an army deep-sea diver and frogman. He investigates class in America through four generations of his family and portrays the continuing joys and challenges of fatherhood while making a living, becoming literate, and staying open to the world. But Griswold\\'s central concerns apply to everyone: What does it mean to be educated? What does it mean to think, feel, create, and be whole? What is the point of this particular journey?\\nPirates You Don\\'t Knowis Griswold\\'s vital attempt at making sense of his life as a writer and now professor. The answers for him are both comic and profound: \"Picture Long John Silver at the end of the movie, his dory filled with stolen gold, rowing and sinking; rowing, sinking, and gloating.\"'}]},\n",
       " 'bert_recommendations': {'top': [{'rank': 1,\n",
       "    'book_id': '29505492',\n",
       "    'title': 'The Oâ€™Rahilly: A Secret History of the Rebellion of 1916',\n",
       "    'authors': array([{'author_id': '15082440', 'role': ''}], dtype=object),\n",
       "    'average_rating': 4.0,\n",
       "    'similarity_score': 0.9943222999572754,\n",
       "    'approach': 'BERT',\n",
       "    'resnet_predicted_emotion': 'awe',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1457963343l/29505492.jpg',\n",
       "    'description': \"The only leader of the 1916 Rising to be killed in action, Michael O'Rahilly died in a Dublin laneway after leading a charge against a British barricade in Moore Street. A letter to his wife, written during his last moments and pierced by the fatal bullet, was found in his breast pocket.\\nThe O'Rahilly, as he became known, was the prime mover in the formation of the Irish Volunteers and its director of arms, organizing the purchase and delivery of the Howth rifles in July 1914. He was Pearse's aide-de-camp in the General Post Office during Easter Week and became commander of the garrison after Connolly was wounded.\"},\n",
       "   {'rank': 2,\n",
       "    'book_id': '1411357',\n",
       "    'title': 'Yosl Rakover Talks to God',\n",
       "    'authors': array([{'author_id': '368781', 'role': ''}], dtype=object),\n",
       "    'average_rating': 4.14,\n",
       "    'similarity_score': 0.9933139681816101,\n",
       "    'approach': 'BERT',\n",
       "    'resnet_predicted_emotion': 'something else',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1320543569l/1411357.jpg',\n",
       "    'description': \"There are two stories here. One is the now legendary tale of a defiant Jew's refusal to abandon God, even in the face of the greatest suffering the world has known, a testament of faith that has taken on an unpredictable and fascinating life of its own and has often been thought to be a direct testament from the Holocaust.\\nThe parallel story is that of Zvi Kolitz, the true author, whose connection to Yosl Rakoverhas been obscured over the fifty years since its original appearance. German journalist Paul Badde tells how a young man came to write this classic response to evil, and then was nearly written out of its history. With brief commentaries by French philosopher Emmanuel Levinas and Leon Wieseltier, author of Kaddish, this edition presents a religious classic and the very human story behind it.\"},\n",
       "   {'rank': 3,\n",
       "    'book_id': '28595947',\n",
       "    'title': \"We Gon' Be Alright: Notes on Race and Resegregation\",\n",
       "    'authors': array([{'author_id': '30905', 'role': ''}], dtype=object),\n",
       "    'average_rating': 4.29,\n",
       "    'similarity_score': 0.9931026697158813,\n",
       "    'approach': 'BERT',\n",
       "    'resnet_predicted_emotion': 'amusement',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1468230274l/28595947.jpg',\n",
       "    'description': 'In these provocative, powerful essays acclaimed writer/journalist Jeff Chang (Can\\'t Stop Won\\'t Stop, Who We Be) takes an incisive and wide-ranging look at the recent tragedies and widespread protests that have shaken the country. Through deep reporting with key activists and thinkers, passionately personal writing, and distinguished cultural criticism, We Gon\\' Be Alright links #BlackLivesMatter to #OscarsSoWhite, Ferguson to Washington D.C., the Great Migration to resurgent nativism. Chang explores the rise and fall of the idea of \"diversity,\" the roots of student protest, changing ideas about Asian Americanness, and the impact of a century of racial separation in housing. He argues that resegregation is the unexamined condition of our time, the undoing of which is key to moving the nation forward to racial justice and cultural equity.'}],\n",
       "  'middle': [{'rank': 4,\n",
       "    'book_id': '7332277',\n",
       "    'title': 'Empires at War: A Short History of Modern Asia Since World War II',\n",
       "    'authors': array([{'author_id': '4678396', 'role': ''}], dtype=object),\n",
       "    'average_rating': 4.0,\n",
       "    'similarity_score': 0.9925889372825623,\n",
       "    'approach': 'BERT',\n",
       "    'resnet_predicted_emotion': 'amusement',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1315685394l/7332277.jpg',\n",
       "    'description': 'Empires at Wargives a dramatic narrative account of how \"Modern Asia\" came into being. Ranging over the whole of Asia, from Japan to Pakistan, the modern history of this important region is placed in the context of the struggle between America and the Soviet Union. Francis Pike shows that America\\'s domination of post-war Asia was a continuation of a 100-year competition for power in the region. He also argues cogently that, contrary to the largely \"Western-centric\" viewpoint, Asian nations were not simply the passive and biddable pawns of the superpowers, but had a political development which was both separate and unique, with a dynamic that was largely independent of the superpower conflict. And, in conclusion, the book traces the unwinding of American influence and the end of its empire, a crucial development in international history which is already having repercussions throughout the world.'},\n",
       "   {'rank': 5,\n",
       "    'book_id': '1394875',\n",
       "    'title': \"Schindler's Ark\",\n",
       "    'authors': array([{'author_id': '6900', 'role': ''}], dtype=object),\n",
       "    'average_rating': 4.34,\n",
       "    'similarity_score': 0.9922177791595459,\n",
       "    'approach': 'BERT',\n",
       "    'resnet_predicted_emotion': 'amusement',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1415587682l/1394875.jpg',\n",
       "    'description': 'The basis for the Oscar-winning Spielberg movie, this novel recreates the story of Oskar Schindler, an Aryan who risked his life to protect Jews in Nazi-occupied Poland.'},\n",
       "   {'rank': 6,\n",
       "    'book_id': '8411911',\n",
       "    'title': 'Treasure Mountain',\n",
       "    'authors': array([{'author_id': '858', 'role': ''}], dtype=object),\n",
       "    'average_rating': 4.01,\n",
       "    'similarity_score': 0.9921080470085144,\n",
       "    'approach': 'BERT',\n",
       "    'resnet_predicted_emotion': 'fear',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1349265725l/8411911.jpg',\n",
       "    'description': \"How do you bring a million dollars in gold down a mountain? First you have to find it, and that's mighty hard when you're tracking a trail that is twenty years old. But the Sackett brothers were determined to find the treasure and to discover if their father, who blazed the trail long ago, was still alive. They just hoped they were smarter than those New Orleans folks who also wanted the gold--and were willing to kill for it.\"}],\n",
       "  'bottom': [{'rank': 7,\n",
       "    'book_id': '282092',\n",
       "    'title': 'Treasure Mountain',\n",
       "    'authors': array([{'author_id': '858', 'role': ''}], dtype=object),\n",
       "    'average_rating': 4.01,\n",
       "    'similarity_score': 0.9921080470085144,\n",
       "    'approach': 'BERT',\n",
       "    'resnet_predicted_emotion': 'contentment',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1320446730l/282092.jpg',\n",
       "    'description': \"How do you bring a million dollars in gold down a mountain? First you have to find it, and that's mighty hard when you're tracking a trail that is twenty years old. But the Sackett brothers were determined to find the treasure and to discover if their father, who blazed the trail long ago, was still alive. They just hoped they were smarter than those New Orleans folks who also wanted the gold--and were willing to kill for it.\"},\n",
       "   {'rank': 8,\n",
       "    'book_id': '120990',\n",
       "    'title': 'Treasure Mountain',\n",
       "    'authors': array([{'author_id': '858', 'role': ''}], dtype=object),\n",
       "    'average_rating': 4.01,\n",
       "    'similarity_score': 0.9921080470085144,\n",
       "    'approach': 'BERT',\n",
       "    'resnet_predicted_emotion': 'sadness',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1326753881l/120990.jpg',\n",
       "    'description': \"How do you bring a million dollars in gold down a mountain? First you have to find it, and that's mighty hard when you're tracking a trail that is twenty years old. But the Sackett brothers were determined to find the treasure and to discover if their father, who blazed the trail long ago, was still alive. They just hoped they were smarter than those New Orleans folks who also wanted the gold--and were willing to kill for it.\"},\n",
       "   {'rank': 9,\n",
       "    'book_id': '30160990',\n",
       "    'title': 'Martin Luther King, Jr.: The Last Interview: And Other Conversations',\n",
       "    'authors': array([{'author_id': '23924', 'role': ''}], dtype=object),\n",
       "    'average_rating': 4.16,\n",
       "    'similarity_score': 0.9919853210449219,\n",
       "    'approach': 'BERT',\n",
       "    'resnet_predicted_emotion': 'amusement',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1471292131l/30160990.jpg',\n",
       "    'description': 'As the Black Lives Matter movement gains momentum, and books like Ta-Nehisi Coates\\'s Between the World and Meand Claudia Rankine\\'s Citizenswing national attention toward the racism and violence that continue to poison our communities, it\\'s as urgent now as ever to celebrate Martin Luther King, Jr., whose insistence on equality and peace defined the Civil Rights Movement and forever changed the course of American history.\\nThis collection ranges from an early 1961 interview in which King describes his reasons for joining the ministry (after considering medicine), to a 1964 conversation with Robert Penn Warren, to his last interview, which was conducted on stage at the convention of the Rabbinical Assembly, just ten days before King\\'s assassination.\\nTimely, poignant, and inspiring, Martin Luther King, Jr.: The Last Interviewis an essential addition to the Last Interview series.\"'}]},\n",
       " 'multimodal_recommendations': {'top': [{'rank': 1,\n",
       "    'book_id': '1442782',\n",
       "    'title': \"The Long March: The true story behind the legendary journey that made Mao's China\",\n",
       "    'authors': array([{'author_id': '678065', 'role': ''},\n",
       "           {'author_id': '678064', 'role': ''}], dtype=object),\n",
       "    'average_rating': 3.8,\n",
       "    'similarity_score': 0.9980773329734802,\n",
       "    'approach': 'Multimodal',\n",
       "    'resnet_predicted_emotion': 'amusement',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1450349679l/1442782.jpg',\n",
       "    'description': \"This is a living history of the legendary journey that made Mao's China. In October 1934, the First Front Army of the Chinese Communist Party fled annihilation by Chiang Kai-shek's Nationalists. Some 80,000 men, women and children left their homes to walk with Mao into the unknown. One year, 4,000 miles and countless battles later, fewer than 4,000 were left. From these survivors would grow the army that conquered China 14 years on, changing history for ever. In October 2002, Ed Jocelyn and Andrew McEwen set off to retrace the Red Army's footsteps, and record the experiences of the last-remaining witnesses and participants of the Long March - before it was too late. The result is an account of the March based squarely on eye-witness accounts. It contrasts starkly with the official version and with recent contentions that the March was a fraud. The Long March really did happen, but it was spun into the key propaganda tool Mao wielded in his rise to ultimate power. Bringing together the historic event, with images of a changing society and their own March - a remarkable feat of endurance in itself - the authors offer a unique picture of China, past and present.\"},\n",
       "   {'rank': 2,\n",
       "    'book_id': '15870096',\n",
       "    'title': 'Summer of Hope',\n",
       "    'authors': array([{'author_id': '6469975', 'role': ''}], dtype=object),\n",
       "    'average_rating': 3.79,\n",
       "    'similarity_score': 0.9968357682228088,\n",
       "    'approach': 'Multimodal',\n",
       "    'resnet_predicted_emotion': 'awe',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1356574564l/15870096.jpg',\n",
       "    'description': 'A secret can change everything.\\nAfter witnessing her twin brother\\'s death, sixteen-year-old Callie shuts down. Forced to go to her family\\'s summer beach house, she resolves to erase the pain any way she can. Enter the \"Perfect\\'s\"--the Gold Card group of girls who offer escape in the form of parties, booze and boys.\\nThings change when she meets Ethan. Callie does her best to convince herself she couldn\\'t care less if Ethan looks like he just stepped out of a magazine and is completely adorkable to boot. Despite trying to keep her distance, Callie is drawn to his sweet ways and sexy smile. She falls hard--but her world comes crashing down when she discovers he\\'s been hiding a secret that could change everything. Ethan came to the beach to escape, to live without the label. Because his label... is the kid with Hodgkin\\'s disease.\\nCallie is left with the choice of standing by Ethan\\'s side and watching another person she loves die, or running and abandoning the one person who helped her to believe in love again. Callie\\'s decision ends up putting her own life in danger, and changes the lives of everyone around her, forever.'},\n",
       "   {'rank': 3,\n",
       "    'book_id': '1816515',\n",
       "    'title': 'Smoldering City: Chicagoans and the Great Fire, 1871-1874',\n",
       "    'authors': array([{'author_id': '82596', 'role': ''}], dtype=object),\n",
       "    'average_rating': 3.33,\n",
       "    'similarity_score': 0.9954131245613098,\n",
       "    'approach': 'Multimodal',\n",
       "    'resnet_predicted_emotion': 'awe',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1328872691l/1816515.jpg',\n",
       "    'description': 'The fateful kick of Mrs. O\\'Leary\\'s cow, the wild flight before the flames, the astonishingly quick rebuilding--these are the well-known stories of the Great Chicago Fire of 1871. But as much as Chicago\\'s recovery from disaster was a remarkable civic achievement, the Great Fire is also the story of a city\\'s people divided and at odds. This is the story that Karen Sawislak tells so revealingly in this book.\\nIn a detailed account, drawn on memoirs, private correspondences, and other documents, Sawislak chronicles years of widespread, sometimes bitter, social and political conflict in the fire\\'s wake, from fights over relief soup kitchens to cries against profiteering and marches on city hall by workers burned out of their homes. She shows how through the years of rebuilding the people of Chicago struggled to define civic order--and the role that \"good citizens\" would play within it. As they rebuilt, she writes, Chicagoans confronted hard questions about charity and social welfare, work and labor relations, morality, and the limits of state power. Their debates in turn exposed the array of values and interests that different class, ethnic, and religious groups brought to these public discussions.\\n\"Sawislak combines the copious detail of a historian with the vivid portrayals of a storyteller in her investigation of the infamous Chicago fire. . . . Highlighted by historical maps, plates and engravings, with an epilogue and notes, Smoldering Citypresents an extremely thorough and engaging study of this extraordinary disaster.\"--Publishers Weekly'}],\n",
       "  'middle': [{'rank': 4,\n",
       "    'book_id': '33800133',\n",
       "    'title': 'This Change Is Everything',\n",
       "    'authors': array([{'author_id': '16277187', 'role': ''}], dtype=object),\n",
       "    'average_rating': 3.43,\n",
       "    'similarity_score': 0.994659960269928,\n",
       "    'approach': 'Multimodal',\n",
       "    'resnet_predicted_emotion': 'awe',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1483637635l/33800133.jpg',\n",
       "    'description': 'In \"This Change Is Everything\", Shane Sebastian walks through the history of God using young people to transform individuals, communities, cultures and nations. Shane shows how seemingly insurmountable obstacles-peer and parental approval, career concerns, debt, doubt, temptation, and the like-are not so much obstacles as opportunities to see God provide and pave a way for a changed life and changed world. This book sits at the threshold of what your life could be if you give God control and let him change you and use you to change others. Don\\'t read unless you\\'re willing to be challenged, to be changed, and to come to a crossroads where you seriously ask yourself how God wants you to change the world. 16-page full color insert of students on mission.'},\n",
       "   {'rank': 5,\n",
       "    'book_id': '15802150',\n",
       "    'title': \"When A Woman You Love Was Abused: A Husband's Guide to Helping Her Overcome Childhood Sexual Molestation\",\n",
       "    'authors': array([{'author_id': '6459662', 'role': ''},\n",
       "           {'author_id': '11099', 'role': 'Foreward'}], dtype=object),\n",
       "    'average_rating': 4.38,\n",
       "    'similarity_score': 0.994420051574707,\n",
       "    'approach': 'Multimodal',\n",
       "    'resnet_predicted_emotion': 'awe',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1344384752l/15802150.jpg',\n",
       "    'description': \"About the Book:\\nThe U.S. Department of Health and Human Services reports that 80 percent of childhood abuse victims later suffer from at least one abuse-induced psychological disorder. It's proven that the effects of childhood abuse follow women into adulthood. Yet few men are prepared to deal with those effects, even when their own wife is the one who is suffering. And their wife's suffering becomes their own suffering as their needs aren't being met by a wife who is powerless to control her inner turmoil.\\nAuthor, pastor, and survivor Dawn Scott Jones candidly shares her own abuse experience to help husbands understand the varied emotions, fears, distorted thoughts, and triggers that hold their wives captive. In practical and accessible language, Jones explains the stages of the healing journey (processing denial, asking for help, grieving, expressing anger, learning to forgive, and finding resolution). Building on that knowledge, Jones then moves to an honest discussion of what husbands can do to help. Whether it's creating a healing environment, understanding the need for control, building trust, or even just praying for healing, a husband plays an active role in helping his wife survive and thrive despite her past abuse.\\nOffering hope for a healthy marriage relationship, When a Woman You Love Was Abused answers the questions men have and offers the advice they need to help their wives finally find peace.\"},\n",
       "   {'rank': 6,\n",
       "    'book_id': '11714143',\n",
       "    'title': \"The Doctor's Mission\",\n",
       "    'authors': array([{'author_id': '4946642', 'role': ''}], dtype=object),\n",
       "    'average_rating': 4.0,\n",
       "    'similarity_score': 0.9943357110023499,\n",
       "    'approach': 'Multimodal',\n",
       "    'resnet_predicted_emotion': 'awe',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1313281835l/11714143.jpg',\n",
       "    'description': \"To save lives, she would risk her own\\nA woman doctor! Missionary William Mayweather can't hide his disappointment. The Nynabo mission in Liberia, Africa, desperately needs help, but he's vowed not to put another female in jeopardy. Too bad flame-haired Dr. Mary O'Hara refuses to turn back--and he cannot allow her to go into the jungle alone.\\nMedicine or marriage? For Mary, the choice was clear. Far away from the patriarchal medical community, she resolves to be of real service. She'll willingly go head-to-head with the handsome, opinionated missionary, even in the face of deadly danger. Yet the greatest tests lie in trusting God's plan--for the mission, and her future happiness in this untamed, beautiful land....\"}],\n",
       "  'bottom': [{'rank': 7,\n",
       "    'book_id': '92961',\n",
       "    'title': 'The Folk of the Fringe',\n",
       "    'authors': array([{'author_id': '589', 'role': ''}], dtype=object),\n",
       "    'average_rating': 3.31,\n",
       "    'similarity_score': 0.9939952492713928,\n",
       "    'approach': 'Multimodal',\n",
       "    'resnet_predicted_emotion': 'amusement',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1311989306l/92961.jpg',\n",
       "    'description': 'Only a few nuclear weapons fell in America-the weapons that destroyed our nation were biological and, ultimately, cultural. But in the chaos, the famine, the plague, there exited a few pockets of order. The strongest of them was the state of Deseret, formed from the vestiges of Utah, Colorado, and Idaho. The climate has changed. The Great Salt Lake has filled up to prehistoric levels. But there, on the fringes, brave, hardworking pioneers are making the desert bloom again.\\nA civilization cannot be reclaimed by powerful organizations, or even by great men alone. It must be renewed by individual men and women, one by one, working together to make a community, a nation, a new America.'},\n",
       "   {'rank': 8,\n",
       "    'book_id': '317567',\n",
       "    'title': 'Losing It All to Sprawl: How Progress Ate My Cracker Landscape',\n",
       "    'authors': array([{'author_id': '182530', 'role': ''},\n",
       "           {'author_id': '193010', 'role': 'Editor'},\n",
       "           {'author_id': '386240', 'role': 'Foreword by'}], dtype=object),\n",
       "    'average_rating': 4.15,\n",
       "    'similarity_score': 0.9939616322517395,\n",
       "    'approach': 'Multimodal',\n",
       "    'resnet_predicted_emotion': 'awe',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1344752725l/317567.jpg',\n",
       "    'description': 'As development threatens his very sense of place, an award-winning nature writer finds hope in the rediscovery and appreciation of his historic Cracker farmhouse.\\nLosing It All to Sprawlis the poignant chronicle of award-winning nature writer Bill Belleville and how he came to understand and love his historic Cracker farmhouse and \"relic\" neighborhood in central Florida, even as it was all wiped out from under him. Belleville\\'s narrative is eloquent, informed, and impassioned, a saga in which tractors and backhoes trample through the woods next to his home in order to build the backbone of Florida sprawl--the mall.\\nAs heavy machinery encircles Belleville and his community--the noise growing louder and closer, displacing everything Belleville has called home for the past fifteen years--he tells a story that is much older, 10,000 years older. The story stretches back to the Timucua and the Mayaca living in harmony with Florida\\'s environment; the conquistadors who expected much from, but also feared, this \"land of flowers\"; the turn-of-the-century tourists \"modernizing\" and \"climatizing\" the state; the original Cracker families who lived in Belleville\\'s farmhouse. In stark contrast to this millennia-long transformation is the whiplash of unbridled growth and development that threatens the nearby wilderness of the Wekiva River system, consuming Belleville\\'s home and, ultimately, his very sense of place.\\nIn Florida, one of the nation\\'s fastest growing states (and where local and state governments encourage growth), balancing use with preservation is an uphill battle. Sprawl spreads into the countryside, consuming not just natural lands but Old Florida neighborhoods and their unique history. In Losing It All to Sprawl, Belleville accounts for the impacts--social, political, natural, personal--that a community in the crosshairs of unsustainable growth ultimately must bear, but he also offers Floridians, and anyone facing the blight of urban confusion, the hope that can be found in the rediscovery and appreciation of the natural landscape.'},\n",
       "   {'rank': 9,\n",
       "    'book_id': '11311549',\n",
       "    'title': 'The Silence of Our Friends',\n",
       "    'authors': array([{'author_id': '286614', 'role': ''},\n",
       "           {'author_id': '4836266', 'role': ''},\n",
       "           {'author_id': '51924', 'role': 'Illustrator'}], dtype=object),\n",
       "    'average_rating': 3.86,\n",
       "    'similarity_score': 0.9934924840927124,\n",
       "    'approach': 'Multimodal',\n",
       "    'resnet_predicted_emotion': 'sadness',\n",
       "    'bert_predicted_emotion': 'sadness',\n",
       "    'image_url_large': 'https://images.gr-assets.com/books/1316731249l/11311549.jpg',\n",
       "    'description': \"In 1960s Texas, a white family from a notoriously racist neighborhood and a black family from its poorest ward cross Houston's color line, overcoming humiliation, degradation, and violence to win the freedom of five black college students unjustly charged with the murder of a policeman.\\nThe Silence of Our Friendsdraws from the childhood of Mark Long, who, with co-author Jim Demonakos, has created a powerful portrait of a volatile moment in US history. With art from the brilliant Nate Powell (Swallow Me Whole) bringing the tale to heart-wrenching life, The Silence of Our Friendsis a new and important entry in the body of civil rights literature.\"}]}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d39b1de-6e92-4ffb-9014-681ad9c36203",
   "metadata": {},
   "outputs": [],
   "source": [
    "A World War II romance about an American girl and a Japanese boy who have seen each other's lives in their sleep since birth. This is a 72-page, FULL COLOR graphic novel collecting the complete acclaimed DREAMLESS story in one handy printed volume! Written by MARRY ME and LAST BLOOD author Bobby Crosby, and beautifully painted by THE PHOENIX REQUIEM creator Sarah Ellerton."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
