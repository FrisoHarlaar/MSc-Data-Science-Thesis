{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565a1762-f292-40ab-920c-bd301e15141c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ FAISS available for ultra-fast similarity search\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path as osp\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchvision import models, transforms\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "from ast import literal_eval\n",
    "import unicodedata\n",
    "\n",
    "# Import artemis modules (same as your notebook)\n",
    "from artemis.emotions import ARTEMIS_EMOTIONS, IDX_TO_EMOTION\n",
    "from artemis.neural_models.resnet_encoder import ResnetEncoder\n",
    "from artemis.neural_models.mlp import MLP\n",
    "from artemis.neural_models.image_emotion_clf import ImageEmotionClassifier\n",
    "from artemis.in_out.neural_net_oriented import torch_load_model\n",
    "\n",
    "# Try to import FAISS for speed optimization\n",
    "try:\n",
    "    import faiss\n",
    "    FAISS_AVAILABLE = True\n",
    "    print(\"✓ FAISS available for ultra-fast similarity search\")\n",
    "except ImportError:\n",
    "    FAISS_AVAILABLE = False\n",
    "    print(\"⚠ FAISS not installed. Install with: pip install faiss-gpu (or faiss-cpu)\")\n",
    "    print(\"  This will provide 10-100x speedup for large datasets\")\n",
    "\n",
    "# Configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Updated Paths\n",
    "RESNET_MODEL_PATH = r'data/artemis/predictions/best_model_good_data.pt'\n",
    "BOOK_RESNET_PARQUET = r'goodreads_emotion_results/goodreads_emotion_predictions_english.parquet'\n",
    "BOOK_BERT_PARQUET = r'goodreads_bert_emotion_results/goodreads_bert_emotion_predictions_20250604_160958.parquet'\n",
    "PREPROCESSED_BOOK_PARQUET = r'preprocessed_books_2025_04_20.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8479fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CompleteImageBookMatcher:\n",
    "    \"\"\"\n",
    "    Complete system for matching image emotions with book emotion distributions\n",
    "    Merges image_url_large from original preprocessed books data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, use_gpu_similarity=True, precompute_indices=True):\n",
    "        self.emotion_labels = ARTEMIS_EMOTIONS\n",
    "        self.num_emotions = len(self.emotion_labels)\n",
    "        self.device = device\n",
    "        self.use_gpu_similarity = use_gpu_similarity and torch.cuda.is_available()\n",
    "        self.use_faiss = FAISS_AVAILABLE\n",
    "        \n",
    "        # Emotion column mapping based on your parquet structure\n",
    "        self.emotion_columns = [\n",
    "            'prob_amusement', 'prob_anger', 'prob_awe', 'prob_contentment',\n",
    "            'prob_disgust', 'prob_excitement', 'prob_fear', 'prob_sadness',\n",
    "            'prob_something_else'\n",
    "        ]\n",
    "        \n",
    "        print(\"=\"*80)\n",
    "        print(\"INITIALIZING COMPLETE IMAGE-BOOK EMOTION MATCHING SYSTEM\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # Load ResNet model (same architecture as your notebook)\n",
    "        print(\"Loading ResNet model...\")\n",
    "        self.resnet_model = self._load_resnet_model()\n",
    "        \n",
    "        # Load and preprocess book data with image URLs\n",
    "        print(\"Loading and preprocessing book emotion distributions with image URLs...\")\n",
    "        self.book_resnet_df, self.book_bert_df = self._load_book_data_with_images()\n",
    "        \n",
    "        # Precompute emotion matrices for fast similarity\n",
    "        print(\"Precomputing emotion matrices for fast similarity...\")\n",
    "        self._precompute_emotion_matrices()\n",
    "        \n",
    "        # Setup FAISS indices for ultra-fast similarity search\n",
    "        if precompute_indices and self.use_faiss:\n",
    "            print(\"Building FAISS indices for similarity search...\")\n",
    "            self._build_faiss_indices()\n",
    "        \n",
    "        # Image preprocessing (same as your notebook)\n",
    "        self.image_transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),  # Same as your notebook\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        print(f\"✓ System ready! Loaded {len(self.book_resnet_df)} books for matching\")\n",
    "        print(\"=\"*80)\n",
    "    \n",
    "    def _load_resnet_model(self):\n",
    "        \"\"\"Load ResNet model using exact same approach as your notebook\"\"\"\n",
    "        try:\n",
    "            # Load model exactly as in your notebook\n",
    "            model = torch_load_model(RESNET_MODEL_PATH)\n",
    "            model.to(self.device)\n",
    "            model.eval()\n",
    "            \n",
    "            # Test the model with a dummy input to make sure it works\n",
    "            with torch.no_grad():\n",
    "                dummy_input = torch.randn(1, 3, 256, 256).to(self.device)\n",
    "                _ = model(dummy_input)\n",
    "            \n",
    "            print(\"✓ ResNet model loaded and tested successfully\")\n",
    "            return model\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading ResNet model: {e}\")\n",
    "            print(\"Creating dummy ResNet for testing...\")\n",
    "            return self._create_dummy_resnet()\n",
    "    \n",
    "    def _create_dummy_resnet(self):\n",
    "        \"\"\"Create dummy ResNet for testing if model loading fails\"\"\"\n",
    "        print(\"⚠ Using dummy ResNet model for testing\")\n",
    "        model = models.resnet34(weights='IMAGENET1K_V1')\n",
    "        model.fc = nn.Linear(model.fc.in_features, self.num_emotions)\n",
    "        model.to(self.device)\n",
    "        model.eval()\n",
    "        return model\n",
    "    \n",
    "    def _load_book_data_with_images(self):\n",
    "        \"\"\"Load book data and merge with image URLs from preprocessed books\"\"\"\n",
    "        try:\n",
    "            print(\"Loading preprocessed books data for image URLs...\")\n",
    "            # Load only book_id and image_url_large from preprocessed books\n",
    "            preprocessed_df = pd.read_parquet(PREPROCESSED_BOOK_PARQUET, \n",
    "                                            columns=['book_id', 'image_url_large', 'description'])\n",
    "            print(f\"✓ Loaded {len(preprocessed_df)} books from preprocessed data\")\n",
    "            print(f\"✓ Found {len(preprocessed_df[preprocessed_df['image_url_large'].notna()])} books with image URLs\")\n",
    "            \n",
    "            # Load emotion prediction data\n",
    "            print(\"Loading ResNet emotion predictions...\")\n",
    "            book_resnet_df = pd.read_parquet(BOOK_RESNET_PARQUET)\n",
    "            \n",
    "            print(\"Loading BERT emotion predictions...\")\n",
    "            book_bert_df = pd.read_parquet(BOOK_BERT_PARQUET)\n",
    "            \n",
    "            print(f\"✓ Loaded ResNet emotions for {len(book_resnet_df)} books\")\n",
    "            print(f\"✓ Loaded BERT emotions for {len(book_bert_df)} books\")\n",
    "            \n",
    "            # Merge with image URLs\n",
    "            print(\"Merging ResNet data with image URLs...\")\n",
    "            book_resnet_df = book_resnet_df.merge(\n",
    "                preprocessed_df[['book_id', 'image_url_large', 'description']], \n",
    "                on='book_id', \n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            print(\"Merging BERT data with image URLs...\")\n",
    "            book_bert_df = book_bert_df.merge(\n",
    "                preprocessed_df[['book_id', 'image_url_large', 'description']], \n",
    "                on='book_id', \n",
    "                how='left'\n",
    "            )\n",
    "            \n",
    "            # Keep only books that exist in both datasets for multimodal comparison\n",
    "            common_book_ids = set(book_resnet_df['book_id']).intersection(\n",
    "                set(book_bert_df['book_id'])\n",
    "            )\n",
    "            \n",
    "            book_resnet_df = book_resnet_df[book_resnet_df['book_id'].isin(common_book_ids)]\n",
    "            book_bert_df = book_bert_df[book_bert_df['book_id'].isin(common_book_ids)]\n",
    "            \n",
    "            # Sort by book_id for faster merging later\n",
    "            book_resnet_df = book_resnet_df.sort_values('book_id').reset_index(drop=True)\n",
    "            book_bert_df = book_bert_df.sort_values('book_id').reset_index(drop=True)\n",
    "            \n",
    "            # Count books with image URLs\n",
    "            resnet_with_images = len(book_resnet_df[book_resnet_df['image_url_large'].notna()])\n",
    "            bert_with_images = len(book_bert_df[book_bert_df['image_url_large'].notna()])\n",
    "            \n",
    "            print(f\"✓ Final dataset: {len(book_resnet_df)} books with both ResNet and BERT predictions\")\n",
    "            print(f\"✓ ResNet books with image URLs: {resnet_with_images}\")\n",
    "            print(f\"✓ BERT books with image URLs: {bert_with_images}\")\n",
    "            \n",
    "            return book_resnet_df, book_bert_df\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading book data: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            return self._create_dummy_book_data()\n",
    "    \n",
    "    def _create_dummy_book_data(self):\n",
    "        \"\"\"Create dummy book data for testing\"\"\"\n",
    "        print(\"⚠ Creating dummy book data for testing\")\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        n_books = 1000  # Smaller for testing\n",
    "        book_ids = [f\"book_{i}\" for i in range(n_books)]\n",
    "        titles = [f\"Test Book Title {i}\" for i in range(n_books)]\n",
    "        authors = [[{'author_id': str(i), 'role': f'Test Author {i}'}] for i in range(n_books)]\n",
    "        \n",
    "        # Create dummy emotion probabilities\n",
    "        emotion_probs = np.random.dirichlet(np.ones(self.num_emotions), n_books)\n",
    "        \n",
    "        # Create ResNet dataframe\n",
    "        resnet_data = {\n",
    "            'book_id': book_ids,\n",
    "            'title': titles,\n",
    "            'authors': authors,\n",
    "            'average_rating': np.random.uniform(3.0, 5.0, n_books),\n",
    "            'predicted_emotion': [self.emotion_labels[np.argmax(probs)] for probs in emotion_probs],\n",
    "            'confidence': [np.max(probs) for probs in emotion_probs],\n",
    "            'image_url_large': [f'https://example.com/cover_{i}.jpg' for i in range(n_books)]\n",
    "        }\n",
    "        \n",
    "        # Add emotion probability columns\n",
    "        for i, col in enumerate(self.emotion_columns):\n",
    "            resnet_data[col] = emotion_probs[:, i]\n",
    "        \n",
    "        resnet_df = pd.DataFrame(resnet_data)\n",
    "        \n",
    "        # Create BERT dataframe (different emotion distributions)\n",
    "        bert_emotion_probs = np.random.dirichlet(np.ones(self.num_emotions), n_books)\n",
    "        bert_data = resnet_data.copy()\n",
    "        bert_data['predicted_emotion'] = [self.emotion_labels[np.argmax(probs)] for probs in bert_emotion_probs]\n",
    "        bert_data['confidence'] = [np.max(probs) for probs in bert_emotion_probs]\n",
    "        \n",
    "        for i, col in enumerate(self.emotion_columns):\n",
    "            bert_data[col] = bert_emotion_probs[:, i]\n",
    "        \n",
    "        bert_df = pd.DataFrame(bert_data)\n",
    "        \n",
    "        return resnet_df, bert_df\n",
    "    \n",
    "    def _precompute_emotion_matrices(self):\n",
    "        \"\"\"Precompute emotion matrices for vectorized operations\"\"\"\n",
    "        # Extract emotion matrices as numpy arrays for fast computation\n",
    "        self.resnet_emotions_matrix = self.book_resnet_df[self.emotion_columns].values.astype(np.float32)\n",
    "        self.bert_emotions_matrix = self.book_bert_df[self.emotion_columns].values.astype(np.float32)\n",
    "        \n",
    "        # Extract confidence arrays\n",
    "        self.resnet_confidences = self.book_resnet_df['confidence'].values.astype(np.float32)\n",
    "        self.bert_confidences = self.book_bert_df['confidence'].values.astype(np.float32)\n",
    "        \n",
    "        # Precompute combined emotions for all books\n",
    "        print(\"Precomputing multimodal combinations...\")\n",
    "        self._precompute_multimodal_emotions()\n",
    "        \n",
    "        # Convert to GPU tensors if using GPU acceleration\n",
    "        if self.use_gpu_similarity:\n",
    "            print(\"Moving emotion matrices to GPU for fast similarity...\")\n",
    "            self.resnet_emotions_gpu = torch.from_numpy(self.resnet_emotions_matrix).to(self.device)\n",
    "            self.bert_emotions_gpu = torch.from_numpy(self.bert_emotions_matrix).to(self.device)\n",
    "            self.multimodal_emotions_gpu = torch.from_numpy(self.multimodal_emotions_matrix).to(self.device)\n",
    "    \n",
    "    def _precompute_multimodal_emotions(self):\n",
    "        \"\"\"Precompute confidence-weighted combinations for all books\"\"\"\n",
    "        # Vectorized confidence weighting\n",
    "        total_confidences = self.resnet_confidences + self.bert_confidences\n",
    "        resnet_weights = self.resnet_confidences / total_confidences\n",
    "        bert_weights = self.bert_confidences / total_confidences\n",
    "        \n",
    "        # Vectorized combination\n",
    "        self.multimodal_emotions_matrix = (\n",
    "            resnet_weights[:, np.newaxis] * self.resnet_emotions_matrix +\n",
    "            bert_weights[:, np.newaxis] * self.bert_emotions_matrix\n",
    "        )\n",
    "        \n",
    "        # Normalize to ensure proper probability distributions\n",
    "        row_sums = self.multimodal_emotions_matrix.sum(axis=1, keepdims=True)\n",
    "        self.multimodal_emotions_matrix = self.multimodal_emotions_matrix / row_sums\n",
    "        \n",
    "        # Store weights for later use\n",
    "        self.resnet_weights = resnet_weights\n",
    "        self.bert_weights = bert_weights\n",
    "    \n",
    "    def _build_faiss_indices(self):\n",
    "        \"\"\"Build FAISS indices for ultra-fast similarity search\"\"\"\n",
    "        if not FAISS_AVAILABLE:\n",
    "            self.use_faiss = False\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            # Build indices for each emotion type\n",
    "            dimension = self.num_emotions\n",
    "            \n",
    "            # ResNet index\n",
    "            self.resnet_index = faiss.IndexFlatIP(dimension)  # Inner product (cosine after normalization)\n",
    "            resnet_normalized = self.resnet_emotions_matrix / np.linalg.norm(\n",
    "                self.resnet_emotions_matrix, axis=1, keepdims=True\n",
    "            )\n",
    "            self.resnet_index.add(resnet_normalized.astype('float32'))\n",
    "            \n",
    "            # BERT index\n",
    "            self.bert_index = faiss.IndexFlatIP(dimension)\n",
    "            bert_normalized = self.bert_emotions_matrix / np.linalg.norm(\n",
    "                self.bert_emotions_matrix, axis=1, keepdims=True\n",
    "            )\n",
    "            self.bert_index.add(bert_normalized.astype('float32'))\n",
    "            \n",
    "            # Multimodal index\n",
    "            self.multimodal_index = faiss.IndexFlatIP(dimension)\n",
    "            multimodal_normalized = self.multimodal_emotions_matrix / np.linalg.norm(\n",
    "                self.multimodal_emotions_matrix, axis=1, keepdims=True\n",
    "            )\n",
    "            self.multimodal_index.add(multimodal_normalized.astype('float32'))\n",
    "            \n",
    "            # Move to GPU if available\n",
    "            if faiss.get_num_gpus() > 0:\n",
    "                self.resnet_index = faiss.index_cpu_to_gpu(faiss.StandardGpuResources(), 0, self.resnet_index)\n",
    "                self.bert_index = faiss.index_cpu_to_gpu(faiss.StandardGpuResources(), 0, self.bert_index)\n",
    "                self.multimodal_index = faiss.index_cpu_to_gpu(faiss.StandardGpuResources(), 0, self.multimodal_index)\n",
    "                print(\"✓ FAISS indices moved to GPU\")\n",
    "            \n",
    "            self.use_faiss = True\n",
    "            print(\"✓ FAISS indices built successfully\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error building FAISS indices: {e}\")\n",
    "            self.use_faiss = False\n",
    "    \n",
    "    def predict_image_emotions(self, image_path):\n",
    "        \"\"\"Predict emotions for an input image using ResNet (same as your notebook)\"\"\"\n",
    "        try:\n",
    "            # Load and preprocess image (same as notebook preprocessing)\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            image_tensor = self.image_transform(image).unsqueeze(0).to(self.device)\n",
    "            \n",
    "            # Fast inference with no gradient computation\n",
    "            with torch.no_grad():\n",
    "                # Model outputs log probabilities (LogSoftmax), so we need to exp them\n",
    "                log_probs = self.resnet_model(image_tensor)\n",
    "                probs = torch.exp(log_probs).cpu().numpy()[0]  # Convert to probabilities\n",
    "                confidence = float(torch.max(torch.exp(log_probs)).cpu())\n",
    "            \n",
    "            return {\n",
    "                'emotion_distribution': probs,\n",
    "                'confidence': confidence,\n",
    "                'dominant_emotion': self.emotion_labels[np.argmax(probs)],\n",
    "                'emotion_scores': dict(zip(self.emotion_labels, probs))\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error predicting image emotions: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            \n",
    "            uniform_probs = np.ones(self.num_emotions) / self.num_emotions\n",
    "            return {\n",
    "                'emotion_distribution': uniform_probs,\n",
    "                'confidence': 1.0 / self.num_emotions,\n",
    "                'dominant_emotion': self.emotion_labels[0],\n",
    "                'emotion_scores': dict(zip(self.emotion_labels, uniform_probs))\n",
    "            }\n",
    "    \n",
    "    def fast_similarity_search(self, image_emotions, top_k=1000):\n",
    "        \"\"\"Ultra-fast similarity search using FAISS or GPU acceleration\"\"\"\n",
    "        if self.use_faiss:\n",
    "            return self._faiss_similarity_search(image_emotions, top_k)\n",
    "        elif self.use_gpu_similarity:\n",
    "            return self._gpu_similarity_search(image_emotions, top_k)\n",
    "        else:\n",
    "            return self._cpu_similarity_search(image_emotions, top_k)\n",
    "    \n",
    "    def _faiss_similarity_search(self, image_emotions, top_k):\n",
    "        \"\"\"FAISS-based similarity search (fastest)\"\"\"\n",
    "        # Normalize query\n",
    "        query = image_emotions / np.linalg.norm(image_emotions)\n",
    "        query = query.reshape(1, -1).astype('float32')\n",
    "        \n",
    "        # Search all three indices\n",
    "        resnet_scores, resnet_indices = self.resnet_index.search(query, top_k)\n",
    "        bert_scores, bert_indices = self.bert_index.search(query, top_k)\n",
    "        multimodal_scores, multimodal_indices = self.multimodal_index.search(query, top_k)\n",
    "        \n",
    "        return {\n",
    "            'resnet': {'scores': resnet_scores[0], 'indices': resnet_indices[0]},\n",
    "            'bert': {'scores': bert_scores[0], 'indices': bert_indices[0]},\n",
    "            'multimodal': {'scores': multimodal_scores[0], 'indices': multimodal_indices[0]}\n",
    "        }\n",
    "    \n",
    "    def _gpu_similarity_search(self, image_emotions, top_k):\n",
    "        \"\"\"GPU-accelerated similarity search\"\"\"\n",
    "        # Convert to GPU tensor\n",
    "        image_tensor = torch.from_numpy(image_emotions).to(self.device).float()\n",
    "        image_tensor = image_tensor / torch.norm(image_tensor)  # Normalize\n",
    "        \n",
    "        # Compute similarities using matrix multiplication\n",
    "        resnet_similarities = torch.mm(image_tensor.unsqueeze(0), self.resnet_emotions_gpu.t()).squeeze()\n",
    "        bert_similarities = torch.mm(image_tensor.unsqueeze(0), self.bert_emotions_gpu.t()).squeeze()\n",
    "        multimodal_similarities = torch.mm(image_tensor.unsqueeze(0), self.multimodal_emotions_gpu.t()).squeeze()\n",
    "        \n",
    "        # Get top-k\n",
    "        resnet_top_k = torch.topk(resnet_similarities, min(top_k, len(resnet_similarities)))\n",
    "        bert_top_k = torch.topk(bert_similarities, min(top_k, len(bert_similarities)))\n",
    "        multimodal_top_k = torch.topk(multimodal_similarities, min(top_k, len(multimodal_similarities)))\n",
    "        \n",
    "        return {\n",
    "            'resnet': {\n",
    "                'scores': resnet_top_k.values.cpu().numpy(),\n",
    "                'indices': resnet_top_k.indices.cpu().numpy()\n",
    "            },\n",
    "            'bert': {\n",
    "                'scores': bert_top_k.values.cpu().numpy(), \n",
    "                'indices': bert_top_k.indices.cpu().numpy()\n",
    "            },\n",
    "            'multimodal': {\n",
    "                'scores': multimodal_top_k.values.cpu().numpy(),\n",
    "                'indices': multimodal_top_k.indices.cpu().numpy()\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _cpu_similarity_search(self, image_emotions, top_k):\n",
    "        \"\"\"CPU-based similarity search (fallback)\"\"\"\n",
    "        # Compute cosine similarities\n",
    "        resnet_similarities = cosine_similarity([image_emotions], self.resnet_emotions_matrix)[0]\n",
    "        bert_similarities = cosine_similarity([image_emotions], self.bert_emotions_matrix)[0]\n",
    "        multimodal_similarities = cosine_similarity([image_emotions], self.multimodal_emotions_matrix)[0]\n",
    "        \n",
    "        # Get top-k indices\n",
    "        resnet_top_indices = np.argpartition(resnet_similarities, -top_k)[-top_k:]\n",
    "        bert_top_indices = np.argpartition(bert_similarities, -top_k)[-top_k:]\n",
    "        multimodal_top_indices = np.argpartition(multimodal_similarities, -top_k)[-top_k:]\n",
    "        \n",
    "        # Sort by similarity\n",
    "        resnet_top_indices = resnet_top_indices[np.argsort(resnet_similarities[resnet_top_indices])[::-1]]\n",
    "        bert_top_indices = bert_top_indices[np.argsort(bert_similarities[bert_top_indices])[::-1]]\n",
    "        multimodal_top_indices = multimodal_top_indices[np.argsort(multimodal_similarities[multimodal_top_indices])[::-1]]\n",
    "        \n",
    "        return {\n",
    "            'resnet': {\n",
    "                'scores': resnet_similarities[resnet_top_indices],\n",
    "                'indices': resnet_top_indices\n",
    "            },\n",
    "            'bert': {\n",
    "                'scores': bert_similarities[bert_top_indices],\n",
    "                'indices': bert_top_indices\n",
    "            },\n",
    "            'multimodal': {\n",
    "                'scores': multimodal_similarities[multimodal_top_indices],\n",
    "                'indices': multimodal_top_indices\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def find_similar_books_complete(self, image_path, top_k=1000, final_n=3):\n",
    "        \"\"\"Complete book similarity search with all optimizations\"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Predict image emotions\n",
    "        image_prediction = self.predict_image_emotions(image_path)\n",
    "        image_emotions = image_prediction['emotion_distribution']\n",
    "        \n",
    "        print(f\"Image prediction took {time.time() - start_time:.3f}s\")\n",
    "        print(f\"Image dominant emotion: {image_prediction['dominant_emotion']}\")\n",
    "        print(f\"Image confidence: {image_prediction['confidence']:.3f}\")\n",
    "        \n",
    "        # Fast similarity search - get ALL books, not just top_k\n",
    "        search_start = time.time()\n",
    "        total_books = len(self.book_resnet_df)\n",
    "        search_results = self.fast_similarity_search(image_emotions, total_books)  # Get all books\n",
    "        print(f\"Similarity search took {time.time() - search_start:.3f}s\")\n",
    "        \n",
    "        # Extract top, middle, bottom recommendations for each approach\n",
    "        def extract_recommendations(scores, indices, approach_name):\n",
    "            total_results = len(scores)\n",
    "            \n",
    "            # Top N most similar (highest scores)\n",
    "            top_indices = indices[:final_n]\n",
    "            top_scores = scores[:final_n]\n",
    "            \n",
    "            # Middle N (around the median)\n",
    "            middle_start = max(0, (total_results // 2) - (final_n // 2))\n",
    "            middle_end = min(total_results, middle_start + final_n)\n",
    "            middle_indices = indices[middle_start:middle_end]\n",
    "            middle_scores = scores[middle_start:middle_end]\n",
    "            \n",
    "            # Bottom N least similar (lowest scores)\n",
    "            bottom_indices = indices[-final_n:]\n",
    "            bottom_scores = scores[-final_n:]\n",
    "            \n",
    "            # Create recommendation objects\n",
    "            def create_recommendations(rec_indices, rec_scores, category):\n",
    "                recommendations = []\n",
    "                for i, (idx, score) in enumerate(zip(rec_indices, rec_scores)):\n",
    "                    book_row = self.book_resnet_df.iloc[idx]  # Use ResNet df for metadata\n",
    "                    bert_row = self.book_bert_df.iloc[idx]    # Get BERT data for emotions\n",
    "                    \n",
    "                    recommendations.append({\n",
    "                        'rank': i + 1,\n",
    "                        'book_id': book_row['book_id'],\n",
    "                        'title': book_row['title'],\n",
    "                        'authors': book_row['authors'],\n",
    "                        'average_rating': book_row.get('average_rating', 'N/A'),\n",
    "                        'similarity_score': float(score),\n",
    "                        'approach': approach_name,\n",
    "                        'category': category,\n",
    "                        'global_rank': int(np.where(indices == idx)[0][0] + 1),  # Rank among all books\n",
    "                        'resnet_predicted_emotion': book_row['predicted_emotion'],\n",
    "                        'bert_predicted_emotion': bert_row['predicted_emotion'],\n",
    "                        'image_url_large': book_row.get('image_url_large', 'No cover URL'),\n",
    "                        'description': book_row.get('description', None)\n",
    "                    })\n",
    "                return recommendations\n",
    "            \n",
    "            top_recommendations = create_recommendations(top_indices, top_scores, 'top')\n",
    "            middle_recommendations = create_recommendations(middle_indices, middle_scores, 'middle')\n",
    "            bottom_recommendations = create_recommendations(bottom_indices, bottom_scores, 'bottom')\n",
    "            \n",
    "            return top_recommendations, middle_recommendations, bottom_recommendations\n",
    "        \n",
    "        # Extract recommendations for each approach\n",
    "        resnet_top, resnet_middle, resnet_bottom = extract_recommendations(\n",
    "            search_results['resnet']['scores'], search_results['resnet']['indices'], 'ResNet'\n",
    "        )\n",
    "        \n",
    "        bert_top, bert_middle, bert_bottom = extract_recommendations(\n",
    "            search_results['bert']['scores'], search_results['bert']['indices'], 'BERT'\n",
    "        )\n",
    "        \n",
    "        multimodal_top, multimodal_middle, multimodal_bottom = extract_recommendations(\n",
    "            search_results['multimodal']['scores'], search_results['multimodal']['indices'], 'Multimodal'\n",
    "        )\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"Total processing time: {total_time:.3f}s for {len(self.book_resnet_df)} books\")\n",
    "        \n",
    "        # Print summary of what we found\n",
    "        print(f\"\\n📊 SIMILARITY SUMMARY:\")\n",
    "        print(f\"   ResNet: Best={resnet_top[0]['similarity_score']:.4f}, \"\n",
    "            f\"Middle={resnet_middle[0]['similarity_score']:.4f}, \"\n",
    "            f\"Worst={resnet_bottom[0]['similarity_score']:.4f}\")\n",
    "        print(f\"   BERT: Best={bert_top[0]['similarity_score']:.4f}, \"\n",
    "            f\"Middle={bert_middle[0]['similarity_score']:.4f}, \"\n",
    "            f\"Worst={bert_bottom[0]['similarity_score']:.4f}\")\n",
    "        print(f\"   Multimodal: Best={multimodal_top[0]['similarity_score']:.4f}, \"\n",
    "            f\"Middle={multimodal_middle[0]['similarity_score']:.4f}, \"\n",
    "            f\"Worst={multimodal_bottom[0]['similarity_score']:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'image_prediction': image_prediction,\n",
    "            'processing_time': total_time,\n",
    "            'total_books_analyzed': total_books,\n",
    "            'resnet_recommendations': {\n",
    "                'top': resnet_top,\n",
    "                'middle': resnet_middle,\n",
    "                'bottom': resnet_bottom\n",
    "            },\n",
    "            'bert_recommendations': {\n",
    "                'top': bert_top,\n",
    "                'middle': bert_middle,\n",
    "                'bottom': bert_bottom\n",
    "            },\n",
    "            'multimodal_recommendations': {\n",
    "                'top': multimodal_top,\n",
    "                'middle': multimodal_middle,\n",
    "                'bottom': multimodal_bottom\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def display_emotion_distributions(self, results, show_plots=True):\n",
    "        \"\"\"Display and compare emotion distributions between image and recommendations\"\"\"\n",
    "        \n",
    "        print(\"\\n\" + \"🎭\" * 80)\n",
    "        print(\"EMOTION DISTRIBUTION ANALYSIS\")\n",
    "        print(\"🎭\" * 80)\n",
    "        \n",
    "        # Get image emotion distribution\n",
    "        image_emotions = results['image_prediction']['emotion_distribution']\n",
    "        image_scores = results['image_prediction']['emotion_scores']\n",
    "        \n",
    "        print(f\"\\n📸 INPUT IMAGE EMOTION DISTRIBUTION:\")\n",
    "        print(f\"   Dominant: {results['image_prediction']['dominant_emotion']} (confidence: {results['image_prediction']['confidence']:.3f})\")\n",
    "        print(\"   Full Distribution:\")\n",
    "        \n",
    "        # Display image emotions in a nice format\n",
    "        for emotion, score in image_scores.items():\n",
    "            bar_length = int(score * 50)  # Scale to 50 characters\n",
    "            bar = \"█\" * bar_length + \"░\" * (50 - bar_length)\n",
    "            print(f\"   {emotion:15s} │{bar}│ {score:.3f}\")\n",
    "        \n",
    "        print(\"\\n\" + \"─\" * 80)\n",
    "        \n",
    "        # Compare with top recommendations from each approach\n",
    "        approaches = [\n",
    "            ('🧠 RESNET RECOMMENDATIONS', results['resnet_recommendations']),\n",
    "            ('📝 BERT RECOMMENDATIONS', results['bert_recommendations']), \n",
    "            ('🔗 MULTIMODAL RECOMMENDATIONS', results['multimodal_recommendations'])\n",
    "        ]\n",
    "        \n",
    "        for approach_name, recommendations in approaches:\n",
    "            print(f\"\\n{approach_name}\")\n",
    "            print(\"─\" * 80)\n",
    "            \n",
    "            # Show top 3 books from this approach\n",
    "            for i, book in enumerate(recommendations['top'], 1):\n",
    "                print(f\"\\n📚 {i}. {book['title'][:50]}{'...' if len(book['title']) > 50 else ''}\")\n",
    "                print(f\"   📊 Similarity Score: {book['similarity_score']:.4f}\")\n",
    "                print(f\"   🎯 Predicted Emotion: {book.get('resnet_predicted_emotion', 'N/A')}\")\n",
    "                \n",
    "                # Get book's emotion distribution\n",
    "                book_idx = self._get_book_index(book['book_id'])\n",
    "                if book_idx is not None:\n",
    "                    if 'resnet' in approach_name.lower():\n",
    "                        book_emotions = self.resnet_emotions_matrix[book_idx]\n",
    "                    elif 'bert' in approach_name.lower():\n",
    "                        book_emotions = self.bert_emotions_matrix[book_idx]\n",
    "                    else:  # multimodal\n",
    "                        book_emotions = self.multimodal_emotions_matrix[book_idx]\n",
    "                    \n",
    "                    print(f\"   📈 Book Emotion Distribution:\")\n",
    "                    \n",
    "                    # Calculate similarity metrics\n",
    "                    cosine_sim = np.dot(image_emotions, book_emotions) / (\n",
    "                        np.linalg.norm(image_emotions) * np.linalg.norm(book_emotions))\n",
    "                    kl_div = self._calculate_kl_divergence(image_emotions, book_emotions)\n",
    "                    \n",
    "                    print(f\"   🔍 Cosine Similarity: {cosine_sim:.4f}\")\n",
    "                    print(f\"   📏 KL Divergence: {kl_div:.4f}\")\n",
    "                    \n",
    "                    # Show emotion-by-emotion comparison\n",
    "                    for j, emotion in enumerate(self.emotion_labels):\n",
    "                        img_score = image_emotions[j]\n",
    "                        book_score = book_emotions[j]\n",
    "                        diff = book_score - img_score\n",
    "                        \n",
    "                        # Visual bars\n",
    "                        img_bar_length = int(img_score * 30)\n",
    "                        book_bar_length = int(book_score * 30)\n",
    "                        img_bar = \"█\" * img_bar_length + \"░\" * (30 - img_bar_length)\n",
    "                        book_bar = \"█\" * book_bar_length + \"░\" * (30 - book_bar_length)\n",
    "                        \n",
    "                        # Color code the difference\n",
    "                        if abs(diff) < 0.05:\n",
    "                            diff_icon = \"≈\"\n",
    "                        elif diff > 0:\n",
    "                            diff_icon = \"↗\"\n",
    "                        else:\n",
    "                            diff_icon = \"↘\"\n",
    "                        \n",
    "                        print(f\"   {emotion:13s} │Img:{img_bar}│{img_score:.3f} │Book:{book_bar}│{book_score:.3f} {diff_icon}\")\n",
    "                    \n",
    "                    print(\"   \" + \"─\" * 70)\n",
    "        \n",
    "        # Create visualization plots if requested\n",
    "        if show_plots:\n",
    "            self._create_emotion_distribution_plots(results)\n",
    "    \n",
    "    def _get_book_index(self, book_id):\n",
    "        \"\"\"Get the index of a book in the dataframe by book_id\"\"\"\n",
    "        try:\n",
    "            # Find index in resnet dataframe (they should be aligned)\n",
    "            mask = self.book_resnet_df['book_id'] == book_id\n",
    "            indices = np.where(mask)[0]\n",
    "            if len(indices) > 0:\n",
    "                return indices[0]\n",
    "            return None\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def _calculate_kl_divergence(self, p, q, epsilon=1e-8):\n",
    "        \"\"\"Calculate KL divergence between two probability distributions\"\"\"\n",
    "        # Add small epsilon to avoid log(0)\n",
    "        p = np.clip(p, epsilon, 1.0)\n",
    "        q = np.clip(q, epsilon, 1.0)\n",
    "        \n",
    "        # Normalize to ensure they sum to 1\n",
    "        p = p / np.sum(p)\n",
    "        q = q / np.sum(q)\n",
    "        \n",
    "        return np.sum(p * np.log(p / q))\n",
    "    \n",
    "    def _create_emotion_distribution_plots(self, results):\n",
    "        \"\"\"Create visual plots comparing emotion distributions\"\"\"\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            import seaborn as sns\n",
    "            \n",
    "            # Set up the plotting style\n",
    "            plt.style.use('default')\n",
    "            sns.set_palette(\"husl\")\n",
    "            \n",
    "            # Create subplots: 2 rows x 2 cols\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "            fig.suptitle('Emotion Distribution Comparison', fontsize=16, fontweight='bold')\n",
    "            \n",
    "            # Get image emotions\n",
    "            image_emotions = results['image_prediction']['emotion_distribution']\n",
    "            \n",
    "            # Plot 1: Image emotion distribution\n",
    "            ax1 = axes[0, 0]\n",
    "            bars1 = ax1.bar(self.emotion_labels, image_emotions, alpha=0.7, color='skyblue')\n",
    "            ax1.set_title(f\"Input Image\\n(Dominant: {results['image_prediction']['dominant_emotion']})\", \n",
    "                         fontweight='bold')\n",
    "            ax1.set_ylabel('Probability')\n",
    "            ax1.tick_params(axis='x', rotation=45)\n",
    "            \n",
    "            # Add value labels on bars\n",
    "            for bar, val in zip(bars1, image_emotions):\n",
    "                ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                        f'{val:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "            \n",
    "            # Plot 2-4: Top recommendation from each approach\n",
    "            approaches = [\n",
    "                ('ResNet Top Match', results['resnet_recommendations']['top'][0], self.resnet_emotions_matrix),\n",
    "                ('BERT Top Match', results['bert_recommendations']['top'][0], self.bert_emotions_matrix),\n",
    "                ('Multimodal Top Match', results['multimodal_recommendations']['top'][0], self.multimodal_emotions_matrix)\n",
    "            ]\n",
    "            \n",
    "            ax_positions = [(0, 1), (1, 0), (1, 1)]\n",
    "            colors = ['lightcoral', 'lightgreen', 'lightsalmon']\n",
    "            \n",
    "            for i, ((title, book, emotion_matrix), ax_pos, color) in enumerate(zip(approaches, ax_positions, colors)):\n",
    "                ax = axes[ax_pos[0], ax_pos[1]]\n",
    "                \n",
    "                # Get book emotions\n",
    "                book_idx = self._get_book_index(book['book_id'])\n",
    "                if book_idx is not None:\n",
    "                    book_emotions = emotion_matrix[book_idx]\n",
    "                    \n",
    "                    # Create comparison bars\n",
    "                    x = np.arange(len(self.emotion_labels))\n",
    "                    width = 0.35\n",
    "                    \n",
    "                    bars1 = ax.bar(x - width/2, image_emotions, width, label='Input Image', \n",
    "                                  alpha=0.7, color='skyblue')\n",
    "                    bars2 = ax.bar(x + width/2, book_emotions, width, label='Book', \n",
    "                                  alpha=0.7, color=color)\n",
    "                    \n",
    "                    # Formatting\n",
    "                    book_title = book['title'][:25] + '...' if len(book['title']) > 25 else book['title']\n",
    "                    ax.set_title(f\"{title}\\n{book_title}\\nSim: {book['similarity_score']:.3f}\", \n",
    "                               fontweight='bold', fontsize=10)\n",
    "                    ax.set_ylabel('Probability')\n",
    "                    ax.set_xticks(x)\n",
    "                    ax.set_xticklabels(self.emotion_labels, rotation=45, ha='right')\n",
    "                    ax.legend()\n",
    "                    \n",
    "                    # Add difference annotations\n",
    "                    for j, (img_val, book_val) in enumerate(zip(image_emotions, book_emotions)):\n",
    "                        diff = book_val - img_val\n",
    "                        if abs(diff) > 0.1:  # Only show significant differences\n",
    "                            ax.annotate(f'{diff:+.2f}', \n",
    "                                      xy=(j, max(img_val, book_val) + 0.02),\n",
    "                                      ha='center', va='bottom', fontsize=8,\n",
    "                                      color='red' if diff > 0 else 'blue')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Create a heatmap comparison\n",
    "            self._create_emotion_heatmap(results)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Could not create emotion distribution plots: {e}\")\n",
    "            print(\"Install required packages: pip install matplotlib seaborn\")\n",
    "    \n",
    "    def _create_emotion_heatmap(self, results):\n",
    "        \"\"\"Create a heatmap showing emotion similarities across all recommendations\"\"\"\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            import seaborn as sns\n",
    "            \n",
    "            # Collect all emotion distributions\n",
    "            image_emotions = results['image_prediction']['emotion_distribution']\n",
    "            \n",
    "            # Get top recommendations from each approach\n",
    "            all_books = []\n",
    "            all_emotions = []\n",
    "            labels = ['Input Image']\n",
    "            all_emotions.append(image_emotions)\n",
    "            \n",
    "            approaches = [\n",
    "                ('ResNet', results['resnet_recommendations']['top'][:3], self.resnet_emotions_matrix),\n",
    "                ('BERT', results['bert_recommendations']['top'][:3], self.bert_emotions_matrix),\n",
    "                ('Multimodal', results['multimodal_recommendations']['top'][:3], self.multimodal_emotions_matrix)\n",
    "            ]\n",
    "            \n",
    "            for approach_name, books, emotion_matrix in approaches:\n",
    "                for i, book in enumerate(books, 1):\n",
    "                    book_idx = self._get_book_index(book['book_id'])\n",
    "                    if book_idx is not None:\n",
    "                        book_emotions = emotion_matrix[book_idx]\n",
    "                        all_emotions.append(book_emotions)\n",
    "                        \n",
    "                        book_title = book['title'][:20] + '...' if len(book['title']) > 20 else book['title']\n",
    "                        labels.append(f\"{approach_name}-{i}\\n{book_title}\")\n",
    "            \n",
    "            # Create emotion matrix\n",
    "            emotion_matrix = np.array(all_emotions)\n",
    "            \n",
    "            # Create heatmap\n",
    "            plt.figure(figsize=(12, 10))\n",
    "            sns.heatmap(emotion_matrix, \n",
    "                       xticklabels=self.emotion_labels,\n",
    "                       yticklabels=labels,\n",
    "                       annot=True, \n",
    "                       fmt='.3f',\n",
    "                       cmap='YlOrRd',\n",
    "                       cbar_kws={'label': 'Emotion Probability'})\n",
    "            \n",
    "            plt.title('Emotion Distribution Heatmap\\nImage vs Top Book Recommendations', \n",
    "                     fontsize=14, fontweight='bold', pad=20)\n",
    "            plt.xlabel('Emotions', fontweight='bold')\n",
    "            plt.ylabel('Items', fontweight='bold')\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.yticks(rotation=0)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Could not create emotion heatmap: {e}\")\n",
    "\n",
    "    def display_detailed_recommendations(self, results, show_covers=True, show_emotion_analysis=True, save_charts=True, save_dir=\"emotion_analysis\"):\n",
    "        \"\"\"Display detailed book recommendations with covers, descriptions, and emotion analysis\"\"\"\n",
    "        print(\"\\n\" + \"=\"*100)\n",
    "        print(\"DETAILED BOOK RECOMMENDATIONS WITH COVERS\")\n",
    "        print(\"=\"*100)\n",
    "        \n",
    "        # Image prediction summary\n",
    "        image_pred = results['image_prediction']\n",
    "        print(f\"\\n📸 IMAGE ANALYSIS:\")\n",
    "        print(f\"   Dominant Emotion: {image_pred['dominant_emotion']}\")\n",
    "        print(f\"   Confidence: {image_pred['confidence']:.3f}\")\n",
    "        print(f\"   Processing Time: {results['processing_time']:.3f}s\")\n",
    "        \n",
    "        # Create and save emotion charts\n",
    "        if save_charts:\n",
    "            save_dir = \"emotion_analysis_2\"\n",
    "            chart_dir = self.create_emotion_bar_charts(results, show_plots=show_emotion_analysis, save_dir=save_dir)\n",
    "            detailed_analysis = self.create_detailed_emotion_report(results)\n",
    "        \n",
    "        # Show emotion distributions if requested\n",
    "        if show_emotion_analysis:\n",
    "            self.display_emotion_distributions(results, show_plots=False)  # Charts already shown above\n",
    "        \n",
    "        # All three approaches (rest of the existing code...)\n",
    "        approaches = [\n",
    "            ('🧠 RESNET-ONLY RECOMMENDATIONS', results['resnet_recommendations'], 'lightcoral'),\n",
    "            ('📝 BERT-ONLY RECOMMENDATIONS', results['bert_recommendations'], 'lightgreen'), \n",
    "            ('🔗 MULTIMODAL RECOMMENDATIONS', results['multimodal_recommendations'], 'lightblue')\n",
    "        ]\n",
    "        \n",
    "        for approach_name, recommendations, color in approaches:\n",
    "            print(f\"\\n{'='*30} {approach_name} {'='*30}\")\n",
    "            \n",
    "            categories = [\n",
    "                ('🏆 TOP 3 MOST SIMILAR', recommendations['top']),\n",
    "                ('📊 MIDDLE 3 SIMILAR', recommendations['middle']),\n",
    "                ('📉 BOTTOM 3 LEAST SIMILAR', recommendations['bottom'])\n",
    "            ]\n",
    "            \n",
    "            for category_name, books in categories:\n",
    "                print(f\"\\n{category_name}\")\n",
    "                print(\"-\" * 80)\n",
    "                \n",
    "                for i, book in enumerate(books, 1):\n",
    "                    self._display_single_book(book, i, approach_name.split()[0])\n",
    "        \n",
    "        # Create a visual summary\n",
    "        if show_covers:\n",
    "            self._create_book_cover_visualization(results)\n",
    "    \n",
    "    def _display_single_book(self, book, rank, approach):\n",
    "        \"\"\"Display detailed information for a single book\"\"\"\n",
    "        \n",
    "        # Handle authors field (list of dicts from your parquet structure)\n",
    "        authors = book['authors']\n",
    "        if isinstance(authors, list) and len(authors) > 0:\n",
    "            try:\n",
    "                author_names = []\n",
    "                for author in authors[:3]:  # Show max 3 authors\n",
    "                    if isinstance(author, dict):\n",
    "                        author_name = author.get('role', 'Unknown Author')\n",
    "                        if not author_name or author_name == '':\n",
    "                            author_name = f\"Author ID: {author.get('author_id', 'Unknown')}\"\n",
    "                    else:\n",
    "                        author_name = str(author)\n",
    "                    author_names.append(author_name)\n",
    "                author_str = ', '.join(author_names)\n",
    "            except:\n",
    "                author_str = 'Unknown Author'\n",
    "        else:\n",
    "            author_str = 'Unknown Author'\n",
    "        \n",
    "        # Extract book information\n",
    "        title = book['title']\n",
    "        book_id = book['book_id']\n",
    "        similarity = book['similarity_score']\n",
    "        rating = book.get('average_rating', 'N/A')\n",
    "        \n",
    "        # Get emotion predictions\n",
    "        resnet_emotion = book.get('resnet_predicted_emotion', 'N/A')\n",
    "        bert_emotion = book.get('bert_predicted_emotion', 'N/A')\n",
    "        \n",
    "        # Use the actual image_url_large from your merged data\n",
    "        cover_url = book.get('image_url_large', 'No cover URL available')\n",
    "        \n",
    "        print(f\"\\n   {rank}. 📚 {title}\")\n",
    "        print(f\"      👤 Author(s): {author_str}\")\n",
    "        print(f\"      🆔 Book ID: {book_id}\")\n",
    "        print(f\"      ⭐ Rating: {rating}\")\n",
    "        print(f\"      🎯 Similarity Score: {similarity:.4f}\")\n",
    "        print(f\"      🧠 ResNet Emotion: {resnet_emotion}\")\n",
    "        print(f\"      📝 BERT Emotion: {bert_emotion}\")\n",
    "        print(f\"      🖼️  Cover URL: {cover_url}\")\n",
    "        \n",
    "        # Try to get book description\n",
    "        description = book.get('description', None)\n",
    "        if not description:\n",
    "            description = self._get_book_description(book_id, title, author_str)\n",
    "        \n",
    "        if description:\n",
    "            print(f\"      📖 Description: {description[:200]}...\")\n",
    "        else:\n",
    "            print(f\"      📖 Description: No description available\")\n",
    "        \n",
    "        print(\"      \" + \"─\" * 70)\n",
    "    \n",
    "    def _get_book_description(self, book_id, title, author):\n",
    "        \"\"\"Try to fetch book description from various APIs\"\"\"\n",
    "        try:\n",
    "            import requests\n",
    "            \n",
    "            # Search by title and author using Google Books API\n",
    "            search_query = f\"{title} {author}\".replace(' ', '+')\n",
    "            google_books_url = f\"https://www.googleapis.com/books/v1/volumes?q={search_query}&maxResults=1\"\n",
    "            \n",
    "            response = requests.get(google_books_url, timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                if 'items' in data and len(data['items']) > 0:\n",
    "                    volume_info = data['items'][0].get('volumeInfo', {})\n",
    "                    description = volume_info.get('description', '')\n",
    "                    if description:\n",
    "                        return description\n",
    "            \n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    def _create_book_cover_visualization(self, results):\n",
    "        \"\"\"Create a visualization grid showing actual book covers from image_url_large\"\"\"\n",
    "        try:\n",
    "            import requests\n",
    "            from io import BytesIO\n",
    "            \n",
    "            fig, axes = plt.subplots(3, 3, figsize=(15, 18))\n",
    "            fig.suptitle('Top Book Recommendations with Actual Covers', fontsize=16, fontweight='bold')\n",
    "            \n",
    "            # Get top book from each category of each approach\n",
    "            books_to_show = [\n",
    "                (results['resnet_recommendations']['top'][0], 'ResNet Top', 0, 0),\n",
    "                (results['bert_recommendations']['top'][0], 'BERT Top', 0, 1),\n",
    "                (results['multimodal_recommendations']['top'][0], 'Multimodal Top', 0, 2),\n",
    "                (results['resnet_recommendations']['middle'][0], 'ResNet Middle', 1, 0),\n",
    "                (results['bert_recommendations']['middle'][0], 'BERT Middle', 1, 1),\n",
    "                (results['multimodal_recommendations']['middle'][0], 'Multimodal Middle', 1, 2),\n",
    "                (results['resnet_recommendations']['bottom'][0], 'ResNet Bottom', 2, 0),\n",
    "                (results['bert_recommendations']['bottom'][0], 'BERT Bottom', 2, 1),\n",
    "                (results['multimodal_recommendations']['bottom'][0], 'Multimodal Bottom', 2, 2),\n",
    "            ]\n",
    "            \n",
    "            for book, label, row, col in books_to_show:\n",
    "                ax = axes[row, col]\n",
    "                \n",
    "                # Try to load actual book cover from image_url_large\n",
    "                try:\n",
    "                    cover_url = book.get('image_url_large', '')\n",
    "                    \n",
    "                    if cover_url and pd.notna(cover_url) and cover_url != 'No cover URL' and cover_url.startswith('http'):\n",
    "                        print(f\"Loading cover for {book['title'][:30]}...\")\n",
    "                        response = requests.get(cover_url, timeout=15, \n",
    "                                              headers={'User-Agent': 'Mozilla/5.0'})\n",
    "                        \n",
    "                        if response.status_code == 200:\n",
    "                            cover_image = Image.open(BytesIO(response.content))\n",
    "                            ax.imshow(cover_image)\n",
    "                            print(f\"✓ Loaded cover for {book['title'][:20]}...\")\n",
    "                        else:\n",
    "                            raise Exception(f\"HTTP {response.status_code}\")\n",
    "                    else:\n",
    "                        raise Exception(\"No valid URL\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Could not load cover for {book['title'][:20]}...: {e}\")\n",
    "                    # Create placeholder for failed loads\n",
    "                    placeholder = np.random.rand(300, 200, 3) * 0.3 + 0.7\n",
    "                    ax.imshow(placeholder)\n",
    "                    ax.text(0.5, 0.5, 'Cover\\nUnavailable', \n",
    "                           transform=ax.transAxes, ha='center', va='center',\n",
    "                           fontsize=12, fontweight='bold', \n",
    "                           bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
    "                \n",
    "                # Set title and details\n",
    "                title = book['title'][:25] + '...' if len(book['title']) > 25 else book['title']\n",
    "                similarity = book['similarity_score']\n",
    "                rating = book.get('average_rating', 'N/A')\n",
    "                \n",
    "                ax.set_title(f\"{label}\\n{title}\\nSim: {similarity:.3f} | ★{rating}\", \n",
    "                            fontsize=10, fontweight='bold', pad=10)\n",
    "                ax.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Could not create cover visualization: {e}\")\n",
    "            print(\"Install required packages: pip install pillow requests\")\n",
    "    \n",
    "    def get_book_urls_and_info(self, results, save_to_file=True):\n",
    "        \"\"\"Extract all book information and save to files\"\"\"\n",
    "        book_info = {\n",
    "            'image_analysis': results['image_prediction'],\n",
    "            'recommendations': {}\n",
    "        }\n",
    "        \n",
    "        approaches = ['resnet', 'bert', 'multimodal']\n",
    "        categories = ['top', 'middle', 'bottom']\n",
    "        \n",
    "        for approach in approaches:\n",
    "            book_info['recommendations'][approach] = {}\n",
    "            \n",
    "            for category in categories:\n",
    "                books = results[f'{approach}_recommendations'][category]\n",
    "                book_info['recommendations'][approach][category] = []\n",
    "                \n",
    "                for book in books:\n",
    "                    # Handle authors\n",
    "                    authors = book['authors']\n",
    "                    if isinstance(authors, list) and len(authors) > 0:\n",
    "                        try:\n",
    "                            author_names = [a.get('role', 'Unknown') if isinstance(a, dict) else str(a) for a in authors]\n",
    "                            author_str = ', '.join(author_names[:3])\n",
    "                        except:\n",
    "                            author_str = 'Unknown Author'\n",
    "                    else:\n",
    "                        author_str = 'Unknown Author'\n",
    "                    \n",
    "                    # Generate search URLs\n",
    "                    book_urls = {\n",
    "                        'actual_cover_url': book.get('image_url_large', 'No cover URL'),\n",
    "                        'goodreads_search': f\"https://www.goodreads.com/search?q={book['title'].replace(' ', '+')}\",\n",
    "                        'google_books_search': f\"https://www.google.com/search?tbm=bks&q={book['title'].replace(' ', '+')}+{author_str.replace(' ', '+')}\",\n",
    "                        'amazon_search': f\"https://www.amazon.com/s?k={book['title'].replace(' ', '+')}&i=stripbooks\",\n",
    "                    }\n",
    "                    \n",
    "                    book_entry = {\n",
    "                        'rank': book.get('rank', 0),\n",
    "                        'book_id': book['book_id'],\n",
    "                        'title': book['title'],\n",
    "                        'authors': author_str,\n",
    "                        'average_rating': book.get('average_rating', 'N/A'),\n",
    "                        'similarity_score': book['similarity_score'],\n",
    "                        'resnet_emotion': book.get('resnet_predicted_emotion', 'N/A'),\n",
    "                        'bert_emotion': book.get('bert_predicted_emotion', 'N/A'),\n",
    "                        'cover_url': book.get('image_url_large', 'No cover URL'),\n",
    "                        'description': book.get('description', 'No description available'),\n",
    "                        'urls': book_urls\n",
    "                    }\n",
    "                    \n",
    "                    book_info['recommendations'][approach][category].append(book_entry)\n",
    "        \n",
    "        # Save to file if requested\n",
    "        if save_to_file:\n",
    "            # Also create a simple CSV for easy viewing\n",
    "            csv_filename = f\"book_recommendations_{results['image_prediction']['dominant_emotion']}.csv\"\n",
    "            self._save_to_csv(book_info, csv_filename)\n",
    "            print(f\"💾 CSV summary saved to: {csv_filename}\")\n",
    "        \n",
    "        return book_info\n",
    "    \n",
    "    def _save_to_csv(self, book_info, filename):\n",
    "        \"\"\"Save book recommendations to CSV format with actual cover URLs\"\"\"\n",
    "        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = ['approach', 'category', 'rank', 'title', 'authors', 'rating', \n",
    "                         'similarity_score', 'resnet_emotion', 'bert_emotion', 'book_id',\n",
    "                         'cover_url', 'description', 'goodreads_search_url']\n",
    "            \n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            \n",
    "            for approach in ['resnet', 'bert', 'multimodal']:\n",
    "                for category in ['top', 'middle', 'bottom']:\n",
    "                    for book in book_info['recommendations'][approach][category]:\n",
    "                        writer.writerow({\n",
    "                            'approach': approach,\n",
    "                            'category': category,\n",
    "                            'rank': book['rank'],\n",
    "                            'title': book['title'],\n",
    "                            'authors': book['authors'],\n",
    "                            'rating': book['average_rating'],\n",
    "                            'similarity_score': book['similarity_score'],\n",
    "                            'resnet_emotion': book['resnet_emotion'],\n",
    "                            'bert_emotion': book['bert_emotion'],\n",
    "                            'book_id': book['book_id'],\n",
    "                            'cover_url': book['cover_url'],\n",
    "                            'description': book['description'][:200] + '...' if len(book.get('description', '')) > 200 else book.get('description', ''),\n",
    "                            'goodreads_search_url': book['urls']['goodreads_search']\n",
    "                        })\n",
    "\n",
    "    def create_emotion_bar_charts(self, results, save_dir=\"emotion_charts\", show_plots=True):\n",
    "        \"\"\"Create and save emotion distribution bar charts for image and recommendations\"\"\"\n",
    "        import os\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "        \n",
    "        # Create save directory\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # Get image emotion distribution\n",
    "        image_emotions = results['image_prediction']['emotion_distribution']\n",
    "        dominant_emotion = results['image_prediction']['dominant_emotion']\n",
    "        \n",
    "        print(f\"\\n📊 Creating emotion distribution bar charts...\")\n",
    "        print(f\"💾 Saving charts to: {save_dir}/\")\n",
    "        \n",
    "        # 1. Create bar chart for input image\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(self.emotion_labels)))\n",
    "        \n",
    "        bars = ax.bar(range(len(self.emotion_labels)), image_emotions, \n",
    "                      color=colors, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "        \n",
    "        # Highlight dominant emotion\n",
    "        max_idx = np.argmax(image_emotions)\n",
    "        bars[max_idx].set_edgecolor('red')\n",
    "        bars[max_idx].set_linewidth(3)\n",
    "        \n",
    "        # Customize plot\n",
    "        ax.set_xlabel('Emotions', fontsize=12, fontweight='bold')\n",
    "        ax.set_ylabel('Probability', fontsize=12, fontweight='bold')\n",
    "        ax.set_title(f'Input Image Emotion Distribution\\n(Dominant: {dominant_emotion})', \n",
    "                    fontsize=14, fontweight='bold', pad=20)\n",
    "        \n",
    "        # Set x-axis labels\n",
    "        ax.set_xticks(range(len(self.emotion_labels)))\n",
    "        ax.set_xticklabels(self.emotion_labels, rotation=45, ha='right')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, image_emotions):\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                   f'{value:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "        \n",
    "        # Add grid and formatting\n",
    "        ax.grid(True, alpha=0.3, axis='y')\n",
    "        ax.set_axisbelow(True)\n",
    "        ax.set_ylim(0, max(image_emotions) * 1.2)\n",
    "        \n",
    "        # Add dominant emotion annotation\n",
    "        ax.text(0.02, 0.98, f'Dominant: {dominant_emotion}\\nConfidence: {image_emotions[max_idx]:.3f}', \n",
    "                transform=ax.transAxes, fontsize=12, fontweight='bold',\n",
    "                bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"yellow\", alpha=0.8),\n",
    "                verticalalignment='top')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save image emotion chart\n",
    "        image_chart_path = os.path.join(save_dir, f'input_image_emotions_{dominant_emotion}.png')\n",
    "        plt.savefig(image_chart_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"✓ Saved input image emotions: {image_chart_path}\")\n",
    "        \n",
    "        if show_plots:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "        \n",
    "        # 2. Create comparison charts for top recommendations\n",
    "        approaches = [\n",
    "            ('resnet', 'ResNet', results['resnet_recommendations'], self.resnet_emotions_matrix),\n",
    "            ('bert', 'BERT', results['bert_recommendations'], self.bert_emotions_matrix),\n",
    "            ('multimodal', 'Multimodal', results['multimodal_recommendations'], self.multimodal_emotions_matrix)\n",
    "        ]\n",
    "        \n",
    "        for approach_key, approach_name, recommendations, emotion_matrix in approaches:\n",
    "            # Create comparison chart for top 3 books\n",
    "            fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "            fig.suptitle(f'{approach_name} Approach: Top 3 Book Recommendations vs Input Image', \n",
    "                        fontsize=16, fontweight='bold')\n",
    "            \n",
    "            # Plot input image in top-left\n",
    "            ax = axes[0, 0]\n",
    "            bars = ax.bar(range(len(self.emotion_labels)), image_emotions, \n",
    "                         color='skyblue', alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "            bars[max_idx].set_edgecolor('red')\n",
    "            bars[max_idx].set_linewidth(3)\n",
    "            \n",
    "            ax.set_title(f'Input Image\\n(Dominant: {dominant_emotion})', fontweight='bold')\n",
    "            ax.set_xticks(range(len(self.emotion_labels)))\n",
    "            ax.set_xticklabels(self.emotion_labels, rotation=45, ha='right')\n",
    "            ax.set_ylabel('Probability')\n",
    "            ax.grid(True, alpha=0.3, axis='y')\n",
    "            \n",
    "            # Add values on bars\n",
    "            for bar, value in zip(bars, image_emotions):\n",
    "                ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.005,\n",
    "                       f'{value:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "            \n",
    "            # Plot top 3 book recommendations\n",
    "            positions = [(0, 1), (1, 0), (1, 1)]\n",
    "            colors_books = ['lightcoral', 'lightgreen', 'lightsalmon']\n",
    "            \n",
    "            for i, (book, pos, color) in enumerate(zip(recommendations['top'][:3], positions, colors_books)):\n",
    "                ax = axes[pos[0], pos[1]]\n",
    "                \n",
    "                # Get book emotions\n",
    "                book_idx = self._get_book_index(book['book_id'])\n",
    "                if book_idx is not None:\n",
    "                    book_emotions = emotion_matrix[book_idx]\n",
    "                    book_max_idx = np.argmax(book_emotions)\n",
    "                    \n",
    "                    # Create bars\n",
    "                    bars = ax.bar(range(len(self.emotion_labels)), book_emotions, \n",
    "                                 color=color, alpha=0.8, edgecolor='black', linewidth=0.5)\n",
    "                    bars[book_max_idx].set_edgecolor('red')\n",
    "                    bars[book_max_idx].set_linewidth(3)\n",
    "                    \n",
    "                    # Formatting\n",
    "                    book_title = book['title'][:30] + '...' if len(book['title']) > 30 else book['title']\n",
    "                    book_emotion = self.emotion_labels[book_max_idx]\n",
    "                    similarity = book['similarity_score']\n",
    "                    \n",
    "                    ax.set_title(f'Book {i+1}: {book_title}\\n(Dominant: {book_emotion}, Sim: {similarity:.3f})', \n",
    "                               fontweight='bold', fontsize=11)\n",
    "                    ax.set_xticks(range(len(self.emotion_labels)))\n",
    "                    ax.set_xticklabels(self.emotion_labels, rotation=45, ha='right')\n",
    "                    ax.set_ylabel('Probability')\n",
    "                    ax.grid(True, alpha=0.3, axis='y')\n",
    "                    \n",
    "                    # Add values on bars\n",
    "                    for bar, value in zip(bars, book_emotions):\n",
    "                        if value > 0.1:  # Only show values > 0.1 to avoid clutter\n",
    "                            ax.text(bar.get_x() + bar.get_width()/2., bar.get_height() + 0.005,\n",
    "                                   f'{value:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save comparison chart\n",
    "            comparison_path = os.path.join(save_dir, f'{approach_key}_emotion_comparison_{dominant_emotion}.png')\n",
    "            plt.savefig(comparison_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"✓ Saved {approach_name} comparison: {comparison_path}\")\n",
    "            \n",
    "            if show_plots:\n",
    "                plt.show()\n",
    "            else:\n",
    "                plt.close()\n",
    "        \n",
    "        # 3. Create comprehensive heatmap\n",
    "        self._create_comprehensive_emotion_heatmap(results, save_dir, show_plots)\n",
    "        \n",
    "        return save_dir\n",
    "    \n",
    "    def _create_comprehensive_emotion_heatmap(self, results, save_dir, show_plots=True):\n",
    "        \"\"\"Create a comprehensive heatmap showing all emotion distributions\"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        import os\n",
    "        \n",
    "        # Collect all emotion distributions\n",
    "        image_emotions = results['image_prediction']['emotion_distribution']\n",
    "        dominant_emotion = results['image_prediction']['dominant_emotion']\n",
    "        \n",
    "        all_emotions = [image_emotions]\n",
    "        labels = ['Input Image']\n",
    "        \n",
    "        # Get top 2 from each approach\n",
    "        approaches = [\n",
    "            ('ResNet', results['resnet_recommendations']['top'][:2], self.resnet_emotions_matrix),\n",
    "            ('BERT', results['bert_recommendations']['top'][:2], self.bert_emotions_matrix),\n",
    "            ('Multimodal', results['multimodal_recommendations']['top'][:2], self.multimodal_emotions_matrix)\n",
    "        ]\n",
    "        \n",
    "        for approach_name, books, emotion_matrix in approaches:\n",
    "            for i, book in enumerate(books, 1):\n",
    "                book_idx = self._get_book_index(book['book_id'])\n",
    "                if book_idx is not None:\n",
    "                    book_emotions = emotion_matrix[book_idx]\n",
    "                    all_emotions.append(book_emotions)\n",
    "                    \n",
    "                    book_title = book['title'][:25] + '...' if len(book['title']) > 25 else book['title']\n",
    "                    similarity = book['similarity_score']\n",
    "                    labels.append(f\"{approach_name}-{i}\\n{book_title}\\n(Sim: {similarity:.3f})\")\n",
    "        \n",
    "        # Create emotion matrix for heatmap\n",
    "        emotion_matrix = np.array(all_emotions)\n",
    "        \n",
    "        # Create heatmap\n",
    "        plt.figure(figsize=(14, 10))\n",
    "        \n",
    "        # Custom colormap\n",
    "        heatmap = sns.heatmap(emotion_matrix, \n",
    "                             xticklabels=self.emotion_labels,\n",
    "                             yticklabels=labels,\n",
    "                             annot=True, \n",
    "                             fmt='.3f',\n",
    "                             cmap='YlOrRd',\n",
    "                             cbar_kws={'label': 'Emotion Probability'},\n",
    "                             linewidths=0.5)\n",
    "        \n",
    "        plt.title(f'Emotion Distribution Heatmap\\nInput Image vs Top Book Recommendations\\n(Dominant Emotion: {dominant_emotion})', \n",
    "                 fontsize=14, fontweight='bold', pad=20)\n",
    "        plt.xlabel('Emotions', fontweight='bold', fontsize=12)\n",
    "        plt.ylabel('Items', fontweight='bold', fontsize=12)\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.yticks(rotation=0)\n",
    "        \n",
    "        # Highlight the input image row\n",
    "        heatmap.add_patch(plt.Rectangle((0, 0), len(self.emotion_labels), 1, \n",
    "                                      fill=False, edgecolor='blue', lw=3))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save heatmap\n",
    "        heatmap_path = os.path.join(save_dir, f'emotion_heatmap_{dominant_emotion}.png')\n",
    "        plt.savefig(heatmap_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"✓ Saved emotion heatmap: {heatmap_path}\")\n",
    "        \n",
    "        if show_plots:\n",
    "            plt.show()\n",
    "        else:\n",
    "            plt.close()\n",
    "    \n",
    "    def create_detailed_emotion_report(self, results, save_dir=\"emotion_analysis_2\"):\n",
    "        \"\"\"Create detailed emotion analysis report with charts and statistics\"\"\"\n",
    "        import os\n",
    "        import json\n",
    "        \n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"\\n📈 Creating detailed emotion analysis report...\")\n",
    "        \n",
    "        # Create all bar charts\n",
    "        chart_dir = os.path.join(save_dir, \"charts\")\n",
    "        self.create_emotion_bar_charts(results, save_dir=chart_dir, show_plots=False)\n",
    "        \n",
    "        # Create detailed statistics\n",
    "        image_emotions = results['image_prediction']['emotion_distribution']\n",
    "        dominant_emotion = results['image_prediction']['dominant_emotion']\n",
    "        \n",
    "        # Calculate emotion statistics for each approach\n",
    "        emotion_analysis = {\n",
    "            'input_image': {\n",
    "                'dominant_emotion': dominant_emotion,\n",
    "                'confidence': float(results['image_prediction']['confidence']),\n",
    "                'emotion_distribution': {emotion: float(prob) for emotion, prob \n",
    "                                       in zip(self.emotion_labels, image_emotions)},\n",
    "                'top_3_emotions': []\n",
    "            },\n",
    "            'recommendations_analysis': {}\n",
    "        }\n",
    "        \n",
    "        # Get top 3 emotions for input image\n",
    "        top_3_indices = np.argsort(image_emotions)[-3:][::-1]\n",
    "        for idx in top_3_indices:\n",
    "            emotion_analysis['input_image']['top_3_emotions'].append({\n",
    "                'emotion': self.emotion_labels[idx],\n",
    "                'probability': float(image_emotions[idx])\n",
    "            })\n",
    "        \n",
    "        # Analyze each approach\n",
    "        approaches = [\n",
    "            ('resnet', results['resnet_recommendations'], self.resnet_emotions_matrix),\n",
    "            ('bert', results['bert_recommendations'], self.bert_emotions_matrix),\n",
    "            ('multimodal', results['multimodal_recommendations'], self.multimodal_emotions_matrix)\n",
    "        ]\n",
    "        \n",
    "        for approach_name, recommendations, emotion_matrix in approaches:\n",
    "            emotion_analysis['recommendations_analysis'][approach_name] = {\n",
    "                'top_books': []\n",
    "            }\n",
    "            \n",
    "            for i, book in enumerate(recommendations['top'][:3], 1):\n",
    "                book_idx = self._get_book_index(book['book_id'])\n",
    "                if book_idx is not None:\n",
    "                    book_emotions = emotion_matrix[book_idx]\n",
    "                    \n",
    "                    # Calculate similarities\n",
    "                    cosine_sim = np.dot(image_emotions, book_emotions) / (\n",
    "                        np.linalg.norm(image_emotions) * np.linalg.norm(book_emotions))\n",
    "                    kl_div = self._calculate_kl_divergence(image_emotions, book_emotions)\n",
    "                    \n",
    "                    # Get top 3 emotions for this book\n",
    "                    book_top_3_indices = np.argsort(book_emotions)[-3:][::-1]\n",
    "                    book_top_3 = []\n",
    "                    for idx in book_top_3_indices:\n",
    "                        book_top_3.append({\n",
    "                            'emotion': self.emotion_labels[idx],\n",
    "                            'probability': float(book_emotions[idx])\n",
    "                        })\n",
    "                    \n",
    "                    book_analysis = {\n",
    "                        'rank': i,\n",
    "                        'title': book['title'],\n",
    "                        'book_id': book['book_id'],\n",
    "                        'similarity_score': float(book['similarity_score']),\n",
    "                        'cosine_similarity': float(cosine_sim),\n",
    "                        'kl_divergence': float(kl_div),\n",
    "                        'dominant_emotion': self.emotion_labels[np.argmax(book_emotions)],\n",
    "                        'emotion_distribution': {emotion: float(prob) for emotion, prob \n",
    "                                               in zip(self.emotion_labels, book_emotions)},\n",
    "                        'top_3_emotions': book_top_3,\n",
    "                        'emotion_differences': {}\n",
    "                    }\n",
    "                    \n",
    "                    # Calculate emotion differences\n",
    "                    for j, emotion in enumerate(self.emotion_labels):\n",
    "                        diff = float(book_emotions[j] - image_emotions[j])\n",
    "                        book_analysis['emotion_differences'][emotion] = diff\n",
    "                    \n",
    "                    emotion_analysis['recommendations_analysis'][approach_name]['top_books'].append(book_analysis)\n",
    "        \n",
    "        # Save detailed analysis\n",
    "        analysis_file = os.path.join(save_dir, f'emotion_analysis_{dominant_emotion}.json')\n",
    "        with open(analysis_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(emotion_analysis, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        print(f\"✓ Saved detailed emotion analysis: {analysis_file}\")\n",
    "        print(f\"✓ Saved emotion charts in: {chart_dir}/\")\n",
    "        \n",
    "        return emotion_analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94888134",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ================== MAIN EXECUTION ==================\n",
    "\n",
    "# ================== UPDATED MAIN EXECUTION ==================\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function with emotion chart creation\"\"\"\n",
    "    print(\"🚀 Starting Complete Image-Book Emotion Matching System\")\n",
    "    \n",
    "    # Initialize the complete matcher\n",
    "    matcher = CompleteImageBookMatcher(\n",
    "        use_gpu_similarity=True,    \n",
    "        precompute_indices=True     \n",
    "    )\n",
    "    \n",
    "    # Example usage - UPDATE THIS PATH\n",
    "    image_path = \"input_images/anger_painting.jpg\"\n",
    "    \n",
    "    # Run the complete analysis\n",
    "    if os.path.exists(image_path):\n",
    "        print(f\"\\n📸 Analyzing image: {image_path}\")\n",
    "        \n",
    "        # Fast matching with comprehensive results\n",
    "        results = matcher.find_similar_books_complete(\n",
    "            image_path=image_path,\n",
    "            top_k=686907,     \n",
    "            final_n=3       \n",
    "        )\n",
    "        \n",
    "        # Display comprehensive results WITH emotion charts\n",
    "        print(\"\\n\" + \"🔍\" * 50)\n",
    "        matcher.display_detailed_recommendations(\n",
    "            results, \n",
    "            # show_covers=True, \n",
    "            show_emotion_analysis=True,\n",
    "            # save_charts=True  # NEW: Save emotion bar charts\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n✅ ANALYSIS COMPLETE!\")\n",
    "        print(f\"📊 Emotion charts saved to: emotion_charts/\")\n",
    "        print(f\"📈 Detailed analysis saved to: emotion_analysis/\")\n",
    "        return results\n",
    "    else:\n",
    "        print(f\"❌ Error: Image file not found: {image_path}\")\n",
    "        return None\n",
    "\n",
    "results = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c9f1913-7bbe-4105-b0d0-5645e359f22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INITIALIZING COMPLETE IMAGE-BOOK EMOTION MATCHING SYSTEM\n",
      "================================================================================\n",
      "Loading ResNet model...\n",
      "✓ ResNet model loaded and tested successfully\n",
      "Loading and preprocessing book emotion distributions with image URLs...\n",
      "Loading preprocessed books data for image URLs...\n",
      "✓ Loaded 931229 books from preprocessed data\n",
      "✓ Found 931229 books with image URLs\n",
      "Loading ResNet emotion predictions...\n",
      "Loading BERT emotion predictions...\n",
      "✓ Loaded ResNet emotions for 686990 books\n",
      "✓ Loaded BERT emotions for 686946 books\n",
      "Merging ResNet data with image URLs...\n",
      "Merging BERT data with image URLs...\n",
      "✓ Final dataset: 686907 books with both ResNet and BERT predictions\n",
      "✓ ResNet books with image URLs: 686907\n",
      "✓ BERT books with image URLs: 686907\n",
      "Precomputing emotion matrices for fast similarity...\n",
      "Precomputing multimodal combinations...\n",
      "Moving emotion matrices to GPU for fast similarity...\n",
      "Building FAISS indices for similarity search...\n",
      "✓ FAISS indices built successfully\n",
      "✓ System ready! Loaded 686907 books for matching\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.16998516, 0.23982911, 0.19944605, ..., 0.20143256, 0.20434676,\n",
       "       0.21503952], shape=(686907,), dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher = CompleteImageBookMatcher(\n",
    "    use_gpu_similarity=True,    \n",
    "    precompute_indices=True     \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38d47b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.16998516, 0.23982911, 0.19944605, ..., 0.20143256, 0.20434676,\n",
       "        0.21503952], shape=(686907,), dtype=float32),\n",
       " array([0.22007017, 0.84584194, 0.43285942, ..., 0.5469671 , 0.88071233,\n",
       "        0.37570584], shape=(686907,), dtype=float32))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matcher.resnet_confidences, matcher.bert_confidences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5039e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ndarray(obj):\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        return obj.tolist()\n",
    "    if isinstance(obj, (np.floating, np.integer)):\n",
    "        return obj.item()\n",
    "    if isinstance(obj, dict):\n",
    "        return {k: convert_ndarray(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, list):\n",
    "        return [convert_ndarray(i) for i in obj]\n",
    "    return obj\n",
    "\n",
    "results_serializable = convert_ndarray(results)\n",
    "\n",
    "with open(\"survey_recommendations_info.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results_serializable, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09861089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet_urls = ['https://images.gr-assets.com/books/1290170247l/9330885.jpg', 'https://images.gr-assets.com/books/1340031123l/14402305.jpg', 'https://images.gr-assets.com/books/1313500615l/12078346.jpg', 'https://images.gr-assets.com/books/1386585006l/19308342.jpg', 'https://images.gr-assets.com/books/1344721731l/13346464.jpg', 'https://images.gr-assets.com/books/1355050076l/278056.jpg', 'https://images.gr-assets.com/books/1381565460l/18663384.jpg', 'https://images.gr-assets.com/books/1327974189l/7901182.jpg', 'https://images.gr-assets.com/books/1355061113l/173589.jpg']\n",
      "BERT_urls = ['https://images.gr-assets.com/books/1457963343l/29505492.jpg', 'https://images.gr-assets.com/books/1320543569l/1411357.jpg', 'https://images.gr-assets.com/books/1468230274l/28595947.jpg', 'https://images.gr-assets.com/books/1395620769l/1064192.jpg', 'https://images.gr-assets.com/books/1327605330l/6970002.jpg', 'https://images.gr-assets.com/books/1320500996l/3364596.jpg', 'https://images.gr-assets.com/books/1479547426l/31321126.jpg', 'https://images.gr-assets.com/books/1404579559l/1027351.jpg', 'https://images.gr-assets.com/books/1450000591l/25734081.jpg']\n",
      "Multimodal_urls = ['https://images.gr-assets.com/books/1450349679l/1442782.jpg', 'https://images.gr-assets.com/books/1356574564l/15870096.jpg', 'https://images.gr-assets.com/books/1328872691l/1816515.jpg', 'https://images.gr-assets.com/books/1356135542l/555274.jpg', 'https://images.gr-assets.com/books/1387790017l/1728883.jpg', 'https://images.gr-assets.com/books/1354931244l/15780375.jpg', 'https://images.gr-assets.com/books/1328837581l/6928833.jpg', 'https://images.gr-assets.com/books/1468992944l/30844277.jpg', 'https://images.gr-assets.com/books/1450000591l/25734081.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Define the models and their corresponding keys in the data dictionary\n",
    "model_keys = {\n",
    "    \"ResNet\": \"resnet_recommendations\",\n",
    "    \"BERT\": \"bert_recommendations\",\n",
    "    \"Multimodal\": \"multimodal_recommendations\"\n",
    "}\n",
    "\n",
    "# Dictionary to store the results\n",
    "urls_by_model = {\n",
    "    \"ResNet\": [],\n",
    "    \"BERT\": [],\n",
    "    \"Multimodal\": []\n",
    "}\n",
    "\n",
    "# Iterate through each model key\n",
    "for model_name, data_key in model_keys.items():\n",
    "    if data_key in results and isinstance(results[data_key], dict):\n",
    "        # Iterate through 'top', 'middle', 'bottom' categories\n",
    "        for category in ['top', 'middle', 'bottom']:\n",
    "            if category in results[data_key] and isinstance(results[data_key][category], list):\n",
    "                # Iterate through each book in the category\n",
    "                for book in results[data_key][category]:\n",
    "                    if 'image_url_large' in book:\n",
    "                        urls_by_model[model_name].append(book['image_url_large'])\n",
    "\n",
    "# Print the results as Python lists\n",
    "for model_name, urls in urls_by_model.items():\n",
    "    print(f\"{model_name}_urls = {urls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d87045",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
