{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c634ea7-3b8a-4417-968a-cb9a859bc04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuration initialized\n",
      "üìä Available GPUs: 4\n",
      "üîÑ Max concurrent downloads: 64\n",
      "‚úÖ Artemis modules imported successfully\n",
      "üìã CONFIGURATION SUMMARY\n",
      "----------------------------------------\n",
      "üìÅ Artemis path: data/artemis/artemis\n",
      "ü§ñ Model file: data/artemis/predictions/best_model_good_data.pt\n",
      "üìä Data file: preprocessed_books_2025_04_20.parquet\n",
      "üíæ Results directory: goodreads_emotion_results\n",
      "üñ•Ô∏è GPUs available: 4\n",
      "üîÑ Max concurrent downloads: 64\n",
      "üì¶ Batch size: 256\n",
      "----------------------------------------\n",
      "üéØ Goodreads Book Cover Emotion Analysis\n",
      "üìö Processing English books only\n",
      "üîÑ Using async optimization for speed\n",
      "--------------------------------------------------\n",
      "üîß Model loaded on GPU 0\n",
      "üîß Model loaded on GPU 1\n",
      "üîß Model loaded on GPU 2\n",
      "üîß Model loaded on GPU 3\n",
      "üöÄ Starting Goodreads emotion analysis...\n",
      "üìÇ Loading Goodreads data...\n",
      "üìä Loaded 931,229 total books\n",
      "üîç Filtering for English books from 931,229 total books\n",
      "‚úÖ Filtered to 687,029 English books\n",
      "üìâ Dropped 244,200 non-English books (26.2%)\n",
      "üìÇ Loaded checkpoint from 2025-06-05T05:20:58.070535\n",
      "üìä Previous progress: 649,963 results, 37 failed\n",
      "üîÑ Resuming from checkpoint: 650,000 books already processed\n",
      "üìã Processing 37,029 remaining English books\n",
      "üîÑ Processing 2 batches of up to 25,000 books each\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd88825d4e14458da53f46ab813be742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Progress: 98.2% (675,000/687,029) | ‚úÖ Success: 100.0% | üöÄ Speed: 2576.2 books/sec | ‚è±Ô∏è ETA: 0.0h\n",
      "üíæ Checkpoint saved: 674,962 results, 38 failed\n",
      "üíæ Checkpoint saved: 686,990 results, 39 failed\n",
      "\n",
      "============================================================\n",
      "üéâ PROCESSING COMPLETED!\n",
      "============================================================\n",
      "üìä Total processed: 687,029\n",
      "‚úÖ Successful: 686,990 (99.99%)\n",
      "‚ùå Failed: 39\n",
      "üíæ Results saved to: goodreads_emotion_results/goodreads_emotion_predictions_english.parquet\n",
      "============================================================\n",
      "\n",
      "üìà Top predicted emotions:\n",
      "  awe: 203,032 (29.6%)\n",
      "  amusement: 179,719 (26.2%)\n",
      "  fear: 172,886 (25.2%)\n",
      "  contentment: 44,676 (6.5%)\n",
      "  something else: 34,407 (5.0%)\n"
     ]
    }
   ],
   "source": [
    "# Async-optimized Goodreads Book Emotion Analysis for Jupyter\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "from queue import Queue\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "\n",
    "# Enable nested async loops for Jupyter\n",
    "nest_asyncio.apply()\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup logging for Jupyter\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('jupyter_emotion_analysis.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuration optimized for Jupyter\n",
    "class JupyterConfig:\n",
    "    ARTEMIS_PATH = r'data/artemis/artemis'  # Your artemis path from the notebook\n",
    "    CHECKPOINT_FILE = r'data/artemis/predictions/best_model_good_data.pt'  # Your model path\n",
    "    DATA_FILE = 'preprocessed_books_2025_04_20.parquet'  # Your data file\n",
    "    RESULTS_DIR = 'goodreads_emotion_results'\n",
    "    \n",
    "    # GPU configuration (auto-detect)\n",
    "    GPU_IDS = list(range(torch.cuda.device_count())) if torch.cuda.is_available() else [0]\n",
    "    BATCH_SIZE = 256  # Adjust based on your GPU memory\n",
    "    \n",
    "    # Async processing - optimized for Jupyter\n",
    "    MAX_CONCURRENT_DOWNLOADS = 64  # Conservative for Jupyter\n",
    "    MAX_CONCURRENT_PREPROCESSING = 32\n",
    "    SEMAPHORE_LIMIT = 128\n",
    "    DOWNLOAD_TIMEOUT = 10\n",
    "    MAX_RETRIES = 3\n",
    "    \n",
    "    # Processing batches\n",
    "    PROCESSING_BATCH_SIZE = 25000  # Large batches for efficiency\n",
    "    CHECKPOINT_FREQUENCY = 10000   # Checkpoint every 10k books\n",
    "    \n",
    "    # Progress tracking (more frequent for Jupyter)\n",
    "    PROGRESS_UPDATE_FREQUENCY = 500\n",
    "    DETAILED_LOG_FREQUENCY = 2000\n",
    "    \n",
    "    # English language filtering\n",
    "    ENGLISH_CODES = {\n",
    "        'en', 'eng', 'en-us', 'en-gb', 'en-ca', 'en-au', 'en-nz', 'en-za', \n",
    "        'en-in', 'english', 'en_us', 'en_gb', 'en_ca', 'en_au'\n",
    "    }\n",
    "    \n",
    "    # Emotion labels (matching your notebook)\n",
    "    EMOTION_LABELS = ['amusement', 'anger', 'awe', 'contentment', 'disgust', \n",
    "                     'excitement', 'fear', 'sadness', 'something else']\n",
    "    \n",
    "    def __init__(self):\n",
    "        os.makedirs(self.RESULTS_DIR, exist_ok=True)\n",
    "        os.makedirs(f\"{self.RESULTS_DIR}/checkpoints\", exist_ok=True)\n",
    "        print(f\"‚úÖ Configuration initialized\")\n",
    "        print(f\"üìä Available GPUs: {len(self.GPU_IDS) if self.GPU_IDS[0] != 0 or torch.cuda.is_available() else 0}\")\n",
    "        print(f\"üîÑ Max concurrent downloads: {self.MAX_CONCURRENT_DOWNLOADS}\")\n",
    "\n",
    "config = JupyterConfig()\n",
    "\n",
    "# # Add artemis to path\n",
    "# if config.ARTEMIS_PATH not in sys.path:\n",
    "#     sys.path.append(config.ARTEMIS_PATH)\n",
    "\n",
    "# Import artemis modules (matching your notebook)\n",
    "try:\n",
    "    from artemis.emotions import ARTEMIS_EMOTIONS\n",
    "    from artemis.neural_models.mlp import MLP\n",
    "    from artemis.neural_models.resnet_encoder import ResnetEncoder\n",
    "    from artemis.neural_models.image_emotion_clf import ImageEmotionClassifier\n",
    "    from artemis.in_out.neural_net_oriented import torch_load_model\n",
    "    print(\"‚úÖ Artemis modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Error importing artemis modules: {e}\")\n",
    "    print(\"Please check your ARTEMIS_PATH in the config above\")\n",
    "\n",
    "def filter_english_books(books_df):\n",
    "    \"\"\"Filter books to include only English language books\"\"\"\n",
    "    print(f\"üîç Filtering for English books from {len(books_df):,} total books\")\n",
    "    \n",
    "    def is_english(lang_code):\n",
    "        if pd.isna(lang_code):\n",
    "            return False\n",
    "        lang_code_clean = str(lang_code).lower().strip()\n",
    "        return lang_code_clean in config.ENGLISH_CODES\n",
    "    \n",
    "    english_mask = books_df['language_code'].astype(str).apply(is_english)\n",
    "    english_books = books_df[english_mask].copy()\n",
    "    \n",
    "    dropped_count = len(books_df) - len(english_books)\n",
    "    print(f\"‚úÖ Filtered to {len(english_books):,} English books\")\n",
    "    print(f\"üìâ Dropped {dropped_count:,} non-English books ({dropped_count/len(books_df)*100:.1f}%)\")\n",
    "    \n",
    "    return english_books\n",
    "\n",
    "class JupyterProgressTracker:\n",
    "    \"\"\"Progress tracker with Jupyter-friendly output\"\"\"\n",
    "    \n",
    "    def __init__(self, total_books):\n",
    "        self.total_books = total_books\n",
    "        self.processed_books = 0\n",
    "        self.successful_books = 0\n",
    "        self.failed_books = 0\n",
    "        self.start_time = time.time()\n",
    "        self.lock = threading.Lock()\n",
    "        \n",
    "        # Performance metrics\n",
    "        self.books_per_second = 0\n",
    "        self.last_update_time = time.time()\n",
    "        \n",
    "    def update(self, successful=0, failed=0):\n",
    "        with self.lock:\n",
    "            self.successful_books += successful\n",
    "            self.failed_books += failed\n",
    "            self.processed_books = self.successful_books + self.failed_books\n",
    "            \n",
    "            # Calculate performance\n",
    "            elapsed = time.time() - self.start_time\n",
    "            if elapsed > 0:\n",
    "                self.books_per_second = self.processed_books / elapsed\n",
    "    \n",
    "    def should_log(self, frequency):\n",
    "        return self.processed_books % frequency == 0\n",
    "    \n",
    "    def get_jupyter_status(self):\n",
    "        \"\"\"Get status formatted for Jupyter output\"\"\"\n",
    "        with self.lock:\n",
    "            progress_pct = (self.processed_books / self.total_books) * 100\n",
    "            success_rate = (self.successful_books / max(1, self.processed_books)) * 100\n",
    "            \n",
    "            remaining = self.total_books - self.processed_books\n",
    "            eta_seconds = remaining / max(0.1, self.books_per_second)\n",
    "            eta_hours = eta_seconds / 3600\n",
    "            \n",
    "            elapsed_hours = (time.time() - self.start_time) / 3600\n",
    "            \n",
    "            status = {\n",
    "                'progress_percent': progress_pct,\n",
    "                'processed': self.processed_books,\n",
    "                'total': self.total_books,\n",
    "                'successful': self.successful_books,\n",
    "                'failed': self.failed_books,\n",
    "                'success_rate': success_rate,\n",
    "                'books_per_second': self.books_per_second,\n",
    "                'elapsed_hours': elapsed_hours,\n",
    "                'eta_hours': eta_hours\n",
    "            }\n",
    "            \n",
    "            return status\n",
    "    \n",
    "    def display_progress(self):\n",
    "        \"\"\"Display progress in Jupyter-friendly format\"\"\"\n",
    "        status = self.get_jupyter_status()\n",
    "        \n",
    "        # Progress bar using tqdm\n",
    "        progress_bar = f\"üìä Progress: {status['progress_percent']:.1f}% \"\n",
    "        progress_bar += f\"({status['processed']:,}/{status['total']:,}) | \"\n",
    "        progress_bar += f\"‚úÖ Success: {status['success_rate']:.1f}% | \"\n",
    "        progress_bar += f\"üöÄ Speed: {status['books_per_second']:.1f} books/sec | \"\n",
    "        progress_bar += f\"‚è±Ô∏è ETA: {status['eta_hours']:.1f}h\"\n",
    "        \n",
    "        print(progress_bar)\n",
    "\n",
    "class JupyterCheckpointManager:\n",
    "    \"\"\"Checkpoint manager for Jupyter (compatible with existing checkpoints)\"\"\"\n",
    "    \n",
    "    def __init__(self, checkpoint_dir):\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        self.checkpoint_file = os.path.join(checkpoint_dir, 'progress_checkpoint.json')\n",
    "        self.results_file = os.path.join(checkpoint_dir, 'partial_results.pkl')\n",
    "        \n",
    "    def save_checkpoint(self, processed_indices, results, failed_books, progress_tracker):\n",
    "        \"\"\"Save checkpoint compatible with previous format\"\"\"\n",
    "        status = progress_tracker.get_jupyter_status()\n",
    "        \n",
    "        checkpoint_data = {\n",
    "            'processed_indices': list(processed_indices),\n",
    "            'num_results': len(results),\n",
    "            'num_failed': len(failed_books),\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'books_per_second': status['books_per_second'],\n",
    "            'success_rate': status['success_rate'],\n",
    "            'jupyter_version': True\n",
    "        }\n",
    "        \n",
    "        # Save checkpoint metadata\n",
    "        with open(self.checkpoint_file, 'w') as f:\n",
    "            json.dump(checkpoint_data, f, indent=2)\n",
    "        \n",
    "        # Save actual results\n",
    "        with open(self.results_file, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'results': results,\n",
    "                'failed_books': failed_books\n",
    "            }, f)\n",
    "        \n",
    "        print(f\"üíæ Checkpoint saved: {len(results):,} results, {len(failed_books):,} failed\")\n",
    "    \n",
    "    def load_checkpoint(self):\n",
    "        \"\"\"Load checkpoint (compatible with previous format)\"\"\"\n",
    "        if os.path.exists(self.checkpoint_file) and os.path.exists(self.results_file):\n",
    "            try:\n",
    "                # Load metadata\n",
    "                with open(self.checkpoint_file, 'r') as f:\n",
    "                    checkpoint_data = json.load(f)\n",
    "                \n",
    "                # Load results\n",
    "                with open(self.results_file, 'rb') as f:\n",
    "                    saved_data = pickle.load(f)\n",
    "                \n",
    "                print(f\"üìÇ Loaded checkpoint from {checkpoint_data['timestamp']}\")\n",
    "                print(f\"üìä Previous progress: {checkpoint_data['num_results']:,} results, {checkpoint_data['num_failed']:,} failed\")\n",
    "                \n",
    "                return (\n",
    "                    set(checkpoint_data['processed_indices']),\n",
    "                    saved_data['results'],\n",
    "                    saved_data['failed_books']\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error loading checkpoint: {e}\")\n",
    "                return set(), [], []\n",
    "        \n",
    "        return set(), [], []\n",
    "\n",
    "class JupyterModelManager:\n",
    "    \"\"\"GPU model manager for Jupyter\"\"\"\n",
    "    \n",
    "    def __init__(self, checkpoint_file, gpu_ids):\n",
    "        self.gpu_ids = gpu_ids\n",
    "        self.models = {}\n",
    "        self.current_gpu = 0\n",
    "        self.load_models(checkpoint_file)\n",
    "        \n",
    "    def load_models(self, checkpoint_file):\n",
    "        \"\"\"Load models on available GPUs\"\"\"\n",
    "        for gpu_id in self.gpu_ids:\n",
    "            try:\n",
    "                if gpu_id is not None and torch.cuda.is_available():\n",
    "                    device = torch.device(f\"cuda:{gpu_id}\")\n",
    "                    torch.cuda.set_device(gpu_id)\n",
    "                else:\n",
    "                    device = torch.device(\"cpu\")\n",
    "                    gpu_id = \"cpu\"\n",
    "                \n",
    "                model = torch_load_model(checkpoint_file)\n",
    "                model.to(device)\n",
    "                model.eval()\n",
    "                \n",
    "                self.models[gpu_id] = (model, device)\n",
    "                print(f\"üîß Model loaded on {'CPU' if gpu_id == 'cpu' else f'GPU {gpu_id}'}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error loading model on GPU {gpu_id}: {e}\")\n",
    "    \n",
    "    def get_model(self):\n",
    "        \"\"\"Get next available model (round-robin)\"\"\"\n",
    "        if not self.models:\n",
    "            return None, None\n",
    "        \n",
    "        gpu_ids = list(self.models.keys())\n",
    "        gpu_id = gpu_ids[self.current_gpu % len(gpu_ids)]\n",
    "        self.current_gpu += 1\n",
    "        \n",
    "        return self.models[gpu_id]\n",
    "    \n",
    "    def predict_batch(self, images, model, device):\n",
    "        \"\"\"Predict emotions for batch\"\"\"\n",
    "        try:\n",
    "            if not images:\n",
    "                return None\n",
    "            \n",
    "            batch = torch.stack(images).to(device, non_blocking=True)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                if device.type == 'cuda':\n",
    "                    torch.cuda.synchronize()\n",
    "                \n",
    "                predictions = model(batch)\n",
    "                probabilities = torch.exp(predictions).cpu().numpy()\n",
    "            \n",
    "            return probabilities\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Prediction error on {device}: {e}\")\n",
    "            return None\n",
    "\n",
    "class JupyterImageProcessor:\n",
    "    \"\"\"Async image processor for Jupyter\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.session = None\n",
    "        \n",
    "    async def create_session(self):\n",
    "        \"\"\"Create aiohttp session\"\"\"\n",
    "        timeout = aiohttp.ClientTimeout(total=config.DOWNLOAD_TIMEOUT)\n",
    "        connector = aiohttp.TCPConnector(\n",
    "            limit=config.MAX_CONCURRENT_DOWNLOADS,\n",
    "            limit_per_host=30,\n",
    "            keepalive_timeout=30\n",
    "        )\n",
    "        \n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        \n",
    "        self.session = aiohttp.ClientSession(\n",
    "            connector=connector,\n",
    "            timeout=timeout,\n",
    "            headers=headers\n",
    "        )\n",
    "    \n",
    "    async def close_session(self):\n",
    "        \"\"\"Close session\"\"\"\n",
    "        if self.session:\n",
    "            await self.session.close()\n",
    "    \n",
    "    async def download_image(self, url):\n",
    "        \"\"\"Download single image\"\"\"\n",
    "        for attempt in range(config.MAX_RETRIES):\n",
    "            try:\n",
    "                async with self.session.get(url) as response:\n",
    "                    if response.status == 200:\n",
    "                        image_data = await response.read()\n",
    "                        image = Image.open(io.BytesIO(image_data)).convert('RGB')\n",
    "                        return image\n",
    "                        \n",
    "            except Exception as e:\n",
    "                if attempt == config.MAX_RETRIES - 1:\n",
    "                    return None\n",
    "                await asyncio.sleep(0.1 * (attempt + 1))\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def preprocess_image(self, image, img_dim=256):\n",
    "        \"\"\"Preprocess image (matching your notebook's preprocessing)\"\"\"\n",
    "        try:\n",
    "            # Resize maintaining aspect ratio\n",
    "            image.thumbnail((img_dim, img_dim), Image.Resampling.LANCZOS)\n",
    "            \n",
    "            # Pad to square\n",
    "            new_image = Image.new('RGB', (img_dim, img_dim), (255, 255, 255))\n",
    "            x = (img_dim - image.width) // 2\n",
    "            y = (img_dim - image.height) // 2\n",
    "            new_image.paste(image, (x, y))\n",
    "            \n",
    "            # Convert to tensor and normalize (matching Artemis preprocessing)\n",
    "            image_array = np.array(new_image).astype(np.float32) / 255.0\n",
    "            image_tensor = torch.from_numpy(image_array).permute(2, 0, 1)\n",
    "            \n",
    "            # ImageNet normalization\n",
    "            mean = torch.tensor([0.485, 0.456, 0.406]).reshape(3, 1, 1)\n",
    "            std = torch.tensor([0.229, 0.224, 0.225]).reshape(3, 1, 1)\n",
    "            return (image_tensor - mean) / std\n",
    "            \n",
    "        except Exception:\n",
    "            return None\n",
    "    \n",
    "    async def process_batch_async(self, batch_df):\n",
    "        \"\"\"Process batch of images asynchronously\"\"\"\n",
    "        # Extract URLs and book data\n",
    "        urls = []\n",
    "        book_data = []\n",
    "        \n",
    "        for idx, row in batch_df.iterrows():\n",
    "            url = row.get('image_url_large', row.get('image_url', ''))\n",
    "            if url and 'nophoto' not in url:\n",
    "                urls.append(url)\n",
    "                book_data.append((idx, row))\n",
    "        \n",
    "        if not urls:\n",
    "            return [], [], []\n",
    "        \n",
    "        # Download all images concurrently\n",
    "        download_tasks = [self.download_image(url) for url in urls]\n",
    "        download_results = await asyncio.gather(*download_tasks, return_exceptions=True)\n",
    "        \n",
    "        # Process downloaded images\n",
    "        valid_images = []\n",
    "        valid_indices = []\n",
    "        valid_book_data = []\n",
    "        \n",
    "        # Use thread pool for CPU-intensive preprocessing\n",
    "        with ThreadPoolExecutor(max_workers=config.MAX_CONCURRENT_PREPROCESSING) as executor:\n",
    "            preprocess_tasks = []\n",
    "            \n",
    "            for i, result in enumerate(download_results):\n",
    "                if isinstance(result, Image.Image):\n",
    "                    task = executor.submit(self.preprocess_image, result)\n",
    "                    preprocess_tasks.append((i, task))\n",
    "            \n",
    "            # Collect preprocessing results\n",
    "            for i, task in preprocess_tasks:\n",
    "                try:\n",
    "                    processed_image = task.result(timeout=5)\n",
    "                    if processed_image is not None:\n",
    "                        valid_images.append(processed_image)\n",
    "                        valid_indices.append(i)\n",
    "                        valid_book_data.append(book_data[i])\n",
    "                except Exception:\n",
    "                    pass\n",
    "        \n",
    "        return valid_images, valid_indices, valid_book_data\n",
    "\n",
    "class JupyterEmotionPredictor:\n",
    "    \"\"\"Main predictor class for Jupyter\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.checkpoint_manager = JupyterCheckpointManager(f\"{config.RESULTS_DIR}/checkpoints\")\n",
    "        self.model_manager = JupyterModelManager(config.CHECKPOINT_FILE, config.GPU_IDS)\n",
    "        self.image_processor = JupyterImageProcessor()\n",
    "        self.progress_tracker = None\n",
    "        \n",
    "    async def process_all_books_async(self, resume_from_checkpoint=True):\n",
    "        \"\"\"Main async processing function\"\"\"\n",
    "        \n",
    "        print(\"üöÄ Starting Goodreads emotion analysis...\")\n",
    "        \n",
    "        # Load and filter data\n",
    "        print(\"üìÇ Loading Goodreads data...\")\n",
    "        try:\n",
    "            books_df = pd.read_parquet(config.DATA_FILE)\n",
    "            print(f\"üìä Loaded {len(books_df):,} total books\")\n",
    "            \n",
    "            # Filter for English books\n",
    "            books_df = filter_english_books(books_df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error loading data: {e}\")\n",
    "            return None\n",
    "        \n",
    "        # Initialize progress tracking\n",
    "        self.progress_tracker = JupyterProgressTracker(len(books_df))\n",
    "        \n",
    "        # Load previous progress if resuming\n",
    "        processed_indices = set()\n",
    "        all_results = []\n",
    "        all_failed = []\n",
    "        \n",
    "        if resume_from_checkpoint:\n",
    "            processed_indices, all_results, all_failed = self.checkpoint_manager.load_checkpoint()\n",
    "            if processed_indices:\n",
    "                print(f\"üîÑ Resuming from checkpoint: {len(processed_indices):,} books already processed\")\n",
    "                # Update progress tracker\n",
    "                self.progress_tracker.update(\n",
    "                    successful=len(all_results),\n",
    "                    failed=len(all_failed)\n",
    "                )\n",
    "        \n",
    "        # Filter out already processed books\n",
    "        remaining_books = books_df[~books_df.index.isin(processed_indices)].copy()\n",
    "        print(f\"üìã Processing {len(remaining_books):,} remaining English books\")\n",
    "        \n",
    "        if len(remaining_books) == 0:\n",
    "            print(\"‚úÖ All books already processed!\")\n",
    "            return pd.DataFrame(all_results)\n",
    "        \n",
    "        # Create aiohttp session\n",
    "        await self.image_processor.create_session()\n",
    "        \n",
    "        try:\n",
    "            # Process in batches with progress bar\n",
    "            total_batches = (len(remaining_books) + config.PROCESSING_BATCH_SIZE - 1) // config.PROCESSING_BATCH_SIZE\n",
    "            \n",
    "            print(f\"üîÑ Processing {total_batches} batches of up to {config.PROCESSING_BATCH_SIZE:,} books each\")\n",
    "            \n",
    "            # Create tqdm progress bar for batches\n",
    "            batch_progress = tqdm(range(total_batches), desc=\"Processing batches\")\n",
    "            \n",
    "            for batch_idx in batch_progress:\n",
    "                start_idx = batch_idx * config.PROCESSING_BATCH_SIZE\n",
    "                end_idx = min(start_idx + config.PROCESSING_BATCH_SIZE, len(remaining_books))\n",
    "                batch_df = remaining_books.iloc[start_idx:end_idx]\n",
    "                \n",
    "                # Process this batch asynchronously\n",
    "                batch_results, batch_failed = await self.process_batch_async(batch_df)\n",
    "                \n",
    "                # Update results\n",
    "                all_results.extend(batch_results)\n",
    "                all_failed.extend(batch_failed)\n",
    "                \n",
    "                # Update processed indices\n",
    "                for idx in batch_df.index:\n",
    "                    processed_indices.add(idx)\n",
    "                \n",
    "                # Update progress\n",
    "                self.progress_tracker.update(\n",
    "                    successful=len(batch_results),\n",
    "                    failed=len(batch_failed)\n",
    "                )\n",
    "                \n",
    "                # Update progress bar description\n",
    "                status = self.progress_tracker.get_jupyter_status()\n",
    "                batch_progress.set_postfix({\n",
    "                    'Success Rate': f\"{status['success_rate']:.1f}%\",\n",
    "                    'Speed': f\"{status['books_per_second']:.1f} books/sec\",\n",
    "                    'ETA': f\"{status['eta_hours']:.1f}h\"\n",
    "                })\n",
    "                \n",
    "                # Log detailed progress\n",
    "                if self.progress_tracker.should_log(config.PROGRESS_UPDATE_FREQUENCY):\n",
    "                    self.progress_tracker.display_progress()\n",
    "                \n",
    "                # Save checkpoint\n",
    "                checkpoint_interval = max(1, config.CHECKPOINT_FREQUENCY // config.PROCESSING_BATCH_SIZE)\n",
    "                if (batch_idx + 1) % checkpoint_interval == 0:\n",
    "                    self.checkpoint_manager.save_checkpoint(\n",
    "                        processed_indices, all_results, all_failed, self.progress_tracker\n",
    "                    )\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error during processing: {e}\")\n",
    "            return None\n",
    "        \n",
    "        finally:\n",
    "            await self.image_processor.close_session()\n",
    "        \n",
    "        # Save final results\n",
    "        return self.save_final_results(all_results, all_failed)\n",
    "    \n",
    "    async def process_batch_async(self, batch_df):\n",
    "        \"\"\"Process a single batch asynchronously\"\"\"\n",
    "        batch_results = []\n",
    "        batch_failed = []\n",
    "        \n",
    "        # Process in GPU-sized sub-batches\n",
    "        for i in range(0, len(batch_df), config.BATCH_SIZE):\n",
    "            sub_batch = batch_df.iloc[i:i+config.BATCH_SIZE]\n",
    "            \n",
    "            # Download and preprocess images asynchronously\n",
    "            images, valid_indices, valid_book_data = \\\n",
    "                await self.image_processor.process_batch_async(sub_batch)\n",
    "            \n",
    "            if not images:\n",
    "                # All failed in this sub-batch\n",
    "                for idx, row in sub_batch.iterrows():\n",
    "                    batch_failed.append({\n",
    "                        'book_id': row['book_id'],\n",
    "                        'reason': 'image_processing_failed'\n",
    "                    })\n",
    "                continue\n",
    "            \n",
    "            # Get model and predict\n",
    "            model_device = self.model_manager.get_model()\n",
    "            if model_device[0] is None:\n",
    "                print(\"‚ùå No model available\")\n",
    "                continue\n",
    "            \n",
    "            model, device = model_device\n",
    "            predictions = self.model_manager.predict_batch(images, model, device)\n",
    "            \n",
    "            if predictions is not None:\n",
    "                # Process successful predictions\n",
    "                for pred_idx, (original_idx, (idx, row)) in enumerate(zip(valid_indices, valid_book_data)):\n",
    "                    emotion_probs = predictions[pred_idx]\n",
    "                    \n",
    "                    top_emotion_idx = np.argmax(emotion_probs)\n",
    "                    top_emotion = config.EMOTION_LABELS[top_emotion_idx]\n",
    "                    confidence = emotion_probs[top_emotion_idx]\n",
    "                    \n",
    "                    result = {\n",
    "                        'book_id': row['book_id'],\n",
    "                        'title': row['title'],\n",
    "                        'authors': row['authors'],\n",
    "                        'average_rating': row.get('average_rating'),\n",
    "                        'ratings_count': row.get('ratings_count'),\n",
    "                        'publication_year': row.get('publication_year'),\n",
    "                        'language_code': row.get('language_code'),\n",
    "                        'popular_shelves': row.get('popular_shelves'),\n",
    "                        'predicted_emotion': top_emotion,\n",
    "                        'confidence': confidence,\n",
    "                        'emotion_probs': emotion_probs.tolist()\n",
    "                    }\n",
    "                    \n",
    "                    # Add individual emotion probabilities\n",
    "                    for j, emotion in enumerate(config.EMOTION_LABELS):\n",
    "                        result[f'prob_{emotion.replace(\" \", \"_\")}'] = emotion_probs[j]\n",
    "                    \n",
    "                    batch_results.append(result)\n",
    "            \n",
    "            # Add failed books\n",
    "            failed_count = len(sub_batch) - len(valid_indices)\n",
    "            for _ in range(failed_count):\n",
    "                batch_failed.append({\n",
    "                    'book_id': 'unknown',\n",
    "                    'reason': 'download_or_preprocessing_failed'\n",
    "                })\n",
    "        \n",
    "        return batch_results, batch_failed\n",
    "    \n",
    "    def save_final_results(self, results, failed):\n",
    "        \"\"\"Save final results\"\"\"\n",
    "        results_df = pd.DataFrame(results)\n",
    "        failed_df = pd.DataFrame(failed)\n",
    "        \n",
    "        # Save files\n",
    "        results_file = f\"{config.RESULTS_DIR}/goodreads_emotion_predictions_english.parquet\"\n",
    "        failed_file = f\"{config.RESULTS_DIR}/failed_books_english.csv\"\n",
    "        \n",
    "        results_df.to_parquet(results_file, index=False)\n",
    "        failed_df.to_csv(failed_file, index=False)\n",
    "        \n",
    "        # Clear checkpoint files\n",
    "        try:\n",
    "            if os.path.exists(self.checkpoint_manager.checkpoint_file):\n",
    "                os.remove(self.checkpoint_manager.checkpoint_file)\n",
    "            if os.path.exists(self.checkpoint_manager.results_file):\n",
    "                os.remove(self.checkpoint_manager.results_file)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Final statistics\n",
    "        total_processed = len(results) + len(failed)\n",
    "        success_rate = len(results) / total_processed * 100 if total_processed > 0 else 0\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üéâ PROCESSING COMPLETED!\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"üìä Total processed: {total_processed:,}\")\n",
    "        print(f\"‚úÖ Successful: {len(results):,} ({success_rate:.2f}%)\")\n",
    "        print(f\"‚ùå Failed: {len(failed):,}\")\n",
    "        print(f\"üíæ Results saved to: {results_file}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Quick emotion analysis\n",
    "        if len(results) > 0:\n",
    "            emotion_counts = results_df['predicted_emotion'].value_counts()\n",
    "            print(\"\\nüìà Top predicted emotions:\")\n",
    "            for emotion, count in emotion_counts.head().items():\n",
    "                pct = count / len(results_df) * 100\n",
    "                print(f\"  {emotion}: {count:,} ({pct:.1f}%)\")\n",
    "        \n",
    "        return results_df\n",
    "\n",
    "# Main execution function for Jupyter\n",
    "async def run_emotion_analysis(resume_from_checkpoint=True):\n",
    "    \"\"\"\n",
    "    Main function to run the emotion analysis in Jupyter\n",
    "    \n",
    "    Parameters:\n",
    "    - resume_from_checkpoint: Whether to resume from existing checkpoint (default: True)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üéØ Goodreads Book Cover Emotion Analysis\")\n",
    "    print(\"üìö Processing English books only\")\n",
    "    print(\"üîÑ Using async optimization for speed\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Check configuration\n",
    "    if not os.path.exists(config.CHECKPOINT_FILE):\n",
    "        print(f\"‚ùå Model file not found: {config.CHECKPOINT_FILE}\")\n",
    "        print(\"Please update CHECKPOINT_FILE in the config above\")\n",
    "        return None\n",
    "    \n",
    "    if not os.path.exists(config.DATA_FILE):\n",
    "        print(f\"‚ùå Data file not found: {config.DATA_FILE}\")\n",
    "        print(\"Please update DATA_FILE in the config above\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize and run predictor\n",
    "    predictor = JupyterEmotionPredictor()\n",
    "    results_df = await predictor.process_all_books_async(resume_from_checkpoint)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Convenience function for one-line execution\n",
    "def analyze_goodreads_emotions(resume_from_checkpoint=True):\n",
    "    \"\"\"\n",
    "    One-line function to run the complete analysis\n",
    "    \n",
    "    Usage:\n",
    "    results = analyze_goodreads_emotions()\n",
    "    \"\"\"\n",
    "    return asyncio.run(run_emotion_analysis(resume_from_checkpoint))\n",
    "\n",
    "# Display configuration\n",
    "print(\"üìã CONFIGURATION SUMMARY\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"üìÅ Artemis path: {config.ARTEMIS_PATH}\")\n",
    "print(f\"ü§ñ Model file: {config.CHECKPOINT_FILE}\")\n",
    "print(f\"üìä Data file: {config.DATA_FILE}\")\n",
    "print(f\"üíæ Results directory: {config.RESULTS_DIR}\")\n",
    "print(f\"üñ•Ô∏è GPUs available: {len(config.GPU_IDS) if config.GPU_IDS[0] != 0 or torch.cuda.is_available() else 0}\")\n",
    "print(f\"üîÑ Max concurrent downloads: {config.MAX_CONCURRENT_DOWNLOADS}\")\n",
    "print(f\"üì¶ Batch size: {config.BATCH_SIZE}\")\n",
    "print(\"-\" * 40)\n",
    "# Run the complete analysis (resumes from checkpoint if available)\n",
    "results = analyze_goodreads_emotions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcd6e3c6-24eb-4b3c-826c-04816232f95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Creating comprehensive ResNet emotion analysis visualizations...\n",
      "üìä Each plot will be saved as a separate image file...\n",
      "============================================================\n",
      "üñºÔ∏è RESNET IMAGE EMOTION ANALYSIS SUMMARY\n",
      "============================================================\n",
      "üìö Total books analyzed: 686,990\n",
      "üéØ Mean confidence: 0.196\n",
      "üìä Median confidence: 0.185\n",
      "üìà Std confidence: 0.048\n",
      "üîç Min confidence: 0.117\n",
      "üîç Max confidence: 0.699\n",
      "\n",
      "üé≠ EMOTION DISTRIBUTION:\n",
      "  awe            : 203,032 ( 29.6%)\n",
      "  amusement      : 179,719 ( 26.2%)\n",
      "  fear           : 172,886 ( 25.2%)\n",
      "  contentment    : 44,676 (  6.5%)\n",
      "  something else : 34,407 (  5.0%)\n",
      "  sadness        : 19,314 (  2.8%)\n",
      "  anger          : 19,093 (  2.8%)\n",
      "  excitement     : 13,863 (  2.0%)\n",
      "\n",
      "üéØ CONFIDENCE ANALYSIS:\n",
      "  Confidence ‚â• 0.5:    284 (  0.0%)\n",
      "  Confidence ‚â• 0.6:     13 (  0.0%)\n",
      "  Confidence ‚â• 0.7:      0 (  0.0%)\n",
      "  Confidence ‚â• 0.8:      0 (  0.0%)\n",
      "  Confidence ‚â• 0.9:      0 (  0.0%)\n",
      "  Confidence ‚â• 0.95:      0 (  0.0%)\n",
      "\n",
      "‚≠ê RATING ANALYSIS:\n",
      "  Books with ratings: 686,990 (100.0%)\n",
      "  Average rating: 3.90\n",
      "  Rating std: 0.47\n",
      "  Highest rated emotion: anger (3.94)\n",
      "  Lowest rated emotion: excitement (3.87)\n",
      "\n",
      "üèÜ MOST CONFIDENT PREDICTIONS:\n",
      "  fear         (0.699): When God is Silent: Choosing to Trust in...\n",
      "  fear         (0.650): Celestial Nights: Visions of an Ancient ...\n",
      "  fear         (0.643): Green Comet\n",
      "  fear         (0.634): Dreamland\n",
      "  fear         (0.625): The Hole Of The Pit\n",
      "\n",
      "üìä AVERAGE CONFIDENCE BY EMOTION:\n",
      "  fear           : 0.215 (n=172,886)\n",
      "  awe            : 0.205 (n=203,032)\n",
      "  sadness        : 0.202 (n=19,314)\n",
      "  anger          : 0.201 (n=19,093)\n",
      "  contentment    : 0.179 (n=44,676)\n",
      "  amusement      : 0.179 (n=179,719)\n",
      "  excitement     : 0.175 (n=13,863)\n",
      "  something else : 0.160 (n=34,407)\n",
      "============================================================\n",
      "üé® Creating ResNet emotion analysis visualizations...\n",
      "‚úÖ Saved: resnet_visualizations/01_emotion_distribution.png\n",
      "‚úÖ Saved: resnet_visualizations/02_confidence_distribution.png\n",
      "‚úÖ Saved: resnet_visualizations/03_confidence_by_emotion.png\n",
      "‚úÖ Saved: resnet_visualizations/04_confidence_thresholds.png\n",
      "‚úÖ Saved: resnet_visualizations/05_ratings_by_emotion.png\n",
      "‚úÖ Saved: resnet_visualizations/06_emotions_by_decade.png\n",
      "‚úÖ Saved: resnet_visualizations/07_emotion_probability_heatmap.png\n",
      "‚úÖ Saved: resnet_visualizations/08_confidence_vs_rating.png\n",
      "‚úÖ Saved: resnet_visualizations/09_top_confident_predictions.png\n",
      "‚úÖ Saved: resnet_visualizations/10_summary_dashboard.png\n",
      "\n",
      "üéâ All ResNet visualizations saved to: resnet_visualizations\n",
      "\n",
      "‚úÖ Analysis complete! All visualizations saved to: resnet_visualizations\n",
      "üìÅ Created 10 visualization files\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>language_code</th>\n",
       "      <th>popular_shelves</th>\n",
       "      <th>predicted_emotion</th>\n",
       "      <th>confidence</th>\n",
       "      <th>emotion_probs</th>\n",
       "      <th>prob_amusement</th>\n",
       "      <th>prob_anger</th>\n",
       "      <th>prob_awe</th>\n",
       "      <th>prob_contentment</th>\n",
       "      <th>prob_disgust</th>\n",
       "      <th>prob_excitement</th>\n",
       "      <th>prob_fear</th>\n",
       "      <th>prob_sadness</th>\n",
       "      <th>prob_something_else</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7327624</td>\n",
       "      <td>The Unschooled Wizard (Sun Wolf and Starhawk, ...</td>\n",
       "      <td>[{'author_id': '10333', 'role': ''}]</td>\n",
       "      <td>4.03</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '58', 'name': 'to-read'}, {'count':...</td>\n",
       "      <td>awe</td>\n",
       "      <td>0.167223</td>\n",
       "      <td>[0.13469205796718597, 0.09353847801685333, 0.1...</td>\n",
       "      <td>0.134692</td>\n",
       "      <td>0.093538</td>\n",
       "      <td>0.167223</td>\n",
       "      <td>0.102514</td>\n",
       "      <td>0.038228</td>\n",
       "      <td>0.078381</td>\n",
       "      <td>0.139589</td>\n",
       "      <td>0.143998</td>\n",
       "      <td>0.101838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6066812</td>\n",
       "      <td>All's Fairy in Love and War (Avalon: Web of Ma...</td>\n",
       "      <td>[{'author_id': '19158', 'role': ''}]</td>\n",
       "      <td>4.22</td>\n",
       "      <td>98.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>en</td>\n",
       "      <td>[{'count': '515', 'name': 'to-read'}, {'count'...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.191088</td>\n",
       "      <td>[0.12145131081342697, 0.19108839333057404, 0.1...</td>\n",
       "      <td>0.121451</td>\n",
       "      <td>0.191088</td>\n",
       "      <td>0.170192</td>\n",
       "      <td>0.170070</td>\n",
       "      <td>0.026302</td>\n",
       "      <td>0.056422</td>\n",
       "      <td>0.124048</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>0.058126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34883016</td>\n",
       "      <td>Playmaker: A Venom Series Novella</td>\n",
       "      <td>[{'author_id': '5807700', 'role': ''}]</td>\n",
       "      <td>3.86</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017</td>\n",
       "      <td>en</td>\n",
       "      <td>[{'count': '4', 'name': 'to-read'}, {'count': ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.154665</td>\n",
       "      <td>[0.09836606681346893, 0.09562262892723083, 0.1...</td>\n",
       "      <td>0.098366</td>\n",
       "      <td>0.095623</td>\n",
       "      <td>0.108461</td>\n",
       "      <td>0.129003</td>\n",
       "      <td>0.083867</td>\n",
       "      <td>0.093636</td>\n",
       "      <td>0.154665</td>\n",
       "      <td>0.116781</td>\n",
       "      <td>0.119598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>287149</td>\n",
       "      <td>The Devil's Notebook</td>\n",
       "      <td>[{'author_id': '2983296', 'role': ''}, {'autho...</td>\n",
       "      <td>3.81</td>\n",
       "      <td>986.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>en</td>\n",
       "      <td>[{'count': '961', 'name': 'to-read'}, {'count'...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.245942</td>\n",
       "      <td>[0.06065783277153969, 0.08587128669023514, 0.1...</td>\n",
       "      <td>0.060658</td>\n",
       "      <td>0.085871</td>\n",
       "      <td>0.122800</td>\n",
       "      <td>0.075539</td>\n",
       "      <td>0.043163</td>\n",
       "      <td>0.068727</td>\n",
       "      <td>0.245942</td>\n",
       "      <td>0.142215</td>\n",
       "      <td>0.155085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6066814</td>\n",
       "      <td>Crowner Royal (Crowner John Mystery, #13)</td>\n",
       "      <td>[{'author_id': '37778', 'role': ''}]</td>\n",
       "      <td>3.93</td>\n",
       "      <td>186.0</td>\n",
       "      <td>2009</td>\n",
       "      <td>en</td>\n",
       "      <td>[{'count': '159', 'name': 'to-read'}, {'count'...</td>\n",
       "      <td>contentment</td>\n",
       "      <td>0.180720</td>\n",
       "      <td>[0.16852310299873352, 0.10087335109710693, 0.1...</td>\n",
       "      <td>0.168523</td>\n",
       "      <td>0.100873</td>\n",
       "      <td>0.113825</td>\n",
       "      <td>0.180720</td>\n",
       "      <td>0.043875</td>\n",
       "      <td>0.066154</td>\n",
       "      <td>0.147142</td>\n",
       "      <td>0.088792</td>\n",
       "      <td>0.090095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686985</th>\n",
       "      <td>23252156</td>\n",
       "      <td>Wicked Reflection</td>\n",
       "      <td>[{'author_id': '4590885', 'role': ''}]</td>\n",
       "      <td>4.00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '36', 'name': 'to-read'}, {'count':...</td>\n",
       "      <td>amusement</td>\n",
       "      <td>0.165978</td>\n",
       "      <td>[0.1659782975912094, 0.09699578583240509, 0.10...</td>\n",
       "      <td>0.165978</td>\n",
       "      <td>0.096996</td>\n",
       "      <td>0.100686</td>\n",
       "      <td>0.148526</td>\n",
       "      <td>0.058673</td>\n",
       "      <td>0.100618</td>\n",
       "      <td>0.138341</td>\n",
       "      <td>0.086296</td>\n",
       "      <td>0.103887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686986</th>\n",
       "      <td>18069148</td>\n",
       "      <td>Different Breeds</td>\n",
       "      <td>[{'author_id': '5344314', 'role': ''}]</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '4', 'name': 'to-read'}, {'count': ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.139925</td>\n",
       "      <td>[0.12173610925674438, 0.09961151331663132, 0.1...</td>\n",
       "      <td>0.121736</td>\n",
       "      <td>0.099612</td>\n",
       "      <td>0.126545</td>\n",
       "      <td>0.079603</td>\n",
       "      <td>0.076664</td>\n",
       "      <td>0.106225</td>\n",
       "      <td>0.139925</td>\n",
       "      <td>0.111887</td>\n",
       "      <td>0.137802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686987</th>\n",
       "      <td>3084038</td>\n",
       "      <td>This Sceptred Isle, Vol. 10: The Age of Victor...</td>\n",
       "      <td>[{'author_id': '4015', 'role': ''}, {'author_i...</td>\n",
       "      <td>4.05</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1999</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '11', 'name': 'to-read'}, {'count':...</td>\n",
       "      <td>awe</td>\n",
       "      <td>0.240141</td>\n",
       "      <td>[0.13476848602294922, 0.10167520493268967, 0.2...</td>\n",
       "      <td>0.134768</td>\n",
       "      <td>0.101675</td>\n",
       "      <td>0.240141</td>\n",
       "      <td>0.100583</td>\n",
       "      <td>0.038896</td>\n",
       "      <td>0.066142</td>\n",
       "      <td>0.073695</td>\n",
       "      <td>0.145328</td>\n",
       "      <td>0.098772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686988</th>\n",
       "      <td>26168430</td>\n",
       "      <td>Sherlock Holmes and the July Crisis</td>\n",
       "      <td>[{'author_id': '2448', 'role': ''}, {'author_i...</td>\n",
       "      <td>3.50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '702', 'name': 'to-read'}, {'count'...</td>\n",
       "      <td>awe</td>\n",
       "      <td>0.171474</td>\n",
       "      <td>[0.12546782195568085, 0.14953885972499847, 0.1...</td>\n",
       "      <td>0.125468</td>\n",
       "      <td>0.149539</td>\n",
       "      <td>0.171474</td>\n",
       "      <td>0.086329</td>\n",
       "      <td>0.028095</td>\n",
       "      <td>0.084800</td>\n",
       "      <td>0.112041</td>\n",
       "      <td>0.100494</td>\n",
       "      <td>0.141759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686989</th>\n",
       "      <td>22017381</td>\n",
       "      <td>101 Nights: Volume One (101 Nights, #1-3)</td>\n",
       "      <td>[{'author_id': '7789809', 'role': ''}]</td>\n",
       "      <td>4.37</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>eng</td>\n",
       "      <td>[{'count': '56', 'name': 'to-read'}, {'count':...</td>\n",
       "      <td>awe</td>\n",
       "      <td>0.185839</td>\n",
       "      <td>[0.18485914170742035, 0.12809523940086365, 0.1...</td>\n",
       "      <td>0.184859</td>\n",
       "      <td>0.128095</td>\n",
       "      <td>0.185839</td>\n",
       "      <td>0.108494</td>\n",
       "      <td>0.022641</td>\n",
       "      <td>0.093042</td>\n",
       "      <td>0.091466</td>\n",
       "      <td>0.079474</td>\n",
       "      <td>0.106090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>686990 rows √ó 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         book_id                                              title  \\\n",
       "0        7327624  The Unschooled Wizard (Sun Wolf and Starhawk, ...   \n",
       "1        6066812  All's Fairy in Love and War (Avalon: Web of Ma...   \n",
       "2       34883016                  Playmaker: A Venom Series Novella   \n",
       "3         287149                               The Devil's Notebook   \n",
       "4        6066814          Crowner Royal (Crowner John Mystery, #13)   \n",
       "...          ...                                                ...   \n",
       "686985  23252156                                  Wicked Reflection   \n",
       "686986  18069148                                   Different Breeds   \n",
       "686987   3084038  This Sceptred Isle, Vol. 10: The Age of Victor...   \n",
       "686988  26168430                Sherlock Holmes and the July Crisis   \n",
       "686989  22017381          101 Nights: Volume One (101 Nights, #1-3)   \n",
       "\n",
       "                                                  authors  average_rating  \\\n",
       "0                    [{'author_id': '10333', 'role': ''}]            4.03   \n",
       "1                    [{'author_id': '19158', 'role': ''}]            4.22   \n",
       "2                  [{'author_id': '5807700', 'role': ''}]            3.86   \n",
       "3       [{'author_id': '2983296', 'role': ''}, {'autho...            3.81   \n",
       "4                    [{'author_id': '37778', 'role': ''}]            3.93   \n",
       "...                                                   ...             ...   \n",
       "686985             [{'author_id': '4590885', 'role': ''}]            4.00   \n",
       "686986             [{'author_id': '5344314', 'role': ''}]            2.00   \n",
       "686987  [{'author_id': '4015', 'role': ''}, {'author_i...            4.05   \n",
       "686988  [{'author_id': '2448', 'role': ''}, {'author_i...            3.50   \n",
       "686989             [{'author_id': '7789809', 'role': ''}]            4.37   \n",
       "\n",
       "        ratings_count publication_year language_code  \\\n",
       "0               140.0             1987           eng   \n",
       "1                98.0             2009            en   \n",
       "2                 5.0             2017            en   \n",
       "3               986.0             2000            en   \n",
       "4               186.0             2009            en   \n",
       "...               ...              ...           ...   \n",
       "686985           16.0             2014           eng   \n",
       "686986            2.0             2013           eng   \n",
       "686987           12.0             1999           eng   \n",
       "686988            6.0             2015           eng   \n",
       "686989           70.0             2014           eng   \n",
       "\n",
       "                                          popular_shelves predicted_emotion  \\\n",
       "0       [{'count': '58', 'name': 'to-read'}, {'count':...               awe   \n",
       "1       [{'count': '515', 'name': 'to-read'}, {'count'...             anger   \n",
       "2       [{'count': '4', 'name': 'to-read'}, {'count': ...              fear   \n",
       "3       [{'count': '961', 'name': 'to-read'}, {'count'...              fear   \n",
       "4       [{'count': '159', 'name': 'to-read'}, {'count'...       contentment   \n",
       "...                                                   ...               ...   \n",
       "686985  [{'count': '36', 'name': 'to-read'}, {'count':...         amusement   \n",
       "686986  [{'count': '4', 'name': 'to-read'}, {'count': ...              fear   \n",
       "686987  [{'count': '11', 'name': 'to-read'}, {'count':...               awe   \n",
       "686988  [{'count': '702', 'name': 'to-read'}, {'count'...               awe   \n",
       "686989  [{'count': '56', 'name': 'to-read'}, {'count':...               awe   \n",
       "\n",
       "        confidence                                      emotion_probs  \\\n",
       "0         0.167223  [0.13469205796718597, 0.09353847801685333, 0.1...   \n",
       "1         0.191088  [0.12145131081342697, 0.19108839333057404, 0.1...   \n",
       "2         0.154665  [0.09836606681346893, 0.09562262892723083, 0.1...   \n",
       "3         0.245942  [0.06065783277153969, 0.08587128669023514, 0.1...   \n",
       "4         0.180720  [0.16852310299873352, 0.10087335109710693, 0.1...   \n",
       "...            ...                                                ...   \n",
       "686985    0.165978  [0.1659782975912094, 0.09699578583240509, 0.10...   \n",
       "686986    0.139925  [0.12173610925674438, 0.09961151331663132, 0.1...   \n",
       "686987    0.240141  [0.13476848602294922, 0.10167520493268967, 0.2...   \n",
       "686988    0.171474  [0.12546782195568085, 0.14953885972499847, 0.1...   \n",
       "686989    0.185839  [0.18485914170742035, 0.12809523940086365, 0.1...   \n",
       "\n",
       "        prob_amusement  prob_anger  prob_awe  prob_contentment  prob_disgust  \\\n",
       "0             0.134692    0.093538  0.167223          0.102514      0.038228   \n",
       "1             0.121451    0.191088  0.170192          0.170070      0.026302   \n",
       "2             0.098366    0.095623  0.108461          0.129003      0.083867   \n",
       "3             0.060658    0.085871  0.122800          0.075539      0.043163   \n",
       "4             0.168523    0.100873  0.113825          0.180720      0.043875   \n",
       "...                ...         ...       ...               ...           ...   \n",
       "686985        0.165978    0.096996  0.100686          0.148526      0.058673   \n",
       "686986        0.121736    0.099612  0.126545          0.079603      0.076664   \n",
       "686987        0.134768    0.101675  0.240141          0.100583      0.038896   \n",
       "686988        0.125468    0.149539  0.171474          0.086329      0.028095   \n",
       "686989        0.184859    0.128095  0.185839          0.108494      0.022641   \n",
       "\n",
       "        prob_excitement  prob_fear  prob_sadness  prob_something_else  \n",
       "0              0.078381   0.139589      0.143998             0.101838  \n",
       "1              0.056422   0.124048      0.082300             0.058126  \n",
       "2              0.093636   0.154665      0.116781             0.119598  \n",
       "3              0.068727   0.245942      0.142215             0.155085  \n",
       "4              0.066154   0.147142      0.088792             0.090095  \n",
       "...                 ...        ...           ...                  ...  \n",
       "686985         0.100618   0.138341      0.086296             0.103887  \n",
       "686986         0.106225   0.139925      0.111887             0.137802  \n",
       "686987         0.066142   0.073695      0.145328             0.098772  \n",
       "686988         0.084800   0.112041      0.100494             0.141759  \n",
       "686989         0.093042   0.091466      0.079474             0.106090  \n",
       "\n",
       "[686990 rows x 20 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ResNet Emotion Analysis Visualization Functions\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_resnet_visualizations(results_df, save_dir=None):\n",
    "    \"\"\"\n",
    "    Create comprehensive visualizations for ResNet emotion analysis results\n",
    "    Each plot is saved as a separate image file\n",
    "    \n",
    "    Parameters:\n",
    "    - results_df: DataFrame with ResNet emotion predictions from image analysis\n",
    "    - save_dir: Directory to save plots (optional)\n",
    "    \"\"\"\n",
    "    \n",
    "    if results_df is None or len(results_df) == 0:\n",
    "        print(\"‚ùå No results to visualize\")\n",
    "        return\n",
    "    \n",
    "    if save_dir is None:\n",
    "        save_dir = 'resnet_visualizations'\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Set up the plotting style\n",
    "    plt.style.use('default')\n",
    "    sns.set_palette(\"husl\")\n",
    "    \n",
    "    print(\"üé® Creating ResNet emotion analysis visualizations...\")\n",
    "    \n",
    "    # Get emotion labels (assuming same as BERT)\n",
    "    try:\n",
    "        from artemis.emotions import ARTEMIS_EMOTIONS\n",
    "        emotion_labels = ARTEMIS_EMOTIONS\n",
    "    except:\n",
    "        emotion_labels = ['amusement', 'anger', 'awe', 'contentment', 'disgust', \n",
    "                         'excitement', 'fear', 'sadness', 'something else']\n",
    "    \n",
    "    # 1. Emotion Distribution Bar Chart\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    emotion_counts = results_df['predicted_emotion'].value_counts()\n",
    "    bars = plt.bar(range(len(emotion_counts)), emotion_counts.values, \n",
    "                   alpha=0.8, color='steelblue', edgecolor='black')\n",
    "    plt.xticks(range(len(emotion_counts)), emotion_counts.index, rotation=45, ha='right')\n",
    "    plt.title('Emotion Distribution in Goodreads Book Covers\\n(ResNet Image Analysis)', \n",
    "              fontsize=14, pad=20)\n",
    "    plt.ylabel('Number of Books', fontsize=12)\n",
    "    plt.xlabel('Predicted Emotion', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, value) in enumerate(zip(bars, emotion_counts.values)):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(emotion_counts.values) * 0.01, \n",
    "                f'{value:,}\\n({value/len(results_df)*100:.1f}%)', \n",
    "                ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_dir}/01_emotion_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"‚úÖ Saved: {save_dir}/01_emotion_distribution.png\")\n",
    "    \n",
    "    # 2. Confidence Distribution Histogram\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(results_df['confidence'], bins=50, alpha=0.7, color='skyblue', \n",
    "             edgecolor='black', density=True)\n",
    "    plt.axvline(results_df['confidence'].mean(), color='red', linestyle='--', linewidth=2,\n",
    "                label=f'Mean: {results_df[\"confidence\"].mean():.3f}')\n",
    "    plt.axvline(results_df['confidence'].median(), color='orange', linestyle='--', linewidth=2,\n",
    "                label=f'Median: {results_df[\"confidence\"].median():.3f}')\n",
    "    plt.title('Prediction Confidence Distribution (ResNet)', fontsize=14, pad=20)\n",
    "    plt.xlabel('Confidence Score', fontsize=12)\n",
    "    plt.ylabel('Density', fontsize=12)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # Add statistics text box\n",
    "    stats_text = f'Mean: {results_df[\"confidence\"].mean():.3f}\\n'\n",
    "    stats_text += f'Std: {results_df[\"confidence\"].std():.3f}\\n'\n",
    "    stats_text += f'Min: {results_df[\"confidence\"].min():.3f}\\n'\n",
    "    stats_text += f'Max: {results_df[\"confidence\"].max():.3f}'\n",
    "    plt.text(0.02, 0.98, stats_text, transform=plt.gca().transAxes, \n",
    "             bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8),\n",
    "             verticalalignment='top', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_dir}/02_confidence_distribution.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"‚úÖ Saved: {save_dir}/02_confidence_distribution.png\")\n",
    "    \n",
    "    # 3. Average Confidence by Emotion\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    emotion_confidence = results_df.groupby('predicted_emotion')['confidence'].agg(['mean', 'std']).sort_values('mean', ascending=False)\n",
    "    \n",
    "    x_pos = range(len(emotion_confidence))\n",
    "    bars = plt.bar(x_pos, emotion_confidence['mean'].values, \n",
    "                   yerr=emotion_confidence['std'].values, \n",
    "                   alpha=0.8, capsize=5, color='lightcoral', edgecolor='black')\n",
    "    \n",
    "    plt.xticks(x_pos, emotion_confidence.index, rotation=45, ha='right')\n",
    "    plt.title('Average Prediction Confidence by Emotion (ResNet)', fontsize=14, pad=20)\n",
    "    plt.ylabel('Average Confidence Score', fontsize=12)\n",
    "    plt.xlabel('Predicted Emotion', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, mean_val, std_val) in enumerate(zip(bars, emotion_confidence['mean'].values, emotion_confidence['std'].values)):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + std_val + 0.01, \n",
    "                f'{mean_val:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_dir}/03_confidence_by_emotion.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"‚úÖ Saved: {save_dir}/03_confidence_by_emotion.png\")\n",
    "    \n",
    "    # 4. High Confidence Predictions Analysis\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    confidence_thresholds = [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "    coverage_data = []\n",
    "    \n",
    "    for threshold in confidence_thresholds:\n",
    "        high_conf_count = (results_df['confidence'] >= threshold).sum()\n",
    "        coverage_pct = (high_conf_count / len(results_df)) * 100\n",
    "        coverage_data.append(coverage_pct)\n",
    "    \n",
    "    bars = plt.bar(range(len(confidence_thresholds)), coverage_data, \n",
    "                   alpha=0.8, color='gold', edgecolor='black')\n",
    "    plt.xticks(range(len(confidence_thresholds)), \n",
    "               [f'‚â•{t}' for t in confidence_thresholds])\n",
    "    plt.title('Coverage at Different Confidence Thresholds (ResNet)', fontsize=14, pad=20)\n",
    "    plt.ylabel('Coverage (%)', fontsize=12)\n",
    "    plt.xlabel('Confidence Threshold', fontsize=12)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, value) in enumerate(zip(bars, coverage_data)):\n",
    "        count = (results_df['confidence'] >= confidence_thresholds[i]).sum()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "                f'{value:.1f}%\\n({count:,})', ha='center', va='bottom', \n",
    "                fontsize=10, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_dir}/04_confidence_thresholds.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"‚úÖ Saved: {save_dir}/04_confidence_thresholds.png\")\n",
    "    \n",
    "    # 5. Book Ratings vs Predicted Emotions\n",
    "    if 'average_rating' in results_df.columns:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Remove books without ratings\n",
    "        rated_books = results_df.dropna(subset=['average_rating'])\n",
    "        \n",
    "        if len(rated_books) > 0:\n",
    "            emotion_ratings = rated_books.groupby('predicted_emotion')['average_rating'].agg(['mean', 'std', 'count'])\n",
    "            emotion_ratings = emotion_ratings.sort_values('mean', ascending=False)\n",
    "            \n",
    "            x_pos = range(len(emotion_ratings))\n",
    "            bars = plt.bar(x_pos, emotion_ratings['mean'].values, \n",
    "                          yerr=emotion_ratings['std'].values, \n",
    "                          alpha=0.8, capsize=5, color='lightgreen', edgecolor='black')\n",
    "            \n",
    "            plt.xticks(x_pos, emotion_ratings.index, rotation=45, ha='right')\n",
    "            plt.title('Average Book Rating by Predicted Emotion (ResNet)', fontsize=14, pad=20)\n",
    "            plt.ylabel('Average Rating', fontsize=12)\n",
    "            plt.xlabel('Predicted Emotion', fontsize=12)\n",
    "            plt.grid(axis='y', alpha=0.3)\n",
    "            plt.ylim(0, 5)\n",
    "            \n",
    "            # Add value labels and count\n",
    "            for i, (bar, mean_val, count) in enumerate(zip(bars, emotion_ratings['mean'].values, emotion_ratings['count'].values)):\n",
    "                plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "                        f'{mean_val:.2f}\\n(n={count:,})', ha='center', va='bottom', \n",
    "                        fontsize=9, fontweight='bold')\n",
    "        else:\n",
    "            plt.text(0.5, 0.5, 'No rating data available', ha='center', va='center', \n",
    "                    transform=plt.gca().transAxes, fontsize=14)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{save_dir}/05_ratings_by_emotion.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"‚úÖ Saved: {save_dir}/05_ratings_by_emotion.png\")\n",
    "    \n",
    "    # 6. Publication Year vs Emotions (if available)\n",
    "    if 'publication_year' in results_df.columns:\n",
    "        plt.figure(figsize=(14, 8))\n",
    "\n",
    "        # Filter reasonable publication years\n",
    "        year_data = results_df.dropna(subset=['publication_year'])\n",
    "        year_data['publication_year'] = pd.to_numeric(year_data['publication_year'], errors='coerce').astype(int)\n",
    "        year_data = year_data[(year_data['publication_year'] >= 1800) & \n",
    "                             (year_data['publication_year'] <= 2024)]\n",
    "        \n",
    "        if len(year_data) > 0:\n",
    "            # Create decade bins\n",
    "            year_data['decade'] = (year_data['publication_year'] // 10) * 10\n",
    "            decade_emotions = year_data.groupby(['decade', 'predicted_emotion']).size().unstack(fill_value=0)\n",
    "            \n",
    "            # Convert to percentages\n",
    "            decade_emotions_pct = decade_emotions.div(decade_emotions.sum(axis=1), axis=0) * 100\n",
    "            \n",
    "            # Plot stacked bar chart\n",
    "            decade_emotions_pct.plot(kind='bar', stacked=True, figsize=(14, 8), \n",
    "                                   colormap='tab10', alpha=0.8)\n",
    "            plt.title('Emotion Distribution by Publication Decade (ResNet)', fontsize=14, pad=20)\n",
    "            plt.xlabel('Publication Decade', fontsize=12)\n",
    "            plt.ylabel('Percentage of Books', fontsize=12)\n",
    "            plt.legend(title='Predicted Emotion', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.grid(axis='y', alpha=0.3)\n",
    "        else:\n",
    "            plt.text(0.5, 0.5, 'No publication year data available', ha='center', va='center', \n",
    "                    transform=plt.gca().transAxes, fontsize=14)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{save_dir}/06_emotions_by_decade.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"‚úÖ Saved: {save_dir}/06_emotions_by_decade.png\")\n",
    "    \n",
    "    # 7. Emotion Probability Heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Get probability columns\n",
    "    prob_columns = [col for col in results_df.columns if col.startswith('prob_')]\n",
    "    \n",
    "    if prob_columns:\n",
    "        # Sample for visualization (to avoid overcrowding)\n",
    "        sample_size = min(100, len(results_df))\n",
    "        sample_df = results_df.sample(sample_size, random_state=42)\n",
    "        \n",
    "        # Create probability matrix\n",
    "        prob_matrix = sample_df[prob_columns].values.T\n",
    "        emotion_names = [col.replace('prob_', '').replace('_', ' ') for col in prob_columns]\n",
    "        \n",
    "        # Create heatmap\n",
    "        im = plt.imshow(prob_matrix, cmap='YlOrRd', aspect='auto', vmin=0, vmax=1)\n",
    "        plt.colorbar(im, shrink=0.8, label='Probability')\n",
    "        plt.yticks(range(len(emotion_names)), emotion_names)\n",
    "        plt.xlabel(f'Book Samples (Random {sample_size} books)', fontsize=12)\n",
    "        plt.ylabel('Emotions', fontsize=12)\n",
    "        plt.title('Emotion Probability Heatmap (ResNet)', fontsize=14, pad=20)\n",
    "        \n",
    "        # Add grid\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No probability data available', ha='center', va='center', \n",
    "                transform=plt.gca().transAxes, fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_dir}/07_emotion_probability_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"‚úÖ Saved: {save_dir}/07_emotion_probability_heatmap.png\")\n",
    "    \n",
    "    # 8. Confidence vs Rating Scatter Plot\n",
    "    if 'average_rating' in results_df.columns:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        \n",
    "        rated_confident = results_df.dropna(subset=['average_rating'])\n",
    "        \n",
    "        if len(rated_confident) > 0:\n",
    "            # Create scatter plot with alpha for overlapping points\n",
    "            scatter = plt.scatter(rated_confident['confidence'], rated_confident['average_rating'], \n",
    "                                alpha=0.6, s=20, c=rated_confident['confidence'], \n",
    "                                cmap='viridis', edgecolors='black', linewidth=0.5)\n",
    "            \n",
    "            # Add trend line\n",
    "            z = np.polyfit(rated_confident['confidence'], rated_confident['average_rating'], 1)\n",
    "            p = np.poly1d(z)\n",
    "            plt.plot(rated_confident['confidence'], p(rated_confident['confidence']), \n",
    "                    \"r--\", alpha=0.8, linewidth=2, label=f'Trend line')\n",
    "            \n",
    "            plt.colorbar(scatter, label='Confidence Score')\n",
    "            plt.xlabel('Prediction Confidence', fontsize=12)\n",
    "            plt.ylabel('Average Book Rating', fontsize=12)\n",
    "            plt.title('Prediction Confidence vs Book Rating (ResNet)', fontsize=14, pad=20)\n",
    "            plt.grid(alpha=0.3)\n",
    "            plt.legend()\n",
    "            \n",
    "            # Calculate correlation\n",
    "            correlation = rated_confident['confidence'].corr(rated_confident['average_rating'])\n",
    "            plt.text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "                    transform=plt.gca().transAxes, \n",
    "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8),\n",
    "                    fontsize=12, fontweight='bold')\n",
    "        else:\n",
    "            plt.text(0.5, 0.5, 'No rating data available', ha='center', va='center', \n",
    "                    transform=plt.gca().transAxes, fontsize=14)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{save_dir}/08_confidence_vs_rating.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"‚úÖ Saved: {save_dir}/08_confidence_vs_rating.png\")\n",
    "    \n",
    "    # 9. Top Confident Predictions by Emotion\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    # Get most confident prediction for each emotion\n",
    "    top_confident_by_emotion = results_df.loc[results_df.groupby('predicted_emotion')['confidence'].idxmax()]\n",
    "    \n",
    "    if len(top_confident_by_emotion) > 0:\n",
    "        emotions = top_confident_by_emotion['predicted_emotion'].values\n",
    "        confidences = top_confident_by_emotion['confidence'].values\n",
    "        \n",
    "        bars = plt.bar(range(len(emotions)), confidences, \n",
    "                      alpha=0.8, color='purple', edgecolor='black')\n",
    "        plt.xticks(range(len(emotions)), emotions, rotation=45, ha='right')\n",
    "        plt.title('Highest Confidence Prediction per Emotion (ResNet)', fontsize=14, pad=20)\n",
    "        plt.ylabel('Confidence Score', fontsize=12)\n",
    "        plt.xlabel('Predicted Emotion', fontsize=12)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.ylim(0, 1)\n",
    "        \n",
    "        # Add value labels and book titles\n",
    "        for i, (bar, conf, title) in enumerate(zip(bars, confidences, top_confident_by_emotion['title'])):\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                    f'{conf:.3f}', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "            # Add truncated title below bar\n",
    "            truncated_title = title[:20] + '...' if len(str(title)) > 20 else str(title)\n",
    "            plt.text(bar.get_x() + bar.get_width()/2, -0.05, truncated_title, \n",
    "                    ha='center', va='top', fontsize=8, rotation=45)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, 'No data available', ha='center', va='center', \n",
    "                transform=plt.gca().transAxes, fontsize=14)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_dir}/09_top_confident_predictions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"‚úÖ Saved: {save_dir}/09_top_confident_predictions.png\")\n",
    "    \n",
    "    # 10. Summary Statistics Visualization\n",
    "    create_resnet_summary_plot(results_df, save_dir)\n",
    "    \n",
    "    print(f\"\\nüéâ All ResNet visualizations saved to: {save_dir}\")\n",
    "    return save_dir\n",
    "\n",
    "def create_resnet_summary_plot(results_df, save_dir):\n",
    "    \"\"\"Create a summary statistics visualization\"\"\"\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Summary statistics table\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    stats = {\n",
    "        'Total Books Analyzed': f\"{len(results_df):,}\",\n",
    "        'Mean Confidence': f\"{results_df['confidence'].mean():.3f}\",\n",
    "        'Median Confidence': f\"{results_df['confidence'].median():.3f}\",\n",
    "        'Std Confidence': f\"{results_df['confidence'].std():.3f}\",\n",
    "        'High Confidence (>0.8)': f\"{(results_df['confidence'] > 0.8).sum():,} ({(results_df['confidence'] > 0.8).mean()*100:.1f}%)\",\n",
    "        'Most Common Emotion': f\"{results_df['predicted_emotion'].mode().iloc[0]}\",\n",
    "        'Least Common Emotion': f\"{results_df['predicted_emotion'].value_counts().index[-1]}\",\n",
    "        'Unique Emotions Found': f\"{results_df['predicted_emotion'].nunique()}\"\n",
    "    }\n",
    "    \n",
    "    if 'average_rating' in results_df.columns:\n",
    "        rated_books = results_df.dropna(subset=['average_rating'])\n",
    "        if len(rated_books) > 0:\n",
    "            stats['Books with Ratings'] = f\"{len(rated_books):,} ({len(rated_books)/len(results_df)*100:.1f}%)\"\n",
    "            stats['Avg Book Rating'] = f\"{rated_books['average_rating'].mean():.2f}\"\n",
    "    \n",
    "    # Create table\n",
    "    table_data = [[key, value] for key, value in stats.items()]\n",
    "    table = ax1.table(cellText=table_data, colLabels=['Metric', 'Value'],\n",
    "                     cellLoc='left', loc='center', bbox=[0, 0, 1, 1])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(11)\n",
    "    table.scale(1.2, 2)\n",
    "    \n",
    "    # Style the table\n",
    "    for i in range(len(stats) + 1):\n",
    "        table[(i, 0)].set_facecolor('#E8E8E8')\n",
    "        table[(i, 1)].set_facecolor('#F5F5F5')\n",
    "        if i == 0:  # Header\n",
    "            table[(i, 0)].set_facecolor('#D0D0D0')\n",
    "            table[(i, 1)].set_facecolor('#D0D0D0')\n",
    "    \n",
    "    ax1.set_title('ResNet Analysis Summary Statistics', fontsize=14, pad=20, fontweight='bold')\n",
    "    \n",
    "    # Emotion distribution pie chart\n",
    "    emotion_counts = results_df['predicted_emotion'].value_counts()\n",
    "    top_emotions = emotion_counts.head(6)  # Top 6 emotions\n",
    "    if len(emotion_counts) > 6:\n",
    "        other_count = emotion_counts.iloc[6:].sum()\n",
    "        top_emotions['Others'] = other_count\n",
    "    \n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(top_emotions)))\n",
    "    wedges, texts, autotexts = ax2.pie(top_emotions.values, labels=top_emotions.index, \n",
    "                                      autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    ax2.set_title('Top Emotions Distribution', fontsize=14, pad=20, fontweight='bold')\n",
    "    \n",
    "    # Enhance pie chart text\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('black')\n",
    "        autotext.set_fontweight('bold')\n",
    "        autotext.set_fontsize(10)\n",
    "    \n",
    "    # Confidence quartiles\n",
    "    quartiles = results_df['confidence'].quantile([0.25, 0.5, 0.75, 1.0])\n",
    "    quartile_labels = ['Q1 (25%)', 'Q2 (50%)', 'Q3 (75%)', 'Q4 (100%)']\n",
    "    quartile_values = [quartiles[0.25], quartiles[0.5], quartiles[0.75], quartiles[1.0]]\n",
    "    \n",
    "    bars = ax3.bar(quartile_labels, quartile_values, alpha=0.8, color='lightblue', edgecolor='black')\n",
    "    ax3.set_title('Confidence Score Quartiles', fontsize=14, pad=20, fontweight='bold')\n",
    "    ax3.set_ylabel('Confidence Score', fontsize=12)\n",
    "    ax3.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for bar, value in zip(bars, quartile_values):\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{value:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Processing info (if available)\n",
    "    ax4.axis('off')\n",
    "    processing_info = [\n",
    "        f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\",\n",
    "        f\"Model Type: ResNet Image Analysis\",\n",
    "        f\"Total Books: {len(results_df):,}\",\n",
    "        f\"Success Rate: 100%\",  # Assuming all in results_df were successful\n",
    "        \"\",\n",
    "        \"Key Findings:\",\n",
    "        f\"‚Ä¢ Most confident emotion: {results_df.loc[results_df['confidence'].idxmax(), 'predicted_emotion']}\",\n",
    "        f\"‚Ä¢ Highest confidence: {results_df['confidence'].max():.3f}\",\n",
    "        f\"‚Ä¢ Most common emotion: {results_df['predicted_emotion'].mode().iloc[0]}\",\n",
    "        f\"‚Ä¢ Emotion diversity: {results_df['predicted_emotion'].nunique()}/9 emotions found\"\n",
    "    ]\n",
    "    \n",
    "    for i, info in enumerate(processing_info):\n",
    "        weight = 'bold' if info.startswith('‚Ä¢') or info.endswith(':') else 'normal'\n",
    "        size = 12 if info.startswith('Analysis') or info.startswith('Key') else 11\n",
    "        ax4.text(0.05, 0.95 - i*0.08, info, transform=ax4.transAxes, \n",
    "                fontsize=size, fontweight=weight, verticalalignment='top')\n",
    "    \n",
    "    ax4.set_title('Processing Information', fontsize=14, pad=20, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_dir}/10_summary_dashboard.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"‚úÖ Saved: {save_dir}/10_summary_dashboard.png\")\n",
    "\n",
    "def print_resnet_summary(results_df):\n",
    "    \"\"\"Print a detailed text summary of the ResNet emotion analysis\"\"\"\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"üñºÔ∏è RESNET IMAGE EMOTION ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"üìö Total books analyzed: {len(results_df):,}\")\n",
    "    print(f\"üéØ Mean confidence: {results_df['confidence'].mean():.3f}\")\n",
    "    print(f\"üìä Median confidence: {results_df['confidence'].median():.3f}\")\n",
    "    print(f\"üìà Std confidence: {results_df['confidence'].std():.3f}\")\n",
    "    print(f\"üîç Min confidence: {results_df['confidence'].min():.3f}\")\n",
    "    print(f\"üîç Max confidence: {results_df['confidence'].max():.3f}\")\n",
    "    \n",
    "    # Emotion distribution\n",
    "    print(f\"\\nüé≠ EMOTION DISTRIBUTION:\")\n",
    "    emotion_counts = results_df['predicted_emotion'].value_counts()\n",
    "    for emotion, count in emotion_counts.items():\n",
    "        pct = count / len(results_df) * 100\n",
    "        print(f\"  {emotion:15}: {count:6,} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Confidence analysis\n",
    "    print(f\"\\nüéØ CONFIDENCE ANALYSIS:\")\n",
    "    conf_thresholds = [0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "    for threshold in conf_thresholds:\n",
    "        high_conf = (results_df['confidence'] >= threshold).sum()\n",
    "        pct = high_conf / len(results_df) * 100\n",
    "        print(f\"  Confidence ‚â• {threshold}: {high_conf:6,} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # Rating analysis (if available)\n",
    "    if 'average_rating' in results_df.columns:\n",
    "        rated_books = results_df.dropna(subset=['average_rating'])\n",
    "        if len(rated_books) > 0:\n",
    "            print(f\"\\n‚≠ê RATING ANALYSIS:\")\n",
    "            print(f\"  Books with ratings: {len(rated_books):,} ({len(rated_books)/len(results_df)*100:.1f}%)\")\n",
    "            print(f\"  Average rating: {rated_books['average_rating'].mean():.2f}\")\n",
    "            print(f\"  Rating std: {rated_books['average_rating'].std():.2f}\")\n",
    "            \n",
    "            # Top rated emotions\n",
    "            emotion_ratings = rated_books.groupby('predicted_emotion')['average_rating'].mean().sort_values(ascending=False)\n",
    "            print(f\"  Highest rated emotion: {emotion_ratings.index[0]} ({emotion_ratings.iloc[0]:.2f})\")\n",
    "            print(f\"  Lowest rated emotion: {emotion_ratings.index[-1]} ({emotion_ratings.iloc[-1]:.2f})\")\n",
    "    \n",
    "    # Most confident predictions\n",
    "    print(f\"\\nüèÜ MOST CONFIDENT PREDICTIONS:\")\n",
    "    top_confident = results_df.nlargest(5, 'confidence')[['title', 'predicted_emotion', 'confidence']]\n",
    "    for _, row in top_confident.iterrows():\n",
    "        title_short = row['title'][:40] + '...' if len(str(row['title'])) > 40 else str(row['title'])\n",
    "        print(f\"  {row['predicted_emotion']:12} ({row['confidence']:.3f}): {title_short}\")\n",
    "    \n",
    "    # Emotion confidence rankings\n",
    "    print(f\"\\nüìä AVERAGE CONFIDENCE BY EMOTION:\")\n",
    "    emotion_confidence = results_df.groupby('predicted_emotion')['confidence'].mean().sort_values(ascending=False)\n",
    "    for emotion, conf in emotion_confidence.items():\n",
    "        count = (results_df['predicted_emotion'] == emotion).sum()\n",
    "        print(f\"  {emotion:15}: {conf:.3f} (n={count:,})\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "\n",
    "def analyze_resnet_results(results_df, save_dir=None):\n",
    "    \"\"\"\n",
    "    Run complete analysis and visualization of ResNet results\n",
    "    \n",
    "    Usage after running ResNet analysis:\n",
    "    analyze_resnet_results(results, 'resnet_visualizations')\n",
    "    \"\"\"\n",
    "    \n",
    "    if save_dir is None:\n",
    "        save_dir = 'resnet_visualizations'\n",
    "    \n",
    "    print(\"üé® Creating comprehensive ResNet emotion analysis visualizations...\")\n",
    "    print(\"üìä Each plot will be saved as a separate image file...\")\n",
    "    \n",
    "    # Print text summary\n",
    "    print_resnet_summary(results_df)\n",
    "    \n",
    "    # Create visualizations\n",
    "    viz_dir = create_resnet_visualizations(results_df, save_dir)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Analysis complete! All visualizations saved to: {viz_dir}\")\n",
    "    print(f\"üìÅ Created {len([f for f in os.listdir(viz_dir) if f.endswith('.png')])} visualization files\")\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "analyze_resnet_results(results, 'resnet_visualizations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f879a204-ebec-4bbd-a0aa-47f071865abe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
